{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"../../dataset/UCI_HAR/UCI HAR Dataset/features.txt\", sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
    "\n",
    "# 피쳐이름에 그룹바이와 cumcount를 적용한 데이터프레임을 만든다\n",
    "features_cc = features_df.groupby('column_name').cumcount() # (561, )의 시리즈 생성됨\n",
    "features_cc = pd.DataFrame(features_cc) # (561, 1)의 데이터프레임으로 변환\n",
    "features_cc.columns = ['cumcount'] # 칼럼명 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cc = features_cc.reset_index() # (561,2)가 된다.\n",
    "features_df = features_df.reset_index() # (561,3)이 된다.\n",
    "\n",
    "# 양쪽 데이터프레임 reset_index()의 결과로 생긴 'index'열을 기준으로 outer join(병합)한다.\n",
    "# 그럼 결과적으로 index, column_index, column_name, cumcount 4개의 열을 가진 데이터프레임이 생성된다.\n",
    "new_df = pd.merge(features_cc, features_df, on='index', how='outer')\n",
    "\n",
    "# 병합에 사용되었던 index 칼럼을 드랍한다.\n",
    "new_df = new_df.drop(['index'], axis=1) # column_index, column_name, cumcount의 (561,3)이 된다.\n",
    "\n",
    "# column_name과 cumcount를 합쳐서 하나의 column_name으로 만드는 과정이다\n",
    "# cumcount가 1이상일경우 column_name 뒤에 _1 또는 _2를 붙인다.\n",
    "new_df['column_name'] = new_df[['column_name', 'cumcount']].apply(lambda x: x[0]+'_'+str(x[1])\n",
    "                                                                if x[1]>0 else x[0], axis=1)\n",
    "\n",
    "# cumcount를 column_name을 새로짓는 데 사용하였으므로 이제 드랍한다.\n",
    "# 이 작업을 마치면 cumcount 칼럼이 없어져서 (561,2) 데이터프레임이 된다.\n",
    "new_df = new_df.drop(['cumcount'], axis=1) # column_index, column_name 두개의 (561,2) 가 된다.\n",
    "\n",
    "h = new_df['column_name'].value_counts()\n",
    "\n",
    "for i in h:\n",
    "    if (i == 3):\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
       "       'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
       "       'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',\n",
       "       'tBodyAcc-max()-X', 'tBodyAcc-max()-Y', 'tBodyAcc-max()-Z',\n",
       "       'tBodyAcc-min()-X', 'tBodyAcc-min()-Y', 'tBodyAcc-min()-Z',\n",
       "       'tBodyAcc-sma()', 'tBodyAcc-energy()-X', 'tBodyAcc-energy()-Y',\n",
       "       'tBodyAcc-energy()-Z', 'tBodyAcc-iqr()-X', 'tBodyAcc-iqr()-Y',\n",
       "       'tBodyAcc-iqr()-Z', 'tBodyAcc-entropy()-X', 'tBodyAcc-entropy()-Y',\n",
       "       'tBodyAcc-entropy()-Z', 'tBodyAcc-arCoeff()-X,1',\n",
       "       'tBodyAcc-arCoeff()-X,2', 'tBodyAcc-arCoeff()-X,3',\n",
       "       'tBodyAcc-arCoeff()-X,4', 'tBodyAcc-arCoeff()-Y,1',\n",
       "       'tBodyAcc-arCoeff()-Y,2', 'tBodyAcc-arCoeff()-Y,3',\n",
       "       'tBodyAcc-arCoeff()-Y,4', 'tBodyAcc-arCoeff()-Z,1',\n",
       "       'tBodyAcc-arCoeff()-Z,2', 'tBodyAcc-arCoeff()-Z,3',\n",
       "       'tBodyAcc-arCoeff()-Z,4', 'tBodyAcc-correlation()-X,Y',\n",
       "       'tBodyAcc-correlation()-X,Z', 'tBodyAcc-correlation()-Y,Z',\n",
       "       'tGravityAcc-mean()-X', 'tGravityAcc-mean()-Y',\n",
       "       'tGravityAcc-mean()-Z', 'tGravityAcc-std()-X',\n",
       "       'tGravityAcc-std()-Y', 'tGravityAcc-std()-Z',\n",
       "       'tGravityAcc-mad()-X', 'tGravityAcc-mad()-Y',\n",
       "       'tGravityAcc-mad()-Z', 'tGravityAcc-max()-X',\n",
       "       'tGravityAcc-max()-Y', 'tGravityAcc-max()-Z',\n",
       "       'tGravityAcc-min()-X', 'tGravityAcc-min()-Y',\n",
       "       'tGravityAcc-min()-Z', 'tGravityAcc-sma()',\n",
       "       'tGravityAcc-energy()-X', 'tGravityAcc-energy()-Y',\n",
       "       'tGravityAcc-energy()-Z', 'tGravityAcc-iqr()-X',\n",
       "       'tGravityAcc-iqr()-Y', 'tGravityAcc-iqr()-Z',\n",
       "       'tGravityAcc-entropy()-X', 'tGravityAcc-entropy()-Y',\n",
       "       'tGravityAcc-entropy()-Z', 'tGravityAcc-arCoeff()-X,1',\n",
       "       'tGravityAcc-arCoeff()-X,2', 'tGravityAcc-arCoeff()-X,3',\n",
       "       'tGravityAcc-arCoeff()-X,4', 'tGravityAcc-arCoeff()-Y,1',\n",
       "       'tGravityAcc-arCoeff()-Y,2', 'tGravityAcc-arCoeff()-Y,3',\n",
       "       'tGravityAcc-arCoeff()-Y,4', 'tGravityAcc-arCoeff()-Z,1',\n",
       "       'tGravityAcc-arCoeff()-Z,2', 'tGravityAcc-arCoeff()-Z,3',\n",
       "       'tGravityAcc-arCoeff()-Z,4', 'tGravityAcc-correlation()-X,Y',\n",
       "       'tGravityAcc-correlation()-X,Z', 'tGravityAcc-correlation()-Y,Z',\n",
       "       'tBodyAccJerk-mean()-X', 'tBodyAccJerk-mean()-Y',\n",
       "       'tBodyAccJerk-mean()-Z', 'tBodyAccJerk-std()-X',\n",
       "       'tBodyAccJerk-std()-Y', 'tBodyAccJerk-std()-Z',\n",
       "       'tBodyAccJerk-mad()-X', 'tBodyAccJerk-mad()-Y',\n",
       "       'tBodyAccJerk-mad()-Z', 'tBodyAccJerk-max()-X',\n",
       "       'tBodyAccJerk-max()-Y', 'tBodyAccJerk-max()-Z',\n",
       "       'tBodyAccJerk-min()-X', 'tBodyAccJerk-min()-Y',\n",
       "       'tBodyAccJerk-min()-Z', 'tBodyAccJerk-sma()',\n",
       "       'tBodyAccJerk-energy()-X', 'tBodyAccJerk-energy()-Y',\n",
       "       'tBodyAccJerk-energy()-Z', 'tBodyAccJerk-iqr()-X',\n",
       "       'tBodyAccJerk-iqr()-Y', 'tBodyAccJerk-iqr()-Z',\n",
       "       'tBodyAccJerk-entropy()-X', 'tBodyAccJerk-entropy()-Y',\n",
       "       'tBodyAccJerk-entropy()-Z', 'tBodyAccJerk-arCoeff()-X,1',\n",
       "       'tBodyAccJerk-arCoeff()-X,2', 'tBodyAccJerk-arCoeff()-X,3',\n",
       "       'tBodyAccJerk-arCoeff()-X,4', 'tBodyAccJerk-arCoeff()-Y,1',\n",
       "       'tBodyAccJerk-arCoeff()-Y,2', 'tBodyAccJerk-arCoeff()-Y,3',\n",
       "       'tBodyAccJerk-arCoeff()-Y,4', 'tBodyAccJerk-arCoeff()-Z,1',\n",
       "       'tBodyAccJerk-arCoeff()-Z,2', 'tBodyAccJerk-arCoeff()-Z,3',\n",
       "       'tBodyAccJerk-arCoeff()-Z,4', 'tBodyAccJerk-correlation()-X,Y',\n",
       "       'tBodyAccJerk-correlation()-X,Z', 'tBodyAccJerk-correlation()-Y,Z',\n",
       "       'tBodyGyro-mean()-X', 'tBodyGyro-mean()-Y', 'tBodyGyro-mean()-Z',\n",
       "       'tBodyGyro-std()-X', 'tBodyGyro-std()-Y', 'tBodyGyro-std()-Z',\n",
       "       'tBodyGyro-mad()-X', 'tBodyGyro-mad()-Y', 'tBodyGyro-mad()-Z',\n",
       "       'tBodyGyro-max()-X', 'tBodyGyro-max()-Y', 'tBodyGyro-max()-Z',\n",
       "       'tBodyGyro-min()-X', 'tBodyGyro-min()-Y', 'tBodyGyro-min()-Z',\n",
       "       'tBodyGyro-sma()', 'tBodyGyro-energy()-X', 'tBodyGyro-energy()-Y',\n",
       "       'tBodyGyro-energy()-Z', 'tBodyGyro-iqr()-X', 'tBodyGyro-iqr()-Y',\n",
       "       'tBodyGyro-iqr()-Z', 'tBodyGyro-entropy()-X',\n",
       "       'tBodyGyro-entropy()-Y', 'tBodyGyro-entropy()-Z',\n",
       "       'tBodyGyro-arCoeff()-X,1', 'tBodyGyro-arCoeff()-X,2',\n",
       "       'tBodyGyro-arCoeff()-X,3', 'tBodyGyro-arCoeff()-X,4',\n",
       "       'tBodyGyro-arCoeff()-Y,1', 'tBodyGyro-arCoeff()-Y,2',\n",
       "       'tBodyGyro-arCoeff()-Y,3', 'tBodyGyro-arCoeff()-Y,4',\n",
       "       'tBodyGyro-arCoeff()-Z,1', 'tBodyGyro-arCoeff()-Z,2',\n",
       "       'tBodyGyro-arCoeff()-Z,3', 'tBodyGyro-arCoeff()-Z,4',\n",
       "       'tBodyGyro-correlation()-X,Y', 'tBodyGyro-correlation()-X,Z',\n",
       "       'tBodyGyro-correlation()-Y,Z', 'tBodyGyroJerk-mean()-X',\n",
       "       'tBodyGyroJerk-mean()-Y', 'tBodyGyroJerk-mean()-Z',\n",
       "       'tBodyGyroJerk-std()-X', 'tBodyGyroJerk-std()-Y',\n",
       "       'tBodyGyroJerk-std()-Z', 'tBodyGyroJerk-mad()-X',\n",
       "       'tBodyGyroJerk-mad()-Y', 'tBodyGyroJerk-mad()-Z',\n",
       "       'tBodyGyroJerk-max()-X', 'tBodyGyroJerk-max()-Y',\n",
       "       'tBodyGyroJerk-max()-Z', 'tBodyGyroJerk-min()-X',\n",
       "       'tBodyGyroJerk-min()-Y', 'tBodyGyroJerk-min()-Z',\n",
       "       'tBodyGyroJerk-sma()', 'tBodyGyroJerk-energy()-X',\n",
       "       'tBodyGyroJerk-energy()-Y', 'tBodyGyroJerk-energy()-Z',\n",
       "       'tBodyGyroJerk-iqr()-X', 'tBodyGyroJerk-iqr()-Y',\n",
       "       'tBodyGyroJerk-iqr()-Z', 'tBodyGyroJerk-entropy()-X',\n",
       "       'tBodyGyroJerk-entropy()-Y', 'tBodyGyroJerk-entropy()-Z',\n",
       "       'tBodyGyroJerk-arCoeff()-X,1', 'tBodyGyroJerk-arCoeff()-X,2',\n",
       "       'tBodyGyroJerk-arCoeff()-X,3', 'tBodyGyroJerk-arCoeff()-X,4',\n",
       "       'tBodyGyroJerk-arCoeff()-Y,1', 'tBodyGyroJerk-arCoeff()-Y,2',\n",
       "       'tBodyGyroJerk-arCoeff()-Y,3', 'tBodyGyroJerk-arCoeff()-Y,4',\n",
       "       'tBodyGyroJerk-arCoeff()-Z,1', 'tBodyGyroJerk-arCoeff()-Z,2',\n",
       "       'tBodyGyroJerk-arCoeff()-Z,3', 'tBodyGyroJerk-arCoeff()-Z,4',\n",
       "       'tBodyGyroJerk-correlation()-X,Y',\n",
       "       'tBodyGyroJerk-correlation()-X,Z',\n",
       "       'tBodyGyroJerk-correlation()-Y,Z', 'tBodyAccMag-mean()',\n",
       "       'tBodyAccMag-std()', 'tBodyAccMag-mad()', 'tBodyAccMag-max()',\n",
       "       'tBodyAccMag-min()', 'tBodyAccMag-sma()', 'tBodyAccMag-energy()',\n",
       "       'tBodyAccMag-iqr()', 'tBodyAccMag-entropy()',\n",
       "       'tBodyAccMag-arCoeff()1', 'tBodyAccMag-arCoeff()2',\n",
       "       'tBodyAccMag-arCoeff()3', 'tBodyAccMag-arCoeff()4',\n",
       "       'tGravityAccMag-mean()', 'tGravityAccMag-std()',\n",
       "       'tGravityAccMag-mad()', 'tGravityAccMag-max()',\n",
       "       'tGravityAccMag-min()', 'tGravityAccMag-sma()',\n",
       "       'tGravityAccMag-energy()', 'tGravityAccMag-iqr()',\n",
       "       'tGravityAccMag-entropy()', 'tGravityAccMag-arCoeff()1',\n",
       "       'tGravityAccMag-arCoeff()2', 'tGravityAccMag-arCoeff()3',\n",
       "       'tGravityAccMag-arCoeff()4', 'tBodyAccJerkMag-mean()',\n",
       "       'tBodyAccJerkMag-std()', 'tBodyAccJerkMag-mad()',\n",
       "       'tBodyAccJerkMag-max()', 'tBodyAccJerkMag-min()',\n",
       "       'tBodyAccJerkMag-sma()', 'tBodyAccJerkMag-energy()',\n",
       "       'tBodyAccJerkMag-iqr()', 'tBodyAccJerkMag-entropy()',\n",
       "       'tBodyAccJerkMag-arCoeff()1', 'tBodyAccJerkMag-arCoeff()2',\n",
       "       'tBodyAccJerkMag-arCoeff()3', 'tBodyAccJerkMag-arCoeff()4',\n",
       "       'tBodyGyroMag-mean()', 'tBodyGyroMag-std()', 'tBodyGyroMag-mad()',\n",
       "       'tBodyGyroMag-max()', 'tBodyGyroMag-min()', 'tBodyGyroMag-sma()',\n",
       "       'tBodyGyroMag-energy()', 'tBodyGyroMag-iqr()',\n",
       "       'tBodyGyroMag-entropy()', 'tBodyGyroMag-arCoeff()1',\n",
       "       'tBodyGyroMag-arCoeff()2', 'tBodyGyroMag-arCoeff()3',\n",
       "       'tBodyGyroMag-arCoeff()4', 'tBodyGyroJerkMag-mean()',\n",
       "       'tBodyGyroJerkMag-std()', 'tBodyGyroJerkMag-mad()',\n",
       "       'tBodyGyroJerkMag-max()', 'tBodyGyroJerkMag-min()',\n",
       "       'tBodyGyroJerkMag-sma()', 'tBodyGyroJerkMag-energy()',\n",
       "       'tBodyGyroJerkMag-iqr()', 'tBodyGyroJerkMag-entropy()',\n",
       "       'tBodyGyroJerkMag-arCoeff()1', 'tBodyGyroJerkMag-arCoeff()2',\n",
       "       'tBodyGyroJerkMag-arCoeff()3', 'tBodyGyroJerkMag-arCoeff()4',\n",
       "       'fBodyAcc-mean()-X', 'fBodyAcc-mean()-Y', 'fBodyAcc-mean()-Z',\n",
       "       'fBodyAcc-std()-X', 'fBodyAcc-std()-Y', 'fBodyAcc-std()-Z',\n",
       "       'fBodyAcc-mad()-X', 'fBodyAcc-mad()-Y', 'fBodyAcc-mad()-Z',\n",
       "       'fBodyAcc-max()-X', 'fBodyAcc-max()-Y', 'fBodyAcc-max()-Z',\n",
       "       'fBodyAcc-min()-X', 'fBodyAcc-min()-Y', 'fBodyAcc-min()-Z',\n",
       "       'fBodyAcc-sma()', 'fBodyAcc-energy()-X', 'fBodyAcc-energy()-Y',\n",
       "       'fBodyAcc-energy()-Z', 'fBodyAcc-iqr()-X', 'fBodyAcc-iqr()-Y',\n",
       "       'fBodyAcc-iqr()-Z', 'fBodyAcc-entropy()-X', 'fBodyAcc-entropy()-Y',\n",
       "       'fBodyAcc-entropy()-Z', 'fBodyAcc-maxInds-X', 'fBodyAcc-maxInds-Y',\n",
       "       'fBodyAcc-maxInds-Z', 'fBodyAcc-meanFreq()-X',\n",
       "       'fBodyAcc-meanFreq()-Y', 'fBodyAcc-meanFreq()-Z',\n",
       "       'fBodyAcc-skewness()-X', 'fBodyAcc-kurtosis()-X',\n",
       "       'fBodyAcc-skewness()-Y', 'fBodyAcc-kurtosis()-Y',\n",
       "       'fBodyAcc-skewness()-Z', 'fBodyAcc-kurtosis()-Z',\n",
       "       'fBodyAcc-bandsEnergy()-1,8', 'fBodyAcc-bandsEnergy()-9,16',\n",
       "       'fBodyAcc-bandsEnergy()-17,24', 'fBodyAcc-bandsEnergy()-25,32',\n",
       "       'fBodyAcc-bandsEnergy()-33,40', 'fBodyAcc-bandsEnergy()-41,48',\n",
       "       'fBodyAcc-bandsEnergy()-49,56', 'fBodyAcc-bandsEnergy()-57,64',\n",
       "       'fBodyAcc-bandsEnergy()-1,16', 'fBodyAcc-bandsEnergy()-17,32',\n",
       "       'fBodyAcc-bandsEnergy()-33,48', 'fBodyAcc-bandsEnergy()-49,64',\n",
       "       'fBodyAcc-bandsEnergy()-1,24', 'fBodyAcc-bandsEnergy()-25,48',\n",
       "       'fBodyAcc-bandsEnergy()-1,8_1', 'fBodyAcc-bandsEnergy()-9,16_1',\n",
       "       'fBodyAcc-bandsEnergy()-17,24_1', 'fBodyAcc-bandsEnergy()-25,32_1',\n",
       "       'fBodyAcc-bandsEnergy()-33,40_1', 'fBodyAcc-bandsEnergy()-41,48_1',\n",
       "       'fBodyAcc-bandsEnergy()-49,56_1', 'fBodyAcc-bandsEnergy()-57,64_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,16_1', 'fBodyAcc-bandsEnergy()-17,32_1',\n",
       "       'fBodyAcc-bandsEnergy()-33,48_1', 'fBodyAcc-bandsEnergy()-49,64_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,24_1', 'fBodyAcc-bandsEnergy()-25,48_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,8_2', 'fBodyAcc-bandsEnergy()-9,16_2',\n",
       "       'fBodyAcc-bandsEnergy()-17,24_2', 'fBodyAcc-bandsEnergy()-25,32_2',\n",
       "       'fBodyAcc-bandsEnergy()-33,40_2', 'fBodyAcc-bandsEnergy()-41,48_2',\n",
       "       'fBodyAcc-bandsEnergy()-49,56_2', 'fBodyAcc-bandsEnergy()-57,64_2',\n",
       "       'fBodyAcc-bandsEnergy()-1,16_2', 'fBodyAcc-bandsEnergy()-17,32_2',\n",
       "       'fBodyAcc-bandsEnergy()-33,48_2', 'fBodyAcc-bandsEnergy()-49,64_2',\n",
       "       'fBodyAcc-bandsEnergy()-1,24_2', 'fBodyAcc-bandsEnergy()-25,48_2',\n",
       "       'fBodyAccJerk-mean()-X', 'fBodyAccJerk-mean()-Y',\n",
       "       'fBodyAccJerk-mean()-Z', 'fBodyAccJerk-std()-X',\n",
       "       'fBodyAccJerk-std()-Y', 'fBodyAccJerk-std()-Z',\n",
       "       'fBodyAccJerk-mad()-X', 'fBodyAccJerk-mad()-Y',\n",
       "       'fBodyAccJerk-mad()-Z', 'fBodyAccJerk-max()-X',\n",
       "       'fBodyAccJerk-max()-Y', 'fBodyAccJerk-max()-Z',\n",
       "       'fBodyAccJerk-min()-X', 'fBodyAccJerk-min()-Y',\n",
       "       'fBodyAccJerk-min()-Z', 'fBodyAccJerk-sma()',\n",
       "       'fBodyAccJerk-energy()-X', 'fBodyAccJerk-energy()-Y',\n",
       "       'fBodyAccJerk-energy()-Z', 'fBodyAccJerk-iqr()-X',\n",
       "       'fBodyAccJerk-iqr()-Y', 'fBodyAccJerk-iqr()-Z',\n",
       "       'fBodyAccJerk-entropy()-X', 'fBodyAccJerk-entropy()-Y',\n",
       "       'fBodyAccJerk-entropy()-Z', 'fBodyAccJerk-maxInds-X',\n",
       "       'fBodyAccJerk-maxInds-Y', 'fBodyAccJerk-maxInds-Z',\n",
       "       'fBodyAccJerk-meanFreq()-X', 'fBodyAccJerk-meanFreq()-Y',\n",
       "       'fBodyAccJerk-meanFreq()-Z', 'fBodyAccJerk-skewness()-X',\n",
       "       'fBodyAccJerk-kurtosis()-X', 'fBodyAccJerk-skewness()-Y',\n",
       "       'fBodyAccJerk-kurtosis()-Y', 'fBodyAccJerk-skewness()-Z',\n",
       "       'fBodyAccJerk-kurtosis()-Z', 'fBodyAccJerk-bandsEnergy()-1,8',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,8_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,8_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48_2', 'fBodyGyro-mean()-X',\n",
       "       'fBodyGyro-mean()-Y', 'fBodyGyro-mean()-Z', 'fBodyGyro-std()-X',\n",
       "       'fBodyGyro-std()-Y', 'fBodyGyro-std()-Z', 'fBodyGyro-mad()-X',\n",
       "       'fBodyGyro-mad()-Y', 'fBodyGyro-mad()-Z', 'fBodyGyro-max()-X',\n",
       "       'fBodyGyro-max()-Y', 'fBodyGyro-max()-Z', 'fBodyGyro-min()-X',\n",
       "       'fBodyGyro-min()-Y', 'fBodyGyro-min()-Z', 'fBodyGyro-sma()',\n",
       "       'fBodyGyro-energy()-X', 'fBodyGyro-energy()-Y',\n",
       "       'fBodyGyro-energy()-Z', 'fBodyGyro-iqr()-X', 'fBodyGyro-iqr()-Y',\n",
       "       'fBodyGyro-iqr()-Z', 'fBodyGyro-entropy()-X',\n",
       "       'fBodyGyro-entropy()-Y', 'fBodyGyro-entropy()-Z',\n",
       "       'fBodyGyro-maxInds-X', 'fBodyGyro-maxInds-Y',\n",
       "       'fBodyGyro-maxInds-Z', 'fBodyGyro-meanFreq()-X',\n",
       "       'fBodyGyro-meanFreq()-Y', 'fBodyGyro-meanFreq()-Z',\n",
       "       'fBodyGyro-skewness()-X', 'fBodyGyro-kurtosis()-X',\n",
       "       'fBodyGyro-skewness()-Y', 'fBodyGyro-kurtosis()-Y',\n",
       "       'fBodyGyro-skewness()-Z', 'fBodyGyro-kurtosis()-Z',\n",
       "       'fBodyGyro-bandsEnergy()-1,8', 'fBodyGyro-bandsEnergy()-9,16',\n",
       "       'fBodyGyro-bandsEnergy()-17,24', 'fBodyGyro-bandsEnergy()-25,32',\n",
       "       'fBodyGyro-bandsEnergy()-33,40', 'fBodyGyro-bandsEnergy()-41,48',\n",
       "       'fBodyGyro-bandsEnergy()-49,56', 'fBodyGyro-bandsEnergy()-57,64',\n",
       "       'fBodyGyro-bandsEnergy()-1,16', 'fBodyGyro-bandsEnergy()-17,32',\n",
       "       'fBodyGyro-bandsEnergy()-33,48', 'fBodyGyro-bandsEnergy()-49,64',\n",
       "       'fBodyGyro-bandsEnergy()-1,24', 'fBodyGyro-bandsEnergy()-25,48',\n",
       "       'fBodyGyro-bandsEnergy()-1,8_1', 'fBodyGyro-bandsEnergy()-9,16_1',\n",
       "       'fBodyGyro-bandsEnergy()-17,24_1',\n",
       "       'fBodyGyro-bandsEnergy()-25,32_1',\n",
       "       'fBodyGyro-bandsEnergy()-33,40_1',\n",
       "       'fBodyGyro-bandsEnergy()-41,48_1',\n",
       "       'fBodyGyro-bandsEnergy()-49,56_1',\n",
       "       'fBodyGyro-bandsEnergy()-57,64_1',\n",
       "       'fBodyGyro-bandsEnergy()-1,16_1',\n",
       "       'fBodyGyro-bandsEnergy()-17,32_1',\n",
       "       'fBodyGyro-bandsEnergy()-33,48_1',\n",
       "       'fBodyGyro-bandsEnergy()-49,64_1',\n",
       "       'fBodyGyro-bandsEnergy()-1,24_1',\n",
       "       'fBodyGyro-bandsEnergy()-25,48_1', 'fBodyGyro-bandsEnergy()-1,8_2',\n",
       "       'fBodyGyro-bandsEnergy()-9,16_2',\n",
       "       'fBodyGyro-bandsEnergy()-17,24_2',\n",
       "       'fBodyGyro-bandsEnergy()-25,32_2',\n",
       "       'fBodyGyro-bandsEnergy()-33,40_2',\n",
       "       'fBodyGyro-bandsEnergy()-41,48_2',\n",
       "       'fBodyGyro-bandsEnergy()-49,56_2',\n",
       "       'fBodyGyro-bandsEnergy()-57,64_2',\n",
       "       'fBodyGyro-bandsEnergy()-1,16_2',\n",
       "       'fBodyGyro-bandsEnergy()-17,32_2',\n",
       "       'fBodyGyro-bandsEnergy()-33,48_2',\n",
       "       'fBodyGyro-bandsEnergy()-49,64_2',\n",
       "       'fBodyGyro-bandsEnergy()-1,24_2',\n",
       "       'fBodyGyro-bandsEnergy()-25,48_2', 'fBodyAccMag-mean()',\n",
       "       'fBodyAccMag-std()', 'fBodyAccMag-mad()', 'fBodyAccMag-max()',\n",
       "       'fBodyAccMag-min()', 'fBodyAccMag-sma()', 'fBodyAccMag-energy()',\n",
       "       'fBodyAccMag-iqr()', 'fBodyAccMag-entropy()',\n",
       "       'fBodyAccMag-maxInds', 'fBodyAccMag-meanFreq()',\n",
       "       'fBodyAccMag-skewness()', 'fBodyAccMag-kurtosis()',\n",
       "       'fBodyBodyAccJerkMag-mean()', 'fBodyBodyAccJerkMag-std()',\n",
       "       'fBodyBodyAccJerkMag-mad()', 'fBodyBodyAccJerkMag-max()',\n",
       "       'fBodyBodyAccJerkMag-min()', 'fBodyBodyAccJerkMag-sma()',\n",
       "       'fBodyBodyAccJerkMag-energy()', 'fBodyBodyAccJerkMag-iqr()',\n",
       "       'fBodyBodyAccJerkMag-entropy()', 'fBodyBodyAccJerkMag-maxInds',\n",
       "       'fBodyBodyAccJerkMag-meanFreq()', 'fBodyBodyAccJerkMag-skewness()',\n",
       "       'fBodyBodyAccJerkMag-kurtosis()', 'fBodyBodyGyroMag-mean()',\n",
       "       'fBodyBodyGyroMag-std()', 'fBodyBodyGyroMag-mad()',\n",
       "       'fBodyBodyGyroMag-max()', 'fBodyBodyGyroMag-min()',\n",
       "       'fBodyBodyGyroMag-sma()', 'fBodyBodyGyroMag-energy()',\n",
       "       'fBodyBodyGyroMag-iqr()', 'fBodyBodyGyroMag-entropy()',\n",
       "       'fBodyBodyGyroMag-maxInds', 'fBodyBodyGyroMag-meanFreq()',\n",
       "       'fBodyBodyGyroMag-skewness()', 'fBodyBodyGyroMag-kurtosis()',\n",
       "       'fBodyBodyGyroJerkMag-mean()', 'fBodyBodyGyroJerkMag-std()',\n",
       "       'fBodyBodyGyroJerkMag-mad()', 'fBodyBodyGyroJerkMag-max()',\n",
       "       'fBodyBodyGyroJerkMag-min()', 'fBodyBodyGyroJerkMag-sma()',\n",
       "       'fBodyBodyGyroJerkMag-energy()', 'fBodyBodyGyroJerkMag-iqr()',\n",
       "       'fBodyBodyGyroJerkMag-entropy()', 'fBodyBodyGyroJerkMag-maxInds',\n",
       "       'fBodyBodyGyroJerkMag-meanFreq()',\n",
       "       'fBodyBodyGyroJerkMag-skewness()',\n",
       "       'fBodyBodyGyroJerkMag-kurtosis()', 'angle(tBodyAccMean,gravity)',\n",
       "       'angle(tBodyAccJerkMean),gravityMean)',\n",
       "       'angle(tBodyGyroMean,gravityMean)',\n",
       "       'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',\n",
       "       'angle(Y,gravityMean)', 'angle(Z,gravityMean)'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['column_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity\n",
       "0            5\n",
       "1            5\n",
       "2            5\n",
       "3            5\n",
       "4            5\n",
       "...        ...\n",
       "7347         2\n",
       "7348         2\n",
       "7349         2\n",
       "7350         2\n",
       "7351         2\n",
       "\n",
       "[7352 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"../../dataset/UCI_HAR/UCI HAR Dataset/train/X_train.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_train = pd.read_csv(\"../../dataset/UCI_HAR/UCI HAR Dataset/train/y_train.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "X_test = pd.read_csv(\"../../dataset/UCI_HAR/UCI HAR Dataset/test/X_test.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_test = pd.read_csv(\"../../dataset/UCI_HAR/UCI HAR Dataset/test/y_test.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4067, 562) (1560, 562)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200642</td>\n",
       "      <td>-0.063683</td>\n",
       "      <td>-0.419628</td>\n",
       "      <td>-0.868814</td>\n",
       "      <td>-0.939441</td>\n",
       "      <td>-0.737529</td>\n",
       "      <td>-0.859817</td>\n",
       "      <td>-0.939019</td>\n",
       "      <td>-0.766437</td>\n",
       "      <td>-0.856036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>-0.276399</td>\n",
       "      <td>-0.360603</td>\n",
       "      <td>0.062940</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>-0.026080</td>\n",
       "      <td>-0.687219</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055948</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>-0.253908</td>\n",
       "      <td>-0.875426</td>\n",
       "      <td>-0.923902</td>\n",
       "      <td>-0.849304</td>\n",
       "      <td>-0.868531</td>\n",
       "      <td>-0.921998</td>\n",
       "      <td>-0.848928</td>\n",
       "      <td>-0.871359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897357</td>\n",
       "      <td>-0.767990</td>\n",
       "      <td>0.133011</td>\n",
       "      <td>-0.021461</td>\n",
       "      <td>-1.218805</td>\n",
       "      <td>1.484470</td>\n",
       "      <td>-0.694138</td>\n",
       "      <td>0.409117</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073515</td>\n",
       "      <td>-0.043416</td>\n",
       "      <td>-0.076295</td>\n",
       "      <td>-0.869039</td>\n",
       "      <td>-0.907760</td>\n",
       "      <td>-0.893785</td>\n",
       "      <td>-0.863137</td>\n",
       "      <td>-0.898854</td>\n",
       "      <td>-0.896701</td>\n",
       "      <td>-0.863323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260878</td>\n",
       "      <td>-0.438316</td>\n",
       "      <td>-0.377840</td>\n",
       "      <td>0.391976</td>\n",
       "      <td>0.151207</td>\n",
       "      <td>1.704201</td>\n",
       "      <td>-0.702239</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066696</td>\n",
       "      <td>-0.208422</td>\n",
       "      <td>-0.249712</td>\n",
       "      <td>-0.870626</td>\n",
       "      <td>-0.940022</td>\n",
       "      <td>-0.921805</td>\n",
       "      <td>-0.864503</td>\n",
       "      <td>-0.938124</td>\n",
       "      <td>-0.925279</td>\n",
       "      <td>-0.863323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.463155</td>\n",
       "      <td>-0.135025</td>\n",
       "      <td>-0.033637</td>\n",
       "      <td>1.037851</td>\n",
       "      <td>-1.003019</td>\n",
       "      <td>-0.701684</td>\n",
       "      <td>0.414650</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030469</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>-0.109848</td>\n",
       "      <td>-0.875188</td>\n",
       "      <td>-0.934878</td>\n",
       "      <td>-0.921343</td>\n",
       "      <td>-0.867384</td>\n",
       "      <td>-0.931789</td>\n",
       "      <td>-0.928028</td>\n",
       "      <td>-0.870260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>-0.240313</td>\n",
       "      <td>0.340406</td>\n",
       "      <td>0.268486</td>\n",
       "      <td>1.125918</td>\n",
       "      <td>-1.276282</td>\n",
       "      <td>-0.700152</td>\n",
       "      <td>0.425463</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.186180</td>\n",
       "      <td>0.070699</td>\n",
       "      <td>-0.873397</td>\n",
       "      <td>-0.954117</td>\n",
       "      <td>-0.933139</td>\n",
       "      <td>-0.865748</td>\n",
       "      <td>-0.953493</td>\n",
       "      <td>-0.940363</td>\n",
       "      <td>-0.870260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742707</td>\n",
       "      <td>-0.713107</td>\n",
       "      <td>0.219586</td>\n",
       "      <td>-0.324856</td>\n",
       "      <td>0.437830</td>\n",
       "      <td>-0.757922</td>\n",
       "      <td>-0.703603</td>\n",
       "      <td>0.424358</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.070680</td>\n",
       "      <td>-0.047671</td>\n",
       "      <td>-0.015559</td>\n",
       "      <td>-0.872474</td>\n",
       "      <td>-0.907757</td>\n",
       "      <td>-0.903754</td>\n",
       "      <td>-0.864275</td>\n",
       "      <td>-0.903852</td>\n",
       "      <td>-0.910339</td>\n",
       "      <td>-0.867538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279795</td>\n",
       "      <td>0.197889</td>\n",
       "      <td>-0.657546</td>\n",
       "      <td>-0.519341</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>-0.384001</td>\n",
       "      <td>-0.708525</td>\n",
       "      <td>0.415441</td>\n",
       "      <td>0.048386</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041908</td>\n",
       "      <td>-0.313491</td>\n",
       "      <td>-0.286403</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>-0.906847</td>\n",
       "      <td>-0.900094</td>\n",
       "      <td>-0.863055</td>\n",
       "      <td>-0.904297</td>\n",
       "      <td>-0.910015</td>\n",
       "      <td>-0.867538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700031</td>\n",
       "      <td>0.661908</td>\n",
       "      <td>-0.087811</td>\n",
       "      <td>1.320191</td>\n",
       "      <td>-0.938078</td>\n",
       "      <td>0.990421</td>\n",
       "      <td>-0.706310</td>\n",
       "      <td>0.420848</td>\n",
       "      <td>0.052091</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039929</td>\n",
       "      <td>-0.099375</td>\n",
       "      <td>-0.205007</td>\n",
       "      <td>-0.873382</td>\n",
       "      <td>-0.895938</td>\n",
       "      <td>-0.905077</td>\n",
       "      <td>-0.865674</td>\n",
       "      <td>-0.885617</td>\n",
       "      <td>-0.913390</td>\n",
       "      <td>-0.866823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117163</td>\n",
       "      <td>0.170041</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>0.175674</td>\n",
       "      <td>-0.399562</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>-0.700359</td>\n",
       "      <td>0.438343</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.189550</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>-0.867755</td>\n",
       "      <td>-0.918844</td>\n",
       "      <td>-0.911221</td>\n",
       "      <td>-0.860507</td>\n",
       "      <td>-0.919424</td>\n",
       "      <td>-0.916439</td>\n",
       "      <td>-0.865776</td>\n",
       "      <td>...</td>\n",
       "      <td>2.014197</td>\n",
       "      <td>2.489717</td>\n",
       "      <td>-0.086925</td>\n",
       "      <td>-0.289813</td>\n",
       "      <td>-0.808199</td>\n",
       "      <td>-0.135349</td>\n",
       "      <td>-0.700990</td>\n",
       "      <td>0.442807</td>\n",
       "      <td>0.079173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.200642          -0.063683          -0.419628         -0.868814   \n",
       "1           0.055948           0.031486          -0.253908         -0.875426   \n",
       "2           0.073515          -0.043416          -0.076295         -0.869039   \n",
       "3           0.066696          -0.208422          -0.249712         -0.870626   \n",
       "4           0.030469           0.027587          -0.109848         -0.875188   \n",
       "5           0.038582           0.186180           0.070699         -0.873397   \n",
       "6           0.070680          -0.047671          -0.015559         -0.872474   \n",
       "7           0.041908          -0.313491          -0.286403         -0.871668   \n",
       "8           0.039929          -0.099375          -0.205007         -0.873382   \n",
       "9           0.086790           0.189550           0.054314         -0.867755   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.939441         -0.737529         -0.859817         -0.939019   \n",
       "1         -0.923902         -0.849304         -0.868531         -0.921998   \n",
       "2         -0.907760         -0.893785         -0.863137         -0.898854   \n",
       "3         -0.940022         -0.921805         -0.864503         -0.938124   \n",
       "4         -0.934878         -0.921343         -0.867384         -0.931789   \n",
       "5         -0.954117         -0.933139         -0.865748         -0.953493   \n",
       "6         -0.907757         -0.903754         -0.864275         -0.903852   \n",
       "7         -0.906847         -0.900094         -0.863055         -0.904297   \n",
       "8         -0.895938         -0.905077         -0.865674         -0.885617   \n",
       "9         -0.918844         -0.911221         -0.860507         -0.919424   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.766437         -0.856036  ...                         0.025960   \n",
       "1         -0.848928         -0.871359  ...                        -0.897357   \n",
       "2         -0.896701         -0.863323  ...                        -0.260878   \n",
       "3         -0.925279         -0.863323  ...                         0.591045   \n",
       "4         -0.928028         -0.870260  ...                        -0.138515   \n",
       "5         -0.940363         -0.870260  ...                        -0.742707   \n",
       "6         -0.910339         -0.867538  ...                         0.279795   \n",
       "7         -0.910015         -0.867538  ...                         0.700031   \n",
       "8         -0.913390         -0.866823  ...                         0.117163   \n",
       "9         -0.916439         -0.865776  ...                         2.014197   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.276399                    -0.360603   \n",
       "1                        -0.767990                     0.133011   \n",
       "2                        -0.438316                    -0.377840   \n",
       "3                         0.463155                    -0.135025   \n",
       "4                        -0.240313                     0.340406   \n",
       "5                        -0.713107                     0.219586   \n",
       "6                         0.197889                    -0.657546   \n",
       "7                         0.661908                    -0.087811   \n",
       "8                         0.170041                     0.012681   \n",
       "9                         2.489717                    -0.086925   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.062940                         -0.778427   \n",
       "1                             -0.021461                         -1.218805   \n",
       "2                              0.391976                          0.151207   \n",
       "3                             -0.033637                          1.037851   \n",
       "4                              0.268486                          1.125918   \n",
       "5                             -0.324856                          0.437830   \n",
       "6                             -0.519341                          0.009718   \n",
       "7                              1.320191                         -0.938078   \n",
       "8                              0.175674                         -0.399562   \n",
       "9                             -0.289813                         -0.808199   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.026080             -0.687219   \n",
       "1                              1.484470             -0.694138   \n",
       "2                              1.704201             -0.702239   \n",
       "3                             -1.003019             -0.701684   \n",
       "4                             -1.276282             -0.700152   \n",
       "5                             -0.757922             -0.703603   \n",
       "6                             -0.384001             -0.708525   \n",
       "7                              0.990421             -0.706310   \n",
       "8                              0.258981             -0.700359   \n",
       "9                             -0.135349             -0.700990   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  label  \n",
       "0              0.407946             -0.007568      5  \n",
       "1              0.409117              0.007875      5  \n",
       "2              0.410288              0.026502      5  \n",
       "3              0.414650              0.031714      5  \n",
       "4              0.425463              0.045225      5  \n",
       "5              0.424358              0.051552      5  \n",
       "6              0.415441              0.048386      5  \n",
       "7              0.420848              0.052091      5  \n",
       "8              0.438343              0.068615      5  \n",
       "9              0.442807              0.079173      5  \n",
       "\n",
       "[10 rows x 562 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(data = X_train, columns = new_df['column_name'].values)\n",
    "scaled_X_test = pd.DataFrame(data = X_test, columns = new_df['column_name'].values)\n",
    "scaled_X_train['label'] = y_train.values\n",
    "scaled_X_test['label'] = y_test.values\n",
    "\n",
    "X_train = scaled_X_train[scaled_X_train['label'] > 3]\n",
    "X_test = scaled_X_test[scaled_X_test['label'] > 3]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "scaled_X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "\n",
    "# The steps to take from one segment to the next; if this value is equal to TIME_PERIODS, then there is\n",
    "# no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label statistics::\n",
      "[[   1 1226]\n",
      " [   2 1073]\n",
      " [   3  986]\n",
      " [   4 1286]\n",
      " [   5 1374]\n",
      " [   6 1407]]\n",
      "Test data label statistics::\n",
      "[[  1 496]\n",
      " [  2 471]\n",
      " [  3 420]\n",
      " [  4 491]\n",
      " [  5 532]\n",
      " [  6 537]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print (\"Train data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  \n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print (\"Test data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4057, 10, 561) (4057, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 10\n",
    "STEP = 1\n",
    "\n",
    "X_train, y_train = create_dataset(X_train[new_df['column_name'].values], X_train.label, TIME_STEPS, STEP)\n",
    "X_test, y_test = create_dataset(X_test[new_df['column_name'].values], X_test.label, TIME_STEPS, STEP)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimtaeyoon/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# cnn model vary kernel size\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose,epochs,batch_size=1,10,32 \n",
    "\n",
    "n_timesteps,n_features,n_outputs=X_train.shape[1],X_train.shape[2],y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(Bidirectional(LSTM(units = 128, input_shape = [X_train.shape[1], X_train.shape[2]])))\n",
    "# model.add(Dropout(rate = 0.5))\n",
    "# model.add(Dense(units = 128, activation = \"relu\"))\n",
    "# model.add(Dense(y_train.shape[1], activation = \"softmax\"))\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4057, 10, 561)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                76032     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,131\n",
      "Trainable params: 76,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 4.9137e-05 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9975\n",
      "Epoch 2/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.2633e-05 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9975\n",
      "Epoch 3/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9992\n",
      "Epoch 4/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.3068e-06 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 0.9926\n",
      "Epoch 5/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0047 - acc: 0.9996 - val_loss: 0.1073 - val_acc: 0.9918\n",
      "Epoch 6/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0087 - acc: 0.9989 - val_loss: 0.0922 - val_acc: 0.9943\n",
      "Epoch 7/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.1804 - val_acc: 0.9901\n",
      "Epoch 8/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0131 - acc: 0.9993 - val_loss: 0.1043 - val_acc: 0.9934\n",
      "Epoch 9/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0798 - val_acc: 0.9943\n",
      "Epoch 10/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.3502e-06 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9934\n",
      "Epoch 11/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0112 - acc: 0.9993 - val_loss: 0.0302 - val_acc: 0.9967\n",
      "Epoch 12/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.8029e-04 - acc: 0.9996 - val_loss: 0.2588 - val_acc: 0.9877\n",
      "Epoch 13/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.8523e-04 - acc: 0.9996 - val_loss: 0.0117 - val_acc: 0.9992\n",
      "Epoch 14/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.1995 - val_acc: 0.9893\n",
      "Epoch 15/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0067 - acc: 0.9986 - val_loss: 0.0708 - val_acc: 0.9943\n",
      "Epoch 16/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0676 - val_acc: 0.9926\n",
      "Epoch 17/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 0.0264 - val_acc: 0.9959\n",
      "Epoch 18/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2661e-05 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9951\n",
      "Epoch 19/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 9.8700e-05 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9967\n",
      "Epoch 20/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0067 - acc: 0.9996 - val_loss: 0.0165 - val_acc: 0.9984\n",
      "Epoch 21/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0111 - val_acc: 0.9975\n",
      "Epoch 22/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2807e-04 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9959\n",
      "Epoch 23/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.0290 - val_acc: 0.9951\n",
      "Epoch 24/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0090 - acc: 0.9989 - val_loss: 0.0108 - val_acc: 0.9975\n",
      "Epoch 25/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.2417e-04 - acc: 0.9996 - val_loss: 0.0129 - val_acc: 0.9967\n",
      "Epoch 26/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.2466e-07 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 27/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 0.0084 - val_acc: 0.9967\n",
      "Epoch 28/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0134 - val_acc: 0.9975\n",
      "Epoch 29/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.9243e-05 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9967\n",
      "Epoch 30/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.8094e-07 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9926\n",
      "Epoch 31/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0704 - val_acc: 0.9926\n",
      "Epoch 32/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.3226 - val_acc: 0.9836\n",
      "Epoch 33/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 0.9993 - val_loss: 0.0615 - val_acc: 0.9959\n",
      "Epoch 34/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0061 - acc: 0.9993 - val_loss: 0.1865 - val_acc: 0.9910\n",
      "Epoch 35/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "Epoch 36/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.3354e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9975\n",
      "Epoch 37/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.9837e-04 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9967\n",
      "Epoch 38/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 9.8726e-05 - acc: 1.0000 - val_loss: 0.2094 - val_acc: 0.9885\n",
      "Epoch 39/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 0.9986 - val_loss: 0.0181 - val_acc: 0.9951\n",
      "Epoch 40/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.1740e-06 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9967\n",
      "Epoch 41/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 0.9986 - val_loss: 0.0489 - val_acc: 0.9934\n",
      "Epoch 42/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0423 - val_acc: 0.9959\n",
      "Epoch 43/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0441 - val_acc: 0.9951\n",
      "Epoch 44/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0130 - val_acc: 0.9975\n",
      "Epoch 45/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.9571e-04 - acc: 0.9993 - val_loss: 0.1660 - val_acc: 0.9893\n",
      "Epoch 46/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.6252e-06 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 0.9934\n",
      "Epoch 47/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "Epoch 48/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 3.2927e-04 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9869\n",
      "Epoch 49/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.6304e-05 - acc: 1.0000 - val_loss: 0.5444 - val_acc: 0.9787\n",
      "Epoch 50/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.9887e-04 - acc: 0.9996 - val_loss: 0.0357 - val_acc: 0.9967\n",
      "Epoch 51/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.4178 - val_acc: 0.9828\n",
      "Epoch 52/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0597 - val_acc: 0.9951\n",
      "Epoch 53/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0262 - val_acc: 0.9951\n",
      "Epoch 54/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.5119e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 55/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.4704 - val_acc: 0.9819\n",
      "Epoch 56/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0107 - acc: 0.9993 - val_loss: 0.0921 - val_acc: 0.9943\n",
      "Epoch 57/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0494 - val_acc: 0.9951\n",
      "Epoch 58/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.1552e-04 - acc: 0.9996 - val_loss: 0.0094 - val_acc: 0.9967\n",
      "Epoch 59/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0090 - acc: 0.9986 - val_loss: 0.0054 - val_acc: 0.9984\n",
      "Epoch 60/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0346 - val_acc: 0.9943\n",
      "Epoch 61/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1199 - val_acc: 0.9901\n",
      "Epoch 62/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.6771e-04 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9918\n",
      "Epoch 63/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0227 - val_acc: 0.9943\n",
      "Epoch 64/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0231 - val_acc: 0.9959\n",
      "Epoch 65/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1503 - val_acc: 0.9893\n",
      "Epoch 66/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0428 - val_acc: 0.9943\n",
      "Epoch 67/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 0.9989 - val_loss: 0.0912 - val_acc: 0.9934\n",
      "Epoch 68/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.0848e-04 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 0.9951\n",
      "Epoch 69/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.7135e-05 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9959\n",
      "Epoch 70/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0136 - val_acc: 0.9967\n",
      "Epoch 71/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.9072e-04 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9910\n",
      "Epoch 72/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.8180e-06 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9934\n",
      "Epoch 73/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0074 - acc: 0.9993 - val_loss: 0.1213 - val_acc: 0.9893\n",
      "Epoch 74/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9989 - val_loss: 0.0236 - val_acc: 0.9959\n",
      "Epoch 75/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 0.9989 - val_loss: 0.0503 - val_acc: 0.9943\n",
      "Epoch 76/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.3296e-06 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9869\n",
      "Epoch 77/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0135 - acc: 0.9996 - val_loss: 0.0656 - val_acc: 0.9918\n",
      "Epoch 78/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0242 - val_acc: 0.9943\n",
      "Epoch 79/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.9193e-06 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 0.9934\n",
      "Epoch 80/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0356 - val_acc: 0.9926\n",
      "Epoch 81/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.8369e-05 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 0.9910\n",
      "Epoch 82/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0140 - acc: 0.9986 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "Epoch 83/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.1601e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9901\n",
      "Epoch 84/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.4326e-06 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9934\n",
      "Epoch 85/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0109 - val_acc: 0.9984\n",
      "Epoch 86/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0297 - val_acc: 0.9951\n",
      "Epoch 87/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.8074e-04 - acc: 0.9996 - val_loss: 0.0771 - val_acc: 0.9934\n",
      "Epoch 88/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 9.5629e-07 - acc: 1.0000 - val_loss: 0.2219 - val_acc: 0.9869\n",
      "Epoch 89/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.0150 - val_acc: 0.9975\n",
      "Epoch 90/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0801 - val_acc: 0.9926\n",
      "Epoch 91/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0506 - val_acc: 0.9967\n",
      "Epoch 92/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.9128e-05 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 0.9901\n",
      "Epoch 93/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.3414e-05 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9975\n",
      "Epoch 94/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0488 - val_acc: 0.9959\n",
      "Epoch 95/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3070e-04 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 0.9959\n",
      "Epoch 96/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0151 - acc: 0.9986 - val_loss: 0.0133 - val_acc: 0.9959\n",
      "Epoch 97/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.2196e-05 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9951\n",
      "Epoch 98/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.8471e-07 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9959\n",
      "Epoch 99/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.0103e-06 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9967\n",
      "Epoch 100/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 5.7070e-05 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9901\n",
      "Epoch 101/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0066 - acc: 0.9993 - val_loss: 0.0403 - val_acc: 0.9959\n",
      "Epoch 102/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 6.2529e-06 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9967\n",
      "Epoch 103/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 6.5456e-05 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9951\n",
      "Epoch 104/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 3.5764e-05 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9877\n",
      "Epoch 105/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0056 - acc: 0.9989 - val_loss: 0.0328 - val_acc: 0.9959\n",
      "Epoch 106/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 8.6275e-07 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9992\n",
      "Epoch 107/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 9.0282e-06 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.9852\n",
      "Epoch 108/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 8.5382e-04 - acc: 0.9996 - val_loss: 0.0176 - val_acc: 0.9984\n",
      "Epoch 109/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0864 - val_acc: 0.9951\n",
      "Epoch 110/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.1125 - val_acc: 0.9943\n",
      "Epoch 111/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.0492e-04 - acc: 1.0000 - val_loss: 0.0670 - val_acc: 0.9959\n",
      "Epoch 112/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.1824e-05 - acc: 1.0000 - val_loss: 0.1131 - val_acc: 0.9910\n",
      "Epoch 113/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0287 - val_acc: 0.9975\n",
      "Epoch 114/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.3736e-05 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "Epoch 115/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.2177e-05 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9967\n",
      "Epoch 116/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6485e-04 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9975\n",
      "Epoch 117/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.0026e-05 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9967\n",
      "Epoch 118/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0451 - val_acc: 0.9967\n",
      "Epoch 119/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.0272e-04 - acc: 1.0000 - val_loss: 0.1762 - val_acc: 0.9918\n",
      "Epoch 120/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.0459e-06 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9951\n",
      "Epoch 121/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0483 - val_acc: 0.9926\n",
      "Epoch 122/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.1091 - val_acc: 0.9934\n",
      "Epoch 123/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.0257 - val_acc: 0.9959\n",
      "Epoch 124/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.0431 - val_acc: 0.9951\n",
      "Epoch 125/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0345 - val_acc: 0.9959\n",
      "Epoch 126/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.7451e-05 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9975\n",
      "Epoch 127/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 0.9993 - val_loss: 0.0482 - val_acc: 0.9975\n",
      "Epoch 128/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 2.5279e-06 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9975\n",
      "Epoch 129/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5254e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9984\n",
      "Epoch 130/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0998 - val_acc: 0.9926\n",
      "Epoch 131/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0012 - acc: 0.9993 - val_loss: 0.1046 - val_acc: 0.9918\n",
      "Epoch 132/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0105 - acc: 0.9996 - val_loss: 0.0571 - val_acc: 0.9959\n",
      "Epoch 133/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.9982e-06 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9959\n",
      "Epoch 134/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0036 - acc: 0.9993 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 135/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.2109e-04 - acc: 0.9996 - val_loss: 0.0597 - val_acc: 0.9951\n",
      "Epoch 136/500\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0469 - val_acc: 0.9951\n",
      "Epoch 137/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0065 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 138/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.0878e-06 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9984\n",
      "Epoch 139/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.3882e-04 - acc: 0.9996 - val_loss: 0.0960 - val_acc: 0.9926\n",
      "Epoch 140/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.2077e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9959\n",
      "Epoch 141/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 9.4758e-05 - acc: 1.0000 - val_loss: 0.1463 - val_acc: 0.9877\n",
      "Epoch 142/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.1058 - val_acc: 0.9934\n",
      "Epoch 143/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0174 - val_acc: 0.9975\n",
      "Epoch 144/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.1531 - val_acc: 0.9910\n",
      "Epoch 145/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3794e-04 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 0.9967\n",
      "Epoch 146/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0108 - acc: 0.9993 - val_loss: 0.0277 - val_acc: 0.9984\n",
      "Epoch 147/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0200 - acc: 0.9979 - val_loss: 0.0349 - val_acc: 0.9943\n",
      "Epoch 148/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0628 - val_acc: 0.9934\n",
      "Epoch 149/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0084 - val_acc: 0.9984\n",
      "Epoch 150/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0354 - val_acc: 0.9943\n",
      "Epoch 151/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.4794 - val_acc: 0.9770\n",
      "Epoch 152/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.2843 - val_acc: 0.9828\n",
      "Epoch 153/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.1452e-04 - acc: 0.9996 - val_loss: 0.4082 - val_acc: 0.9819\n",
      "Epoch 154/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0965 - val_acc: 0.9910\n",
      "Epoch 155/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 0.9993 - val_loss: 0.1231 - val_acc: 0.9918\n",
      "Epoch 156/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0696 - val_acc: 0.9943\n",
      "Epoch 157/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.8741e-05 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 0.9934\n",
      "Epoch 158/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.0716 - val_acc: 0.9934\n",
      "Epoch 159/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 2.8515e-06 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9943\n",
      "Epoch 160/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 3.1430e-04 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9959\n",
      "Epoch 161/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.9010e-06 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9943\n",
      "Epoch 162/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.8588e-07 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 0.9959\n",
      "Epoch 163/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5541e-04 - acc: 1.0000 - val_loss: 1.0044 - val_acc: 0.9631\n",
      "Epoch 164/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.0063 - val_acc: 0.9984\n",
      "Epoch 165/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.2973e-05 - acc: 1.0000 - val_loss: 0.4967 - val_acc: 0.9770\n",
      "Epoch 166/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.6257e-06 - acc: 1.0000 - val_loss: 0.4335 - val_acc: 0.9803\n",
      "Epoch 167/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2802e-04 - acc: 1.0000 - val_loss: 0.2154 - val_acc: 0.9901\n",
      "Epoch 168/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.4256e-05 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9943\n",
      "Epoch 169/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.9828e-05 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9959\n",
      "Epoch 170/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 9.5733e-08 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9943\n",
      "Epoch 171/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.9585e-04 - acc: 0.9996 - val_loss: 0.0039 - val_acc: 0.9984\n",
      "Epoch 172/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.0997e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9992\n",
      "Epoch 173/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0499 - val_acc: 0.9926\n",
      "Epoch 174/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.7903e-06 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 0.9951\n",
      "Epoch 175/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.9636e-05 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 0.9951\n",
      "Epoch 176/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.2105e-06 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9943\n",
      "Epoch 177/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.8421e-06 - acc: 1.0000 - val_loss: 0.1566 - val_acc: 0.9910\n",
      "Epoch 178/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.0088e-04 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9943\n",
      "Epoch 179/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.0012e-06 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9959\n",
      "Epoch 180/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 1.0115e-05 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9943\n",
      "Epoch 181/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.4773e-05 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9893\n",
      "Epoch 182/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.2486e-04 - acc: 0.9996 - val_loss: 0.0320 - val_acc: 0.9967\n",
      "Epoch 183/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.3940e-04 - acc: 0.9996 - val_loss: 0.2327 - val_acc: 0.9860\n",
      "Epoch 184/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.4349e-06 - acc: 1.0000 - val_loss: 0.2478 - val_acc: 0.9852\n",
      "Epoch 185/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "Epoch 186/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Epoch 187/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.2598e-07 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 188/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5982e-06 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9967\n",
      "Epoch 189/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.3738e-05 - acc: 1.0000 - val_loss: 0.1252 - val_acc: 0.9910\n",
      "Epoch 190/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.0474e-06 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9975\n",
      "Epoch 191/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.0834e-06 - acc: 1.0000 - val_loss: 0.1415 - val_acc: 0.9910\n",
      "Epoch 192/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5785e-05 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9975\n",
      "Epoch 193/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.4400e-05 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9992\n",
      "Epoch 194/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.4418e-08 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9975\n",
      "Epoch 195/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3014e-07 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 0.9975\n",
      "Epoch 196/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 0.9989 - val_loss: 0.0315 - val_acc: 0.9967\n",
      "Epoch 197/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.1544e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9967\n",
      "Epoch 198/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.3684e-05 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.9836\n",
      "Epoch 199/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.8472e-06 - acc: 1.0000 - val_loss: 0.3849 - val_acc: 0.9836\n",
      "Epoch 200/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4345e-05 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.9934\n",
      "Epoch 201/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0116 - acc: 0.9989 - val_loss: 0.0963 - val_acc: 0.9934\n",
      "Epoch 202/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.0129e-07 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9934\n",
      "Epoch 203/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.2631e-06 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.9885\n",
      "Epoch 204/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1034 - val_acc: 0.9943\n",
      "Epoch 205/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.2479 - val_acc: 0.9852\n",
      "Epoch 206/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.2772e-06 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9934\n",
      "Epoch 207/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 6.2385e-04 - acc: 0.9996 - val_loss: 0.1014 - val_acc: 0.9926\n",
      "Epoch 208/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.0929e-04 - acc: 0.9996 - val_loss: 0.0843 - val_acc: 0.9926\n",
      "Epoch 209/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3387e-07 - acc: 1.0000 - val_loss: 0.1446 - val_acc: 0.9926\n",
      "Epoch 210/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0062 - acc: 0.9993 - val_loss: 0.0680 - val_acc: 0.9951\n",
      "Epoch 211/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.9558e-05 - acc: 1.0000 - val_loss: 0.0608 - val_acc: 0.9943\n",
      "Epoch 212/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.4289e-04 - acc: 0.9996 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "Epoch 213/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3869e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9943\n",
      "Epoch 214/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.8619e-06 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9943\n",
      "Epoch 215/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.8724e-05 - acc: 1.0000 - val_loss: 0.4336 - val_acc: 0.9803\n",
      "Epoch 216/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.9325e-06 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 0.9926\n",
      "Epoch 217/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.9990e-06 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9918\n",
      "Epoch 218/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.7942e-05 - acc: 1.0000 - val_loss: 0.3756 - val_acc: 0.9852\n",
      "Epoch 219/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.2608e-07 - acc: 1.0000 - val_loss: 0.5189 - val_acc: 0.9844\n",
      "Epoch 220/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 3.1647e-05 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9934\n",
      "Epoch 221/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.6403e-07 - acc: 1.0000 - val_loss: 0.1964 - val_acc: 0.9943\n",
      "Epoch 222/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.1554e-04 - acc: 0.9996 - val_loss: 0.1589 - val_acc: 0.9918\n",
      "Epoch 223/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.0401e-05 - acc: 1.0000 - val_loss: 0.3567 - val_acc: 0.9836\n",
      "Epoch 224/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.7109e-07 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9959\n",
      "Epoch 225/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.4167e-06 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.9910\n",
      "Epoch 226/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 2.8870e-07 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9951\n",
      "Epoch 227/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.0810e-07 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 0.9926\n",
      "Epoch 228/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.2753e-07 - acc: 1.0000 - val_loss: 0.2685 - val_acc: 0.9893\n",
      "Epoch 229/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.5001e-04 - acc: 0.9996 - val_loss: 0.0306 - val_acc: 0.9959\n",
      "Epoch 230/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0014 - acc: 0.9993 - val_loss: 0.0767 - val_acc: 0.9943\n",
      "Epoch 231/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.4087e-07 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9951\n",
      "Epoch 232/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 3.1343e-04 - acc: 0.9996 - val_loss: 0.3302 - val_acc: 0.9877\n",
      "Epoch 233/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.6719e-04 - acc: 0.9996 - val_loss: 0.0613 - val_acc: 0.9943\n",
      "Epoch 234/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.3558e-07 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 0.9951\n",
      "Epoch 235/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 9.2291e-08 - acc: 1.0000 - val_loss: 0.2927 - val_acc: 0.9877\n",
      "Epoch 236/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "Epoch 237/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.2393e-04 - acc: 0.9996 - val_loss: 0.0041 - val_acc: 0.9984\n",
      "Epoch 238/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9992\n",
      "Epoch 239/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.1794e-06 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9975\n",
      "Epoch 240/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.0308e-06 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9984\n",
      "Epoch 241/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 5.1096e-07 - acc: 1.0000 - val_loss: 0.2543 - val_acc: 0.9901\n",
      "Epoch 242/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 5.7904e-06 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 0.9951\n",
      "Epoch 243/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.7206e-07 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9951\n",
      "Epoch 244/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.0187e-06 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9951\n",
      "Epoch 245/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 7.2065e-07 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9951\n",
      "Epoch 246/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0402 - val_acc: 0.9967\n",
      "Epoch 247/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0801 - val_acc: 0.9943\n",
      "Epoch 248/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.8921e-04 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 0.9967\n",
      "Epoch 249/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.9522e-07 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 0.9934\n",
      "Epoch 250/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.2372e-06 - acc: 1.0000 - val_loss: 0.3332 - val_acc: 0.9860\n",
      "Epoch 251/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1285e-06 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 0.9951\n",
      "Epoch 252/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.4653e-07 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 0.9943\n",
      "Epoch 253/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0427 - val_acc: 0.9975\n",
      "Epoch 254/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2032 - val_acc: 0.9910\n",
      "Epoch 255/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1411 - val_acc: 0.9918\n",
      "Epoch 256/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.5098 - val_acc: 0.9762\n",
      "Epoch 257/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.7659e-07 - acc: 1.0000 - val_loss: 0.2791 - val_acc: 0.9877\n",
      "Epoch 258/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.2344e-07 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9975\n",
      "Epoch 259/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.3120e-07 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9926\n",
      "Epoch 260/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.1729e-05 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9967\n",
      "Epoch 261/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.9878e-05 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9951\n",
      "Epoch 262/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.7831e-06 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9926\n",
      "Epoch 263/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.1908e-06 - acc: 1.0000 - val_loss: 0.1788 - val_acc: 0.9934\n",
      "Epoch 264/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0190 - val_acc: 0.9975\n",
      "Epoch 265/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.3043e-06 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 0.9975\n",
      "Epoch 266/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1358 - val_acc: 0.9926\n",
      "Epoch 267/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 2.4541e-05 - acc: 1.0000 - val_loss: 0.1335 - val_acc: 0.9934\n",
      "Epoch 268/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.0798e-04 - acc: 0.9996 - val_loss: 0.0851 - val_acc: 0.9934\n",
      "Epoch 269/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.9986 - val_loss: 0.0738 - val_acc: 0.9934\n",
      "Epoch 270/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.2046 - val_acc: 0.9893\n",
      "Epoch 271/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 2.1568e-07 - acc: 1.0000 - val_loss: 0.1928 - val_acc: 0.9893\n",
      "Epoch 272/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.7209e-08 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 0.9934\n",
      "Epoch 273/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.3876e-07 - acc: 1.0000 - val_loss: 0.1202 - val_acc: 0.9910\n",
      "Epoch 274/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0048 - acc: 0.9996 - val_loss: 0.2392 - val_acc: 0.9901\n",
      "Epoch 275/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 0.0261 - val_acc: 0.9975\n",
      "Epoch 276/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 5.0325e-06 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9984\n",
      "Epoch 277/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.1632e-05 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 0.9943\n",
      "Epoch 278/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.2882e-05 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9967\n",
      "Epoch 279/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0594 - val_acc: 0.9943\n",
      "Epoch 280/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 6.1840e-04 - acc: 0.9996 - val_loss: 0.3484 - val_acc: 0.9828\n",
      "Epoch 281/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 0.0034 - val_acc: 0.9992\n",
      "Epoch 282/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.9289e-04 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9984\n",
      "Epoch 283/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.0970e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9975\n",
      "Epoch 284/500\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 1.1925e-05 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9967\n",
      "Epoch 285/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 1.0399e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9992\n",
      "Epoch 286/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 3.2770e-04 - acc: 0.9996 - val_loss: 0.2669 - val_acc: 0.9852\n",
      "Epoch 287/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.0604e-04 - acc: 0.9996 - val_loss: 0.2037 - val_acc: 0.9901\n",
      "Epoch 288/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 3.1329e-07 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9885\n",
      "Epoch 289/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 3.1017e-07 - acc: 1.0000 - val_loss: 0.1840 - val_acc: 0.9885\n",
      "Epoch 290/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 6.2348e-04 - val_acc: 0.9992\n",
      "Epoch 291/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.3400e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9992\n",
      "Epoch 292/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.3507e-06 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 0.9918\n",
      "Epoch 293/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.8682e-07 - acc: 1.0000 - val_loss: 0.0458 - val_acc: 0.9959\n",
      "Epoch 294/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 2.7820e-06 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 0.9943\n",
      "Epoch 295/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.7627e-07 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9951\n",
      "Epoch 296/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.1345e-07 - acc: 1.0000 - val_loss: 0.1194 - val_acc: 0.9951\n",
      "Epoch 297/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 7.9395e-08 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 0.9943\n",
      "Epoch 298/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2950 - val_acc: 0.9885\n",
      "Epoch 299/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 6.9814e-07 - acc: 1.0000 - val_loss: 0.2711 - val_acc: 0.9901\n",
      "Epoch 300/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.2926e-08 - acc: 1.0000 - val_loss: 0.0718 - val_acc: 0.9959\n",
      "Epoch 301/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2302 - val_acc: 0.9877\n",
      "Epoch 302/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.0565e-06 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.9721\n",
      "Epoch 303/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 8.8771e-04 - acc: 0.9996 - val_loss: 0.0194 - val_acc: 0.9984\n",
      "Epoch 304/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 1.6051e-05 - acc: 1.0000 - val_loss: 0.3083 - val_acc: 0.9877\n",
      "Epoch 305/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1717 - val_acc: 0.9918\n",
      "Epoch 306/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0052 - acc: 0.9996 - val_loss: 0.1224 - val_acc: 0.9951\n",
      "Epoch 307/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.2320e-06 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9934\n",
      "Epoch 308/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5494e-08 - acc: 1.0000 - val_loss: 0.1426 - val_acc: 0.9934\n",
      "Epoch 309/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6428e-07 - acc: 1.0000 - val_loss: 0.3412 - val_acc: 0.9885\n",
      "Epoch 310/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.1986e-06 - acc: 1.0000 - val_loss: 0.1517 - val_acc: 0.9934\n",
      "Epoch 311/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.8622e-08 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9951\n",
      "Epoch 312/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.3283e-07 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9934\n",
      "Epoch 313/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.6493e-08 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 0.9918\n",
      "Epoch 314/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.0420e-06 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9959\n",
      "Epoch 315/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 7.9202e-05 - acc: 1.0000 - val_loss: 0.2645 - val_acc: 0.9910\n",
      "Epoch 316/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.1622e-07 - acc: 1.0000 - val_loss: 0.3042 - val_acc: 0.9901\n",
      "Epoch 317/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.8278e-06 - acc: 1.0000 - val_loss: 0.2813 - val_acc: 0.9901\n",
      "Epoch 318/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.7344e-05 - acc: 1.0000 - val_loss: 0.1475 - val_acc: 0.9934\n",
      "Epoch 319/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.3409e-05 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9918\n",
      "Epoch 320/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 8.1973e-07 - acc: 1.0000 - val_loss: 0.3310 - val_acc: 0.9901\n",
      "Epoch 321/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0150 - acc: 0.9989 - val_loss: 0.2627 - val_acc: 0.9877\n",
      "Epoch 322/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 9.1183e-07 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9885\n",
      "Epoch 323/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.4169 - val_acc: 0.9811\n",
      "Epoch 324/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.4329e-06 - acc: 1.0000 - val_loss: 0.4043 - val_acc: 0.9844\n",
      "Epoch 325/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.2092e-06 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.9795\n",
      "Epoch 326/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.6825e-05 - acc: 1.0000 - val_loss: 0.3684 - val_acc: 0.9852\n",
      "Epoch 327/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 3.8014e-07 - acc: 1.0000 - val_loss: 0.3485 - val_acc: 0.9869\n",
      "Epoch 328/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.9570e-07 - acc: 1.0000 - val_loss: 0.1225 - val_acc: 0.9943\n",
      "Epoch 329/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 9.0910e-07 - acc: 1.0000 - val_loss: 0.3193 - val_acc: 0.9893\n",
      "Epoch 330/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.3581e-07 - acc: 1.0000 - val_loss: 0.4186 - val_acc: 0.9869\n",
      "Epoch 331/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.4246 - val_acc: 0.9869\n",
      "Epoch 332/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.0267e-06 - acc: 1.0000 - val_loss: 0.2813 - val_acc: 0.9877\n",
      "Epoch 333/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.5076e-05 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9926\n",
      "Epoch 334/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 5.1997e-06 - acc: 1.0000 - val_loss: 0.0612 - val_acc: 0.9951\n",
      "Epoch 335/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.5904e-06 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9959\n",
      "Epoch 336/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0658 - val_acc: 0.9959\n",
      "Epoch 337/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0901 - val_acc: 0.9934\n",
      "Epoch 338/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 8.1686e-06 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9967\n",
      "Epoch 339/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.7657e-05 - acc: 1.0000 - val_loss: 0.0763 - val_acc: 0.9959\n",
      "Epoch 340/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 0.2742 - val_acc: 0.9918\n",
      "Epoch 341/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.7360e-05 - acc: 1.0000 - val_loss: 0.2852 - val_acc: 0.9926\n",
      "Epoch 342/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.2476 - val_acc: 0.9926\n",
      "Epoch 343/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6311e-06 - acc: 1.0000 - val_loss: 0.2839 - val_acc: 0.9910\n",
      "Epoch 344/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.1906e-05 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 0.9910\n",
      "Epoch 345/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.2974e-07 - acc: 1.0000 - val_loss: 0.3839 - val_acc: 0.9860\n",
      "Epoch 346/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.1663e-06 - acc: 1.0000 - val_loss: 0.1766 - val_acc: 0.9934\n",
      "Epoch 347/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.9986 - val_loss: 0.2471 - val_acc: 0.9893\n",
      "Epoch 348/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.2595e-04 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 0.9910\n",
      "Epoch 349/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.5005e-06 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.9893\n",
      "Epoch 350/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 3.5629e-05 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9951\n",
      "Epoch 351/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 9.8280e-05 - acc: 1.0000 - val_loss: 0.3566 - val_acc: 0.9860\n",
      "Epoch 352/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.1544e-05 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9951\n",
      "Epoch 353/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.3854e-04 - acc: 1.0000 - val_loss: 0.1058 - val_acc: 0.9926\n",
      "Epoch 354/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0105 - acc: 0.9993 - val_loss: 0.1564 - val_acc: 0.9918\n",
      "Epoch 355/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.7154e-05 - acc: 1.0000 - val_loss: 0.0995 - val_acc: 0.9959\n",
      "Epoch 356/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.3722 - val_acc: 0.9836\n",
      "Epoch 357/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.1216e-05 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 0.9885\n",
      "Epoch 358/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.3386e-04 - acc: 0.9996 - val_loss: 0.0538 - val_acc: 0.9943\n",
      "Epoch 359/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.3407e-05 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9967\n",
      "Epoch 360/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.4344e-06 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9959\n",
      "Epoch 361/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.2151 - val_acc: 0.9877\n",
      "Epoch 362/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.5930e-04 - acc: 0.9996 - val_loss: 0.0253 - val_acc: 0.9959\n",
      "Epoch 363/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1075 - val_acc: 0.9943\n",
      "Epoch 364/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.4375e-05 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 0.9959\n",
      "Epoch 365/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.1887e-04 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9869\n",
      "Epoch 366/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 3.6708e-07 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9852\n",
      "Epoch 367/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.3104e-04 - acc: 0.9996 - val_loss: 0.1148 - val_acc: 0.9926\n",
      "Epoch 368/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 5.4879e-08 - acc: 1.0000 - val_loss: 0.1292 - val_acc: 0.9910\n",
      "Epoch 369/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.1021e-07 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 0.9910\n",
      "Epoch 370/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.1421e-06 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 0.9959\n",
      "Epoch 371/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 8.5446e-06 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 0.9934\n",
      "Epoch 372/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 8.6898e-07 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9877\n",
      "Epoch 373/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0660 - val_acc: 0.9926\n",
      "Epoch 374/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.1704e-07 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9943\n",
      "Epoch 375/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.1028e-05 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9975\n",
      "Epoch 376/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.0376 - val_acc: 0.9951\n",
      "Epoch 377/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.0980e-06 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 0.9926\n",
      "Epoch 378/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0698 - val_acc: 0.9943\n",
      "Epoch 379/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.4414e-04 - acc: 0.9996 - val_loss: 0.1634 - val_acc: 0.9901\n",
      "Epoch 380/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.5838 - val_acc: 0.9787\n",
      "Epoch 381/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.0522e-05 - acc: 1.0000 - val_loss: 0.4847 - val_acc: 0.9811\n",
      "Epoch 382/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 3.8740e-07 - acc: 1.0000 - val_loss: 0.4810 - val_acc: 0.9795\n",
      "Epoch 383/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 5.0252e-05 - acc: 1.0000 - val_loss: 0.1992 - val_acc: 0.9943\n",
      "Epoch 384/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.1125 - val_acc: 0.9926\n",
      "Epoch 385/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.3017e-04 - acc: 0.9996 - val_loss: 0.0832 - val_acc: 0.9934\n",
      "Epoch 386/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.3919e-05 - acc: 1.0000 - val_loss: 0.3622 - val_acc: 0.9836\n",
      "Epoch 387/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0970 - val_acc: 0.9934\n",
      "Epoch 388/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.7522e-06 - acc: 1.0000 - val_loss: 0.1310 - val_acc: 0.9910\n",
      "Epoch 389/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.6170e-06 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9959\n",
      "Epoch 390/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0096 - val_acc: 0.9984\n",
      "Epoch 391/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0070 - acc: 0.9996 - val_loss: 0.0141 - val_acc: 0.9967\n",
      "Epoch 392/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 8.3832e-07 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9967\n",
      "Epoch 393/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.3130e-08 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9975\n",
      "Epoch 394/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.3402e-07 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9975\n",
      "Epoch 395/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.0831e-04 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9967\n",
      "Epoch 396/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0941 - val_acc: 0.9926\n",
      "Epoch 397/500\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 0.0144 - acc: 0.9993 - val_loss: 0.0139 - val_acc: 0.9992\n",
      "Epoch 398/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 8.5738e-04 - acc: 0.9996 - val_loss: 0.3472 - val_acc: 0.9828\n",
      "Epoch 399/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0010 - acc: 0.9993 - val_loss: 0.0161 - val_acc: 0.9984\n",
      "Epoch 400/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.5209e-08 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9975\n",
      "Epoch 401/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 4.3597e-05 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 0.9967\n",
      "Epoch 402/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 1.2269e-04 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 0.9984\n",
      "Epoch 403/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.6928e-04 - acc: 0.9996 - val_loss: 0.2372 - val_acc: 0.9828\n",
      "Epoch 404/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0061 - acc: 0.9989 - val_loss: 0.0973 - val_acc: 0.9959\n",
      "Epoch 405/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 1.0790e-04 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9943\n",
      "Epoch 406/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.2374 - val_acc: 0.9877\n",
      "Epoch 407/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0217 - val_acc: 0.9992\n",
      "Epoch 408/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0043 - acc: 0.9993 - val_loss: 0.0077 - val_acc: 0.9992\n",
      "Epoch 409/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.4286e-05 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9943\n",
      "Epoch 410/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0277 - val_acc: 0.9943\n",
      "Epoch 411/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0100 - acc: 0.9989 - val_loss: 0.0735 - val_acc: 0.9926\n",
      "Epoch 412/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0063 - acc: 0.9993 - val_loss: 0.0365 - val_acc: 0.9943\n",
      "Epoch 413/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0047 - acc: 0.9996 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 414/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0062 - acc: 0.9989 - val_loss: 0.0205 - val_acc: 0.9975\n",
      "Epoch 415/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.1196 - val_acc: 0.9910\n",
      "Epoch 416/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "Epoch 417/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0031 - val_acc: 0.9984\n",
      "Epoch 418/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 1.1728e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9967\n",
      "Epoch 419/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1589 - val_acc: 0.9893\n",
      "Epoch 420/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0046 - acc: 0.9993 - val_loss: 0.6247 - val_acc: 0.9729\n",
      "Epoch 421/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.9996 - val_loss: 0.0900 - val_acc: 0.9934\n",
      "Epoch 422/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6558e-06 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9926\n",
      "Epoch 423/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0024 - acc: 0.9996 - val_loss: 0.0181 - val_acc: 0.9975\n",
      "Epoch 424/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0054 - acc: 0.9989 - val_loss: 0.0260 - val_acc: 0.9959\n",
      "Epoch 425/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.1914e-04 - acc: 0.9996 - val_loss: 0.0125 - val_acc: 0.9992\n",
      "Epoch 426/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 5.1794e-07 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 0.9943\n",
      "Epoch 427/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.5018e-04 - acc: 0.9996 - val_loss: 0.0092 - val_acc: 0.9967\n",
      "Epoch 428/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0506 - val_acc: 0.9975\n",
      "Epoch 429/500\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.9938e-04 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9984\n",
      "Epoch 430/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0349 - val_acc: 0.9984\n",
      "Epoch 431/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.9131e-05 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9984\n",
      "Epoch 432/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 4.9740e-07 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9943\n",
      "Epoch 433/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 4.1166e-05 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9951\n",
      "Epoch 434/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6626e-06 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9959\n",
      "Epoch 435/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.0509e-07 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 0.9967\n",
      "Epoch 436/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 8.2997e-06 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 0.9926\n",
      "Epoch 437/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 9.3524e-04 - acc: 0.9993 - val_loss: 0.0380 - val_acc: 0.9975\n",
      "Epoch 438/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.6244e-05 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9967\n",
      "Epoch 439/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.3006 - val_acc: 0.9860\n",
      "Epoch 440/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.8062e-04 - acc: 0.9996 - val_loss: 0.0545 - val_acc: 0.9959\n",
      "Epoch 441/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 7.2731e-05 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9967\n",
      "Epoch 442/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.5268e-04 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9967\n",
      "Epoch 443/500\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 4.4217e-06 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9926\n",
      "Epoch 444/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 2.8513e-06 - acc: 1.0000 - val_loss: 0.1656 - val_acc: 0.9910\n",
      "Epoch 445/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.4557e-06 - acc: 1.0000 - val_loss: 0.2235 - val_acc: 0.9901\n",
      "Epoch 446/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.5377e-05 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 0.9951\n",
      "Epoch 447/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 7.4046e-04 - acc: 0.9996 - val_loss: 0.0382 - val_acc: 0.9951\n",
      "Epoch 448/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2224 - val_acc: 0.9877\n",
      "Epoch 449/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.5777e-07 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.9885\n",
      "Epoch 450/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0306 - val_acc: 0.9984\n",
      "Epoch 451/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1171 - val_acc: 0.9943\n",
      "Epoch 452/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 0.3565 - val_acc: 0.9844\n",
      "Epoch 453/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0577 - val_acc: 0.9959\n",
      "Epoch 454/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0010 - acc: 0.9993 - val_loss: 0.7016 - val_acc: 0.9721\n",
      "Epoch 455/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.3175e-05 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.9770\n",
      "Epoch 456/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 1.6434e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 0.9959\n",
      "Epoch 457/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.1432e-06 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9975\n",
      "Epoch 458/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.2381e-05 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.9828\n",
      "Epoch 459/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.4413 - val_acc: 0.9836\n",
      "Epoch 460/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.8977e-05 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 0.9967\n",
      "Epoch 461/500\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 2.3627e-06 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9951\n",
      "Epoch 462/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.6954e-05 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9934\n",
      "Epoch 463/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 6.2396e-08 - acc: 1.0000 - val_loss: 0.0975 - val_acc: 0.9934\n",
      "Epoch 464/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.4802e-08 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9893\n",
      "Epoch 465/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 4.5101e-06 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.9803\n",
      "Epoch 466/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.2675e-07 - acc: 1.0000 - val_loss: 0.4826 - val_acc: 0.9762\n",
      "Epoch 467/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.6611e-07 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9943\n",
      "Epoch 468/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 1.1608e-06 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 0.9910\n",
      "Epoch 469/500\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 2.3653e-06 - acc: 1.0000 - val_loss: 0.1246 - val_acc: 0.9943\n",
      "Epoch 470/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.1546e-07 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 0.9975\n",
      "Epoch 471/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.7260e-07 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.9910\n",
      "Epoch 472/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.1596e-08 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9910\n",
      "Epoch 473/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.5447e-07 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9943\n",
      "Epoch 474/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.3389e-06 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9967\n",
      "Epoch 475/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 7.0934e-07 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9967\n",
      "Epoch 476/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.0953e-06 - acc: 1.0000 - val_loss: 0.8131 - val_acc: 0.9729\n",
      "Epoch 477/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.6835 - val_acc: 0.9795\n",
      "Epoch 478/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.2437e-08 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 0.9795\n",
      "Epoch 479/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 1.6864e-05 - acc: 1.0000 - val_loss: 0.3911 - val_acc: 0.9860\n",
      "Epoch 480/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 5.9188e-04 - acc: 0.9996 - val_loss: 0.0731 - val_acc: 0.9943\n",
      "Epoch 481/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.2953e-04 - acc: 0.9996 - val_loss: 0.3374 - val_acc: 0.9852\n",
      "Epoch 482/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1829 - val_acc: 0.9910\n",
      "Epoch 483/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.8687e-05 - acc: 1.0000 - val_loss: 0.2396 - val_acc: 0.9893\n",
      "Epoch 484/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.6076e-04 - acc: 0.9996 - val_loss: 0.1377 - val_acc: 0.9926\n",
      "Epoch 485/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 9.9750e-04 - acc: 0.9996 - val_loss: 0.3884 - val_acc: 0.9860\n",
      "Epoch 486/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 6.8728e-04 - acc: 0.9996 - val_loss: 0.1833 - val_acc: 0.9885\n",
      "Epoch 487/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.7947e-05 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9943\n",
      "Epoch 488/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 8.2473e-06 - acc: 1.0000 - val_loss: 0.2817 - val_acc: 0.9901\n",
      "Epoch 489/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.7360e-04 - acc: 1.0000 - val_loss: 0.5330 - val_acc: 0.9828\n",
      "Epoch 490/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.0027e-07 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9926\n",
      "Epoch 491/500\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.9160 - val_acc: 0.9745\n",
      "Epoch 492/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.5000 - val_acc: 0.9869\n",
      "Epoch 493/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 7.0340e-05 - acc: 1.0000 - val_loss: 0.2526 - val_acc: 0.9893\n",
      "Epoch 494/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 0.0137 - acc: 0.9996 - val_loss: 0.1193 - val_acc: 0.9934\n",
      "Epoch 495/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 2.2850e-07 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9918\n",
      "Epoch 496/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 2.5489e-04 - acc: 0.9996 - val_loss: 0.0909 - val_acc: 0.9926\n",
      "Epoch 497/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 1.8810e-06 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9918\n",
      "Epoch 498/500\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2512 - val_acc: 0.9877\n",
      "Epoch 499/500\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.2429 - val_acc: 0.9918\n",
      "Epoch 500/500\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 6.0613e-07 - acc: 1.0000 - val_loss: 0.2546 - val_acc: 0.9901\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 500, batch_size = 32, validation_split = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "x = np.arange(0, 500)\n",
    "plt.plot(x, acc, 'y', label='Training acc')\n",
    "plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 892us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 783us/step\n",
      "Confusion Matrix\n",
      "[[452   7  36   1   0   0]\n",
      " [  1 467   1   1   0   0]\n",
      " [  2  18 400   0   0   0]\n",
      " [  0   2   0 436  52   1]\n",
      " [  0   0   0  32 500   0]\n",
      " [  0   0   0   0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "y_test_arg=np.argmax(y_test,axis=1)\n",
    "Y_pred = np.argmax(model.predict(X_test),axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test_arg, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 994us/step - loss: 0.6593 - acc: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.659272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.659272\n",
       "1  0.947726"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "pd.DataFrame(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
