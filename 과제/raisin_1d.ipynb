{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>83248</td>\n",
       "      <td>430.077308</td>\n",
       "      <td>247.838695</td>\n",
       "      <td>0.817263</td>\n",
       "      <td>85839</td>\n",
       "      <td>0.668793</td>\n",
       "      <td>1129.072</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>87350</td>\n",
       "      <td>440.735698</td>\n",
       "      <td>259.293149</td>\n",
       "      <td>0.808629</td>\n",
       "      <td>90899</td>\n",
       "      <td>0.636476</td>\n",
       "      <td>1214.252</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>99657</td>\n",
       "      <td>431.706981</td>\n",
       "      <td>298.837323</td>\n",
       "      <td>0.721684</td>\n",
       "      <td>106264</td>\n",
       "      <td>0.741099</td>\n",
       "      <td>1292.828</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>93523</td>\n",
       "      <td>476.344094</td>\n",
       "      <td>254.176054</td>\n",
       "      <td>0.845739</td>\n",
       "      <td>97653</td>\n",
       "      <td>0.658798</td>\n",
       "      <td>1258.548</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>85609</td>\n",
       "      <td>512.081774</td>\n",
       "      <td>215.271976</td>\n",
       "      <td>0.907345</td>\n",
       "      <td>89197</td>\n",
       "      <td>0.632020</td>\n",
       "      <td>1272.862</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0    87524       442.246011       253.291155      0.819738       90546   \n",
       "1    75166       406.690687       243.032436      0.801805       78789   \n",
       "2    90856       442.267048       266.328318      0.798354       93717   \n",
       "3    45928       286.540559       208.760042      0.684989       47336   \n",
       "4    79408       352.190770       290.827533      0.564011       81463   \n",
       "..     ...              ...              ...           ...         ...   \n",
       "895  83248       430.077308       247.838695      0.817263       85839   \n",
       "896  87350       440.735698       259.293149      0.808629       90899   \n",
       "897  99657       431.706981       298.837323      0.721684      106264   \n",
       "898  93523       476.344094       254.176054      0.845739       97653   \n",
       "899  85609       512.081774       215.271976      0.907345       89197   \n",
       "\n",
       "       Extent  Perimeter    Class  \n",
       "0    0.758651   1184.040  Kecimen  \n",
       "1    0.684130   1121.786  Kecimen  \n",
       "2    0.637613   1208.575  Kecimen  \n",
       "3    0.699599    844.162  Kecimen  \n",
       "4    0.792772   1073.251  Kecimen  \n",
       "..        ...        ...      ...  \n",
       "895  0.668793   1129.072    Besni  \n",
       "896  0.636476   1214.252    Besni  \n",
       "897  0.741099   1292.828    Besni  \n",
       "898  0.658798   1258.548    Besni  \n",
       "899  0.632020   1272.862    Besni  \n",
       "\n",
       "[900 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./Raisin_Dataset.xlsx')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kecimen    450\n",
       "Besni      450\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Besni</th>\n",
       "      <th>Kecimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Besni  Kecimen\n",
       "0        0        1\n",
       "1        0        1\n",
       "2        0        1\n",
       "3        0        1\n",
       "4        0        1\n",
       "..     ...      ...\n",
       "895      1        0\n",
       "896      1        0\n",
       "897      1        0\n",
       "898      1        0\n",
       "899      1        0\n",
       "\n",
       "[900 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "X = df.iloc[:,:7]\n",
    "\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 64)             256       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                16050     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,408\n",
      "Trainable params: 16,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(input_shape=(X_train.shape[1], 1), filters=64, activation='relu', kernel_size=3),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 7ms/step - loss: 1181.1647 - accuracy: 0.4785 - val_loss: 421.6700 - val_accuracy: 0.4667\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 346.8654 - accuracy: 0.5200 - val_loss: 121.0193 - val_accuracy: 0.4667\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 95.9816 - accuracy: 0.5348 - val_loss: 339.5459 - val_accuracy: 0.4667\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 210.8298 - accuracy: 0.4741 - val_loss: 351.3221 - val_accuracy: 0.8311\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 293.2160 - accuracy: 0.5126 - val_loss: 319.1688 - val_accuracy: 0.4667\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 204.3640 - accuracy: 0.5422 - val_loss: 329.8453 - val_accuracy: 0.5333\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 220.4892 - accuracy: 0.5111 - val_loss: 535.6978 - val_accuracy: 0.4667\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 260.4743 - accuracy: 0.5185 - val_loss: 140.0734 - val_accuracy: 0.5156\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 227.1974 - accuracy: 0.5511 - val_loss: 236.1918 - val_accuracy: 0.5333\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 141.1838 - accuracy: 0.5437 - val_loss: 289.4307 - val_accuracy: 0.4667\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 235.1905 - accuracy: 0.5304 - val_loss: 203.1891 - val_accuracy: 0.5333\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 219.1548 - accuracy: 0.5319 - val_loss: 285.6646 - val_accuracy: 0.5333\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 218.0419 - accuracy: 0.5052 - val_loss: 109.9351 - val_accuracy: 0.4667\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 174.1990 - accuracy: 0.5333 - val_loss: 295.9974 - val_accuracy: 0.4667\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 110.5926 - accuracy: 0.5852 - val_loss: 42.0327 - val_accuracy: 0.5111\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 68.2100 - accuracy: 0.6370 - val_loss: 92.6433 - val_accuracy: 0.5333\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 169.3095 - accuracy: 0.5393 - val_loss: 193.7506 - val_accuracy: 0.4667\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 148.3823 - accuracy: 0.5230 - val_loss: 111.3346 - val_accuracy: 0.5333\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 86.9665 - accuracy: 0.5793 - val_loss: 91.4298 - val_accuracy: 0.8400\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 62.3441 - accuracy: 0.6889 - val_loss: 183.6040 - val_accuracy: 0.4667\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 71.7414 - accuracy: 0.6074 - val_loss: 193.6863 - val_accuracy: 0.5333\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 148.4380 - accuracy: 0.5556 - val_loss: 186.6308 - val_accuracy: 0.4667\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 124.2361 - accuracy: 0.5807 - val_loss: 179.2381 - val_accuracy: 0.6133\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 85.7553 - accuracy: 0.6622 - val_loss: 233.7077 - val_accuracy: 0.4667\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 194.4843 - accuracy: 0.5215 - val_loss: 334.7685 - val_accuracy: 0.4667\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 372.9304 - accuracy: 0.5393 - val_loss: 664.1050 - val_accuracy: 0.4667\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 355.7858 - accuracy: 0.5081 - val_loss: 192.4800 - val_accuracy: 0.4711\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 198.7646 - accuracy: 0.5407 - val_loss: 386.2505 - val_accuracy: 0.4667\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 136.5325 - accuracy: 0.6059 - val_loss: 155.2133 - val_accuracy: 0.8444\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 55.3015 - accuracy: 0.6815 - val_loss: 78.0971 - val_accuracy: 0.5067\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 98.1697 - accuracy: 0.5541 - val_loss: 150.8657 - val_accuracy: 0.4667\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.2246 - accuracy: 0.6741 - val_loss: 13.7374 - val_accuracy: 0.8356\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.0418 - accuracy: 0.8104 - val_loss: 39.7816 - val_accuracy: 0.7467\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.1962 - accuracy: 0.7437 - val_loss: 104.7832 - val_accuracy: 0.4889\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.7323 - accuracy: 0.6815 - val_loss: 52.1541 - val_accuracy: 0.5733\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.9952 - accuracy: 0.7304 - val_loss: 12.5311 - val_accuracy: 0.8178\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.4791 - accuracy: 0.7689 - val_loss: 65.2003 - val_accuracy: 0.5689\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.1707 - accuracy: 0.6815 - val_loss: 23.6058 - val_accuracy: 0.8356\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.2579 - accuracy: 0.7170 - val_loss: 49.1876 - val_accuracy: 0.5822\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 91.6250 - accuracy: 0.5659 - val_loss: 42.5393 - val_accuracy: 0.6089\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.7936 - accuracy: 0.7244 - val_loss: 54.2067 - val_accuracy: 0.5600\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 51.9226 - accuracy: 0.6415 - val_loss: 16.5580 - val_accuracy: 0.8578\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.2609 - accuracy: 0.6593 - val_loss: 212.3490 - val_accuracy: 0.5378\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2519 - accuracy: 0.5570 - val_loss: 31.7960 - val_accuracy: 0.7467\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.7432 - accuracy: 0.6874 - val_loss: 49.4248 - val_accuracy: 0.5867\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 43.1983 - accuracy: 0.6667 - val_loss: 128.8843 - val_accuracy: 0.4800\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 48.3959 - accuracy: 0.6800 - val_loss: 43.2771 - val_accuracy: 0.6578\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.5955 - accuracy: 0.7585 - val_loss: 18.5621 - val_accuracy: 0.8711\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.5498 - accuracy: 0.7763 - val_loss: 195.1329 - val_accuracy: 0.5378\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 75.2081 - accuracy: 0.6207 - val_loss: 190.1596 - val_accuracy: 0.5333\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 66.4466 - accuracy: 0.6459 - val_loss: 42.6626 - val_accuracy: 0.8578\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.7534 - accuracy: 0.7763 - val_loss: 21.1595 - val_accuracy: 0.8356\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.3025 - accuracy: 0.7719 - val_loss: 49.5513 - val_accuracy: 0.5867\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 62.3839 - accuracy: 0.6207 - val_loss: 56.3321 - val_accuracy: 0.6356\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 60.8590 - accuracy: 0.6207 - val_loss: 76.3953 - val_accuracy: 0.5156\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 92.8456 - accuracy: 0.5778 - val_loss: 27.7463 - val_accuracy: 0.6978\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.3285 - accuracy: 0.7274 - val_loss: 25.7762 - val_accuracy: 0.7200\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.4804 - accuracy: 0.7659 - val_loss: 19.2652 - val_accuracy: 0.7689\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.6442 - accuracy: 0.8015 - val_loss: 11.2327 - val_accuracy: 0.8622\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.5436 - accuracy: 0.6948 - val_loss: 26.9691 - val_accuracy: 0.7200\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.1272 - accuracy: 0.7363 - val_loss: 22.6491 - val_accuracy: 0.7200\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.9659 - accuracy: 0.7452 - val_loss: 160.5257 - val_accuracy: 0.5333\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 123.7449 - accuracy: 0.5452 - val_loss: 28.9206 - val_accuracy: 0.8311\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.4324 - accuracy: 0.7259 - val_loss: 10.1267 - val_accuracy: 0.8578\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.2289 - accuracy: 0.7644 - val_loss: 96.9254 - val_accuracy: 0.5333\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 47.7103 - accuracy: 0.6696 - val_loss: 11.6957 - val_accuracy: 0.8711\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.4647 - accuracy: 0.8193 - val_loss: 11.3778 - val_accuracy: 0.8800\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.9871 - accuracy: 0.7630 - val_loss: 34.6641 - val_accuracy: 0.6533\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.5021 - accuracy: 0.7807 - val_loss: 50.7883 - val_accuracy: 0.5867\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 40.5557 - accuracy: 0.6756 - val_loss: 41.2157 - val_accuracy: 0.6578\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36.6256 - accuracy: 0.6726 - val_loss: 75.0870 - val_accuracy: 0.5556\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 47.4991 - accuracy: 0.6756 - val_loss: 50.4493 - val_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 48.7106 - accuracy: 0.7007 - val_loss: 26.5849 - val_accuracy: 0.8311\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.7239 - accuracy: 0.7674 - val_loss: 21.7020 - val_accuracy: 0.7867\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 34.0799 - accuracy: 0.7170 - val_loss: 14.3649 - val_accuracy: 0.8800\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.0864 - accuracy: 0.7852 - val_loss: 32.3542 - val_accuracy: 0.6889\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 46.2403 - accuracy: 0.6578 - val_loss: 92.4409 - val_accuracy: 0.5111\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 42.0907 - accuracy: 0.7274 - val_loss: 35.4702 - val_accuracy: 0.7067\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.1404 - accuracy: 0.7630 - val_loss: 53.5158 - val_accuracy: 0.5911\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.4459 - accuracy: 0.7156 - val_loss: 91.1040 - val_accuracy: 0.5422\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 79.6977 - accuracy: 0.6015 - val_loss: 218.8184 - val_accuracy: 0.5378\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 80.4925 - accuracy: 0.6415 - val_loss: 35.5184 - val_accuracy: 0.6889\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.5681 - accuracy: 0.7659 - val_loss: 91.9651 - val_accuracy: 0.5378\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 97.0932 - accuracy: 0.6296 - val_loss: 15.8278 - val_accuracy: 0.8578\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.3422 - accuracy: 0.8193 - val_loss: 11.0955 - val_accuracy: 0.8578\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.7752 - accuracy: 0.7674 - val_loss: 11.5435 - val_accuracy: 0.8756\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.7356 - accuracy: 0.8237 - val_loss: 24.3327 - val_accuracy: 0.7600\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.6656 - accuracy: 0.8104 - val_loss: 76.7342 - val_accuracy: 0.5644\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.2161 - accuracy: 0.7081 - val_loss: 16.2515 - val_accuracy: 0.8356\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.8389 - accuracy: 0.7022 - val_loss: 92.3151 - val_accuracy: 0.5422\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 70.6093 - accuracy: 0.6489 - val_loss: 111.6127 - val_accuracy: 0.5333\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 69.6146 - accuracy: 0.6296 - val_loss: 23.9314 - val_accuracy: 0.8800\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30.0040 - accuracy: 0.7600 - val_loss: 46.9067 - val_accuracy: 0.6444\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.2314 - accuracy: 0.7481 - val_loss: 15.0281 - val_accuracy: 0.8622\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.3524 - accuracy: 0.8222 - val_loss: 13.1523 - val_accuracy: 0.8578\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8375 - accuracy: 0.8252 - val_loss: 15.4632 - val_accuracy: 0.8711\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.6568 - accuracy: 0.7867 - val_loss: 62.2608 - val_accuracy: 0.5778\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.3644 - accuracy: 0.7585 - val_loss: 32.6463 - val_accuracy: 0.6978\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.2953 - accuracy: 0.7541 - val_loss: 78.6010 - val_accuracy: 0.5289\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 33.5670 - accuracy: 0.7022 - val_loss: 27.8341 - val_accuracy: 0.7067\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.5995 - accuracy: 0.8059 - val_loss: 14.0883 - val_accuracy: 0.8800\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.2344 - accuracy: 0.7689 - val_loss: 46.7317 - val_accuracy: 0.6222\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.3395 - accuracy: 0.7837 - val_loss: 13.3713 - val_accuracy: 0.8578\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.1635 - accuracy: 0.7585 - val_loss: 21.3000 - val_accuracy: 0.7911\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.0242 - accuracy: 0.7052 - val_loss: 36.0993 - val_accuracy: 0.6756\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.3845 - accuracy: 0.7837 - val_loss: 24.2508 - val_accuracy: 0.7644\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.6267 - accuracy: 0.7881 - val_loss: 235.8207 - val_accuracy: 0.4667\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 123.5952 - accuracy: 0.6104 - val_loss: 257.2039 - val_accuracy: 0.4667\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 286.0044 - accuracy: 0.5585 - val_loss: 103.6984 - val_accuracy: 0.8756\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.3070 - accuracy: 0.5704 - val_loss: 101.0688 - val_accuracy: 0.5111\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.3375 - accuracy: 0.7689 - val_loss: 12.3775 - val_accuracy: 0.8711\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7805 - accuracy: 0.7570 - val_loss: 61.6783 - val_accuracy: 0.5778\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.5821 - accuracy: 0.7719 - val_loss: 109.5378 - val_accuracy: 0.5067\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 47.9241 - accuracy: 0.7185 - val_loss: 96.8055 - val_accuracy: 0.5156\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 42.6990 - accuracy: 0.7200 - val_loss: 41.8416 - val_accuracy: 0.7956\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 38.3339 - accuracy: 0.7230 - val_loss: 38.8804 - val_accuracy: 0.8622\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.9427 - accuracy: 0.7659 - val_loss: 60.6645 - val_accuracy: 0.5822\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.8448 - accuracy: 0.7289 - val_loss: 90.6552 - val_accuracy: 0.5156\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.4439 - accuracy: 0.6815 - val_loss: 20.4471 - val_accuracy: 0.8444\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.0551 - accuracy: 0.7541 - val_loss: 53.9713 - val_accuracy: 0.5956\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 56.4614 - accuracy: 0.6311 - val_loss: 32.3918 - val_accuracy: 0.7067\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.9932 - accuracy: 0.7200 - val_loss: 22.5265 - val_accuracy: 0.8133\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.6819 - accuracy: 0.7867 - val_loss: 37.4736 - val_accuracy: 0.8089\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.6673 - accuracy: 0.8296 - val_loss: 18.7317 - val_accuracy: 0.8489\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 34.3643 - accuracy: 0.7363 - val_loss: 117.6078 - val_accuracy: 0.5067\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 62.9988 - accuracy: 0.6193 - val_loss: 167.0540 - val_accuracy: 0.4711\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.8282 - accuracy: 0.7437 - val_loss: 21.5148 - val_accuracy: 0.8667\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.3483 - accuracy: 0.7941 - val_loss: 82.0982 - val_accuracy: 0.5733\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.0367 - accuracy: 0.6815 - val_loss: 23.3094 - val_accuracy: 0.7956\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 63.1970 - accuracy: 0.6341 - val_loss: 14.0546 - val_accuracy: 0.8622\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 48.2407 - accuracy: 0.6948 - val_loss: 103.4963 - val_accuracy: 0.5511\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 41.0888 - accuracy: 0.7141 - val_loss: 57.8277 - val_accuracy: 0.5956\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.9705 - accuracy: 0.8074 - val_loss: 20.9387 - val_accuracy: 0.8578\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.2363 - accuracy: 0.8267 - val_loss: 30.6919 - val_accuracy: 0.8800\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.5123 - accuracy: 0.7867 - val_loss: 48.1892 - val_accuracy: 0.6667\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.4259 - accuracy: 0.7704 - val_loss: 26.0693 - val_accuracy: 0.8578\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36.3791 - accuracy: 0.7407 - val_loss: 49.6761 - val_accuracy: 0.6267\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.6488 - accuracy: 0.7630 - val_loss: 52.3695 - val_accuracy: 0.6222\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 78.7625 - accuracy: 0.6252 - val_loss: 183.2750 - val_accuracy: 0.4711\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 304.6321 - accuracy: 0.5333 - val_loss: 286.6142 - val_accuracy: 0.4667\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 61.9251 - accuracy: 0.7022 - val_loss: 17.4822 - val_accuracy: 0.8356\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.0519 - accuracy: 0.7437 - val_loss: 50.9879 - val_accuracy: 0.6089\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.4418 - accuracy: 0.6430 - val_loss: 185.7935 - val_accuracy: 0.4711\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 53.9310 - accuracy: 0.6904 - val_loss: 60.9016 - val_accuracy: 0.6000\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.5108 - accuracy: 0.7570 - val_loss: 14.5835 - val_accuracy: 0.8578\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.2543 - accuracy: 0.8444 - val_loss: 32.6956 - val_accuracy: 0.7200\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2880 - accuracy: 0.8119 - val_loss: 12.3336 - val_accuracy: 0.8667\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.0679 - accuracy: 0.7970 - val_loss: 26.3686 - val_accuracy: 0.7733\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.3933 - accuracy: 0.8193 - val_loss: 51.2177 - val_accuracy: 0.6444\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.1496 - accuracy: 0.7970 - val_loss: 93.8918 - val_accuracy: 0.5378\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.8048 - accuracy: 0.7378 - val_loss: 81.6204 - val_accuracy: 0.5467\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 47.7079 - accuracy: 0.6919 - val_loss: 70.9277 - val_accuracy: 0.5733\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.5134 - accuracy: 0.7467 - val_loss: 55.6598 - val_accuracy: 0.6089\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.3412 - accuracy: 0.7007 - val_loss: 38.1884 - val_accuracy: 0.6889\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.0568 - accuracy: 0.8222 - val_loss: 37.1926 - val_accuracy: 0.7022\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.1608 - accuracy: 0.7956 - val_loss: 21.7685 - val_accuracy: 0.8533\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 20.3322 - accuracy: 0.7807 - val_loss: 25.7124 - val_accuracy: 0.8044\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.4655 - accuracy: 0.7748 - val_loss: 80.3326 - val_accuracy: 0.5467\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.0068 - accuracy: 0.7659 - val_loss: 12.7700 - val_accuracy: 0.8756\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.5863 - accuracy: 0.8059 - val_loss: 40.8265 - val_accuracy: 0.6844\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.6727 - accuracy: 0.7570 - val_loss: 128.7036 - val_accuracy: 0.5067\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 82.1077 - accuracy: 0.6904 - val_loss: 35.4438 - val_accuracy: 0.7511\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 30.7936 - accuracy: 0.7763 - val_loss: 170.0435 - val_accuracy: 0.5333\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 69.4859 - accuracy: 0.6370 - val_loss: 40.1366 - val_accuracy: 0.7200\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.8043 - accuracy: 0.8222 - val_loss: 83.9451 - val_accuracy: 0.5467\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.3360 - accuracy: 0.7941 - val_loss: 22.9623 - val_accuracy: 0.8711\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.9951 - accuracy: 0.8400 - val_loss: 21.6003 - val_accuracy: 0.8222\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2451 - accuracy: 0.8133 - val_loss: 11.8348 - val_accuracy: 0.8800\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.3933 - accuracy: 0.7881 - val_loss: 22.1106 - val_accuracy: 0.8133\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.1163 - accuracy: 0.8089 - val_loss: 20.4040 - val_accuracy: 0.8133\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.5601 - accuracy: 0.7526 - val_loss: 56.4320 - val_accuracy: 0.5956\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 41.3113 - accuracy: 0.7185 - val_loss: 42.1552 - val_accuracy: 0.6844\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 33.8640 - accuracy: 0.7407 - val_loss: 59.6089 - val_accuracy: 0.6222\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.8631 - accuracy: 0.7319 - val_loss: 43.8268 - val_accuracy: 0.7156\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.2840 - accuracy: 0.7674 - val_loss: 16.3753 - val_accuracy: 0.8533\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.7769 - accuracy: 0.8163 - val_loss: 18.5394 - val_accuracy: 0.8489\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.8114 - accuracy: 0.7378 - val_loss: 74.6725 - val_accuracy: 0.5556\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.9355 - accuracy: 0.7511 - val_loss: 11.9557 - val_accuracy: 0.8800\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.3713 - accuracy: 0.8207 - val_loss: 22.0596 - val_accuracy: 0.8356\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.4590 - accuracy: 0.8104 - val_loss: 19.3797 - val_accuracy: 0.8400\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.6328 - accuracy: 0.7333 - val_loss: 202.5298 - val_accuracy: 0.4667\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 59.4744 - accuracy: 0.6578 - val_loss: 54.6530 - val_accuracy: 0.6089\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 45.8218 - accuracy: 0.6904 - val_loss: 15.0952 - val_accuracy: 0.8622\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.3202 - accuracy: 0.8178 - val_loss: 52.5236 - val_accuracy: 0.6178\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.5349 - accuracy: 0.7941 - val_loss: 59.3217 - val_accuracy: 0.5778\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7886 - accuracy: 0.7644 - val_loss: 85.1254 - val_accuracy: 0.5333\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.9642 - accuracy: 0.7022 - val_loss: 54.6411 - val_accuracy: 0.6000\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.5115 - accuracy: 0.6844 - val_loss: 59.5277 - val_accuracy: 0.6667\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.1311 - accuracy: 0.7615 - val_loss: 38.6077 - val_accuracy: 0.7333\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.8748 - accuracy: 0.8193 - val_loss: 65.1468 - val_accuracy: 0.5822\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 38.0411 - accuracy: 0.7289 - val_loss: 109.5124 - val_accuracy: 0.5111\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 61.0139 - accuracy: 0.7111 - val_loss: 18.9061 - val_accuracy: 0.8489\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.9068 - accuracy: 0.7911 - val_loss: 14.1165 - val_accuracy: 0.8667\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37.5794 - accuracy: 0.7067 - val_loss: 49.8168 - val_accuracy: 0.6667\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.3891 - accuracy: 0.7896 - val_loss: 13.9024 - val_accuracy: 0.8489\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.3746 - accuracy: 0.8000 - val_loss: 25.0802 - val_accuracy: 0.7644\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 33.4112 - accuracy: 0.7378 - val_loss: 40.2725 - val_accuracy: 0.7111\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.6567 - accuracy: 0.8015 - val_loss: 14.9042 - val_accuracy: 0.8533\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.8949 - accuracy: 0.8311 - val_loss: 43.7912 - val_accuracy: 0.6711\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 30.2460 - accuracy: 0.7215 - val_loss: 22.5645 - val_accuracy: 0.8622\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.1924 - accuracy: 0.7985 - val_loss: 18.1016 - val_accuracy: 0.8489\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.6090 - accuracy: 0.8133 - val_loss: 16.6761 - val_accuracy: 0.8489\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.3171 - accuracy: 0.8222 - val_loss: 21.1742 - val_accuracy: 0.8489\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 33.8778 - accuracy: 0.7526 - val_loss: 22.9762 - val_accuracy: 0.8089\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.4600 - accuracy: 0.7585 - val_loss: 12.1269 - val_accuracy: 0.8844\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.0337 - accuracy: 0.8015 - val_loss: 37.9406 - val_accuracy: 0.6933\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36.0422 - accuracy: 0.7481 - val_loss: 26.1140 - val_accuracy: 0.8489\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.8937 - accuracy: 0.7956 - val_loss: 78.7784 - val_accuracy: 0.5467\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.5434 - accuracy: 0.7304 - val_loss: 81.4418 - val_accuracy: 0.5600\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.0588 - accuracy: 0.7289 - val_loss: 106.0941 - val_accuracy: 0.5111\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 41.1494 - accuracy: 0.7081 - val_loss: 75.8846 - val_accuracy: 0.5556\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 60.4558 - accuracy: 0.6504 - val_loss: 17.1628 - val_accuracy: 0.8489\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 33.6928 - accuracy: 0.7422 - val_loss: 132.1717 - val_accuracy: 0.5067\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 88.4054 - accuracy: 0.6222 - val_loss: 16.3825 - val_accuracy: 0.8489\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.6056 - accuracy: 0.7674 - val_loss: 129.1387 - val_accuracy: 0.5067\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 55.7718 - accuracy: 0.6622 - val_loss: 52.5928 - val_accuracy: 0.7511\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 47.7094 - accuracy: 0.7333 - val_loss: 17.0618 - val_accuracy: 0.8444\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.1228 - accuracy: 0.8089 - val_loss: 23.0396 - val_accuracy: 0.8667\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.7656 - accuracy: 0.7970 - val_loss: 20.1815 - val_accuracy: 0.8178\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.7744 - accuracy: 0.8519 - val_loss: 48.6702 - val_accuracy: 0.6489\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.9710 - accuracy: 0.7659 - val_loss: 48.6567 - val_accuracy: 0.6222\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 43.2018 - accuracy: 0.6667 - val_loss: 56.6387 - val_accuracy: 0.5956\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 50.5920 - accuracy: 0.6830 - val_loss: 45.4125 - val_accuracy: 0.6667\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 46.2452 - accuracy: 0.7141 - val_loss: 32.2684 - val_accuracy: 0.7244\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 54.8372 - accuracy: 0.6622 - val_loss: 16.5971 - val_accuracy: 0.8444\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.7872 - accuracy: 0.8222 - val_loss: 20.3023 - val_accuracy: 0.8133\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.2966 - accuracy: 0.7881 - val_loss: 13.0048 - val_accuracy: 0.8622\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.2083 - accuracy: 0.8370 - val_loss: 15.5910 - val_accuracy: 0.8489\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.3239 - accuracy: 0.8415 - val_loss: 55.1216 - val_accuracy: 0.6089\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 38.5231 - accuracy: 0.7037 - val_loss: 18.0422 - val_accuracy: 0.8178\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36.3533 - accuracy: 0.7215 - val_loss: 16.7921 - val_accuracy: 0.8844\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.5730 - accuracy: 0.8030 - val_loss: 14.3422 - val_accuracy: 0.8533\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.2282 - accuracy: 0.7970 - val_loss: 14.8676 - val_accuracy: 0.8533\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.7578 - accuracy: 0.8341 - val_loss: 16.9549 - val_accuracy: 0.8533\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 11.6054 - accuracy: 0.8578 - val_loss: 30.9560 - val_accuracy: 0.7600\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.7836 - accuracy: 0.7985 - val_loss: 81.4052 - val_accuracy: 0.5422\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.9529 - accuracy: 0.7481 - val_loss: 47.8703 - val_accuracy: 0.6489\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.3369 - accuracy: 0.7674 - val_loss: 17.0341 - val_accuracy: 0.8356\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.6759 - accuracy: 0.7526 - val_loss: 14.7367 - val_accuracy: 0.8489\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.6653 - accuracy: 0.7319 - val_loss: 25.7438 - val_accuracy: 0.7911\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.1535 - accuracy: 0.7807 - val_loss: 23.3957 - val_accuracy: 0.7867\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.4992 - accuracy: 0.8133 - val_loss: 22.1998 - val_accuracy: 0.8489\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7584 - accuracy: 0.8430 - val_loss: 36.2877 - val_accuracy: 0.8489\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 34.4176 - accuracy: 0.7407 - val_loss: 18.5482 - val_accuracy: 0.8089\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.8812 - accuracy: 0.8267 - val_loss: 22.0996 - val_accuracy: 0.7956\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.8771 - accuracy: 0.8000 - val_loss: 37.4267 - val_accuracy: 0.6844\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.7242 - accuracy: 0.8178 - val_loss: 17.6761 - val_accuracy: 0.8444\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.8716 - accuracy: 0.7881 - val_loss: 41.9760 - val_accuracy: 0.6444\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.0520 - accuracy: 0.8059 - val_loss: 14.4952 - val_accuracy: 0.8578\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 13.2017 - accuracy: 0.8430 - val_loss: 26.8386 - val_accuracy: 0.7511\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.1909 - accuracy: 0.7926 - val_loss: 15.1304 - val_accuracy: 0.8667\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.3196 - accuracy: 0.8237 - val_loss: 29.2511 - val_accuracy: 0.7511\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.0891 - accuracy: 0.7481 - val_loss: 16.5528 - val_accuracy: 0.8311\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.6911 - accuracy: 0.7289 - val_loss: 19.9113 - val_accuracy: 0.8133\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2502 - accuracy: 0.8104 - val_loss: 22.0482 - val_accuracy: 0.7689\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.8536 - accuracy: 0.8015 - val_loss: 16.3162 - val_accuracy: 0.8400\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.2297 - accuracy: 0.8504 - val_loss: 15.6326 - val_accuracy: 0.8444\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7930 - accuracy: 0.7985 - val_loss: 69.3531 - val_accuracy: 0.5556\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.2175 - accuracy: 0.6978 - val_loss: 29.9574 - val_accuracy: 0.7289\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 29.6531 - accuracy: 0.7556 - val_loss: 20.8451 - val_accuracy: 0.8311\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7242 - accuracy: 0.7941 - val_loss: 39.5372 - val_accuracy: 0.6444\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.1828 - accuracy: 0.7570 - val_loss: 35.3458 - val_accuracy: 0.7467\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.8396 - accuracy: 0.8163 - val_loss: 76.2737 - val_accuracy: 0.5467\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 80.7183 - accuracy: 0.5956 - val_loss: 259.6306 - val_accuracy: 0.5333\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 97.1945 - accuracy: 0.7126 - val_loss: 37.0235 - val_accuracy: 0.8578\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 18.5660 - accuracy: 0.8119 - val_loss: 16.5466 - val_accuracy: 0.8533\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.2411 - accuracy: 0.8089 - val_loss: 19.3375 - val_accuracy: 0.8489\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.7114 - accuracy: 0.8281 - val_loss: 36.2055 - val_accuracy: 0.6800\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.7339 - accuracy: 0.7570 - val_loss: 67.1533 - val_accuracy: 0.5733\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.9625 - accuracy: 0.7719 - val_loss: 13.0962 - val_accuracy: 0.8533\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7028 - accuracy: 0.7467 - val_loss: 191.8094 - val_accuracy: 0.5333\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 109.2169 - accuracy: 0.5659 - val_loss: 49.3128 - val_accuracy: 0.6222\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 48.7059 - accuracy: 0.6978 - val_loss: 51.2572 - val_accuracy: 0.7689\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 30.9687 - accuracy: 0.7778 - val_loss: 23.1006 - val_accuracy: 0.8578\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.2272 - accuracy: 0.7911 - val_loss: 19.8421 - val_accuracy: 0.8000\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.3410 - accuracy: 0.7719 - val_loss: 11.0787 - val_accuracy: 0.8711\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.3181 - accuracy: 0.8370 - val_loss: 11.9836 - val_accuracy: 0.8578\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.3261 - accuracy: 0.8133 - val_loss: 48.6921 - val_accuracy: 0.6133\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.6788 - accuracy: 0.7926 - val_loss: 15.3302 - val_accuracy: 0.8578\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.3011 - accuracy: 0.8104 - val_loss: 15.1713 - val_accuracy: 0.8622\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.1757 - accuracy: 0.8400 - val_loss: 20.9314 - val_accuracy: 0.8622\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7852 - accuracy: 0.8030 - val_loss: 38.5899 - val_accuracy: 0.6622\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.9262 - accuracy: 0.7881 - val_loss: 52.9896 - val_accuracy: 0.8533\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39.5491 - accuracy: 0.7230 - val_loss: 18.7202 - val_accuracy: 0.8089\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.0108 - accuracy: 0.8385 - val_loss: 10.4877 - val_accuracy: 0.8800\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.7873 - accuracy: 0.8030 - val_loss: 57.3368 - val_accuracy: 0.5822\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.2422 - accuracy: 0.7007 - val_loss: 10.3712 - val_accuracy: 0.8622\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.0874 - accuracy: 0.7941 - val_loss: 40.6573 - val_accuracy: 0.6267\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.8600 - accuracy: 0.8281 - val_loss: 22.2835 - val_accuracy: 0.8356\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.9085 - accuracy: 0.8178 - val_loss: 12.2063 - val_accuracy: 0.8489\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.9062 - accuracy: 0.8267 - val_loss: 11.8724 - val_accuracy: 0.8578\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.6297 - accuracy: 0.8267 - val_loss: 10.3160 - val_accuracy: 0.8711\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.3187 - accuracy: 0.8000 - val_loss: 16.5410 - val_accuracy: 0.8311\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.4047 - accuracy: 0.7837 - val_loss: 54.4724 - val_accuracy: 0.5822\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.3455 - accuracy: 0.7704 - val_loss: 39.4297 - val_accuracy: 0.7156\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36.1623 - accuracy: 0.7215 - val_loss: 57.0606 - val_accuracy: 0.5822\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.2239 - accuracy: 0.7867 - val_loss: 107.5152 - val_accuracy: 0.5600\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 57.4791 - accuracy: 0.7067 - val_loss: 98.6299 - val_accuracy: 0.5067\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 58.2649 - accuracy: 0.7111 - val_loss: 48.3160 - val_accuracy: 0.8800\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.8863 - accuracy: 0.7333 - val_loss: 59.5688 - val_accuracy: 0.6311\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 28.3431 - accuracy: 0.7526 - val_loss: 12.4862 - val_accuracy: 0.8533\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.4995 - accuracy: 0.8459 - val_loss: 91.9278 - val_accuracy: 0.5111\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7864 - accuracy: 0.7319 - val_loss: 81.2772 - val_accuracy: 0.5244\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.2833 - accuracy: 0.7215 - val_loss: 101.9574 - val_accuracy: 0.5067\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 84.4571 - accuracy: 0.6044 - val_loss: 45.2843 - val_accuracy: 0.6178\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.0807 - accuracy: 0.7541 - val_loss: 78.2207 - val_accuracy: 0.5289\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.8154 - accuracy: 0.7215 - val_loss: 14.4943 - val_accuracy: 0.8400\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 19.8359 - accuracy: 0.7704 - val_loss: 115.2278 - val_accuracy: 0.5333\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.1182 - accuracy: 0.7407 - val_loss: 13.9216 - val_accuracy: 0.8533\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.1421 - accuracy: 0.7689 - val_loss: 23.3778 - val_accuracy: 0.7556\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.6316 - accuracy: 0.7956 - val_loss: 17.4873 - val_accuracy: 0.8711\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.1035 - accuracy: 0.8311 - val_loss: 43.1966 - val_accuracy: 0.6044\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.8679 - accuracy: 0.7407 - val_loss: 19.6006 - val_accuracy: 0.8667\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 18.2139 - accuracy: 0.7778 - val_loss: 13.2881 - val_accuracy: 0.8533\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.6178 - accuracy: 0.8133 - val_loss: 62.1367 - val_accuracy: 0.5556\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 17.3771 - accuracy: 0.7778 - val_loss: 14.9374 - val_accuracy: 0.8356\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.0127 - accuracy: 0.7630 - val_loss: 12.3785 - val_accuracy: 0.8489\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 10.3669 - accuracy: 0.8267 - val_loss: 49.0594 - val_accuracy: 0.6000\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 36.2037 - accuracy: 0.6815 - val_loss: 22.6739 - val_accuracy: 0.7600\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 20.3881 - accuracy: 0.7570 - val_loss: 24.8370 - val_accuracy: 0.8089\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 25.8178 - accuracy: 0.7807 - val_loss: 66.4910 - val_accuracy: 0.5867\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.0912 - accuracy: 0.7170 - val_loss: 54.3078 - val_accuracy: 0.6000\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 34.7582 - accuracy: 0.7141 - val_loss: 21.2526 - val_accuracy: 0.8222\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.1551 - accuracy: 0.7556 - val_loss: 38.0069 - val_accuracy: 0.6844\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24.0248 - accuracy: 0.7852 - val_loss: 25.3288 - val_accuracy: 0.7733\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.1702 - accuracy: 0.7644 - val_loss: 32.2104 - val_accuracy: 0.7200\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2307 - accuracy: 0.7941 - val_loss: 20.0936 - val_accuracy: 0.7733\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.6078 - accuracy: 0.8044 - val_loss: 27.6745 - val_accuracy: 0.7200\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2239 - accuracy: 0.8133 - val_loss: 17.2160 - val_accuracy: 0.8489\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.4036 - accuracy: 0.8341 - val_loss: 27.2104 - val_accuracy: 0.7156\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14.5705 - accuracy: 0.7941 - val_loss: 22.8719 - val_accuracy: 0.7378\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.5566 - accuracy: 0.7496 - val_loss: 10.8212 - val_accuracy: 0.8533\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34.8705 - accuracy: 0.7141 - val_loss: 50.4016 - val_accuracy: 0.8711\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.7691 - accuracy: 0.8044 - val_loss: 51.9151 - val_accuracy: 0.5956\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39.7331 - accuracy: 0.6933 - val_loss: 204.8105 - val_accuracy: 0.4667\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 177.8074 - accuracy: 0.5585 - val_loss: 12.7036 - val_accuracy: 0.8489\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.1585 - accuracy: 0.7778 - val_loss: 14.6972 - val_accuracy: 0.8267\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.1428 - accuracy: 0.8519 - val_loss: 15.7846 - val_accuracy: 0.8133\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.2709 - accuracy: 0.8148 - val_loss: 23.9624 - val_accuracy: 0.7200\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.2552 - accuracy: 0.7615 - val_loss: 17.1978 - val_accuracy: 0.7867\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.2107 - accuracy: 0.7956 - val_loss: 9.3837 - val_accuracy: 0.8667\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.6452 - accuracy: 0.8578 - val_loss: 12.5969 - val_accuracy: 0.8489\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 19.1686 - accuracy: 0.7941 - val_loss: 18.3883 - val_accuracy: 0.8622\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 11.4335 - accuracy: 0.8489 - val_loss: 15.9475 - val_accuracy: 0.8711\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.2289 - accuracy: 0.8133 - val_loss: 16.3864 - val_accuracy: 0.8533\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.6836 - accuracy: 0.7985 - val_loss: 14.9394 - val_accuracy: 0.8222\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.2886 - accuracy: 0.7778 - val_loss: 16.9489 - val_accuracy: 0.8133\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 26.0529 - accuracy: 0.7111 - val_loss: 60.2675 - val_accuracy: 0.5467\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 35.6625 - accuracy: 0.6815 - val_loss: 17.1732 - val_accuracy: 0.7733\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.5666 - accuracy: 0.8341 - val_loss: 45.3456 - val_accuracy: 0.5911\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7783 - accuracy: 0.7763 - val_loss: 10.5660 - val_accuracy: 0.8533\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.5096 - accuracy: 0.8430 - val_loss: 14.2034 - val_accuracy: 0.8622\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.1874 - accuracy: 0.8044 - val_loss: 16.3036 - val_accuracy: 0.8489\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 12.1145 - accuracy: 0.8207 - val_loss: 12.7305 - val_accuracy: 0.8356\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 10.3256 - accuracy: 0.8415 - val_loss: 39.9780 - val_accuracy: 0.5956\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.7925 - accuracy: 0.7259 - val_loss: 26.2393 - val_accuracy: 0.7200\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.3627 - accuracy: 0.8015 - val_loss: 59.1795 - val_accuracy: 0.5378\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.1231 - accuracy: 0.7674 - val_loss: 16.2160 - val_accuracy: 0.7733\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.5472 - accuracy: 0.7570 - val_loss: 18.5503 - val_accuracy: 0.7644\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.1776 - accuracy: 0.7719 - val_loss: 121.6723 - val_accuracy: 0.5333\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 61.3465 - accuracy: 0.6193 - val_loss: 90.9311 - val_accuracy: 0.5067\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 45.7399 - accuracy: 0.6741 - val_loss: 8.5131 - val_accuracy: 0.8711\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.2092 - accuracy: 0.8133 - val_loss: 16.1226 - val_accuracy: 0.8000\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.9508 - accuracy: 0.8059 - val_loss: 18.5485 - val_accuracy: 0.7733\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.5434 - accuracy: 0.8163 - val_loss: 10.2642 - val_accuracy: 0.8533\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.7436 - accuracy: 0.8074 - val_loss: 12.2541 - val_accuracy: 0.8444\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.8281 - accuracy: 0.7941 - val_loss: 40.8989 - val_accuracy: 0.8356\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 38.5556 - accuracy: 0.7052 - val_loss: 41.9603 - val_accuracy: 0.6978\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.7295 - accuracy: 0.7926 - val_loss: 14.1163 - val_accuracy: 0.8489\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.8692 - accuracy: 0.8356 - val_loss: 22.7304 - val_accuracy: 0.7156\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.7415 - accuracy: 0.8356 - val_loss: 24.7023 - val_accuracy: 0.7200\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.6871 - accuracy: 0.8400 - val_loss: 8.2473 - val_accuracy: 0.8667\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 11.2405 - accuracy: 0.8267 - val_loss: 24.2860 - val_accuracy: 0.7156\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7863 - accuracy: 0.7644 - val_loss: 13.4927 - val_accuracy: 0.8711\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.5192 - accuracy: 0.8089 - val_loss: 30.9261 - val_accuracy: 0.6578\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.5284 - accuracy: 0.7822 - val_loss: 10.6783 - val_accuracy: 0.8622\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.6875 - accuracy: 0.8030 - val_loss: 13.1540 - val_accuracy: 0.8222\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.5180 - accuracy: 0.8296 - val_loss: 14.0305 - val_accuracy: 0.7867\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.4332 - accuracy: 0.8044 - val_loss: 15.9418 - val_accuracy: 0.7911\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.3235 - accuracy: 0.7970 - val_loss: 17.5579 - val_accuracy: 0.8133\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.7617 - accuracy: 0.7793 - val_loss: 55.1150 - val_accuracy: 0.5689\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 34.2243 - accuracy: 0.7481 - val_loss: 42.8471 - val_accuracy: 0.6133\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.4135 - accuracy: 0.7719 - val_loss: 25.8436 - val_accuracy: 0.8400\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 26.9412 - accuracy: 0.7304 - val_loss: 22.3315 - val_accuracy: 0.7156\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.8737 - accuracy: 0.8133 - val_loss: 13.2504 - val_accuracy: 0.8267\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.1746 - accuracy: 0.8311 - val_loss: 17.2020 - val_accuracy: 0.7644\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 13.9207 - accuracy: 0.7526 - val_loss: 11.6144 - val_accuracy: 0.8622\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.6876 - accuracy: 0.7985 - val_loss: 19.3427 - val_accuracy: 0.7556\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.0480 - accuracy: 0.8252 - val_loss: 19.0989 - val_accuracy: 0.7911\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 31.4958 - accuracy: 0.7304 - val_loss: 20.7935 - val_accuracy: 0.7467\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.2534 - accuracy: 0.8252 - val_loss: 23.7153 - val_accuracy: 0.6889\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.1938 - accuracy: 0.7437 - val_loss: 45.5770 - val_accuracy: 0.5689\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.2684 - accuracy: 0.7630 - val_loss: 23.9399 - val_accuracy: 0.7156\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.2028 - accuracy: 0.7570 - val_loss: 28.1693 - val_accuracy: 0.7289\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.0174 - accuracy: 0.7970 - val_loss: 8.2855 - val_accuracy: 0.8711\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4954 - accuracy: 0.8267 - val_loss: 23.4141 - val_accuracy: 0.7200\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.9074 - accuracy: 0.7244 - val_loss: 59.1349 - val_accuracy: 0.5600\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 51.1101 - accuracy: 0.6607 - val_loss: 170.5780 - val_accuracy: 0.5378\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 56.3284 - accuracy: 0.6533 - val_loss: 27.0933 - val_accuracy: 0.7378\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 19.8980 - accuracy: 0.7733 - val_loss: 14.8840 - val_accuracy: 0.8089\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4947 - accuracy: 0.8385 - val_loss: 8.4712 - val_accuracy: 0.8711\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8289 - accuracy: 0.8281 - val_loss: 60.9174 - val_accuracy: 0.7644\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.3374 - accuracy: 0.7896 - val_loss: 28.7216 - val_accuracy: 0.8133\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.8315 - accuracy: 0.8133 - val_loss: 11.9240 - val_accuracy: 0.8089\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.0440 - accuracy: 0.8193 - val_loss: 14.1825 - val_accuracy: 0.8356\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4728 - accuracy: 0.8400 - val_loss: 21.8969 - val_accuracy: 0.7200\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.1480 - accuracy: 0.8296 - val_loss: 9.0380 - val_accuracy: 0.8667\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.6086 - accuracy: 0.8281 - val_loss: 11.3911 - val_accuracy: 0.8267\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.0627 - accuracy: 0.8044 - val_loss: 17.4564 - val_accuracy: 0.8133\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.8808 - accuracy: 0.8207 - val_loss: 9.6222 - val_accuracy: 0.8533\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.4101 - accuracy: 0.7333 - val_loss: 50.3297 - val_accuracy: 0.5733\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.5968 - accuracy: 0.7378 - val_loss: 17.2072 - val_accuracy: 0.7600\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.3728 - accuracy: 0.7926 - val_loss: 13.3460 - val_accuracy: 0.7778\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.1239 - accuracy: 0.6978 - val_loss: 65.1521 - val_accuracy: 0.5511\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 27.1549 - accuracy: 0.7052 - val_loss: 12.4088 - val_accuracy: 0.8533\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.6200 - accuracy: 0.8341 - val_loss: 7.7234 - val_accuracy: 0.8800\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.1126 - accuracy: 0.8222 - val_loss: 36.0165 - val_accuracy: 0.5956\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 32.6935 - accuracy: 0.6726 - val_loss: 28.7747 - val_accuracy: 0.7200\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.6230 - accuracy: 0.7867 - val_loss: 9.3320 - val_accuracy: 0.8533\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.5405 - accuracy: 0.8489 - val_loss: 10.6558 - val_accuracy: 0.8400\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.1496 - accuracy: 0.8030 - val_loss: 38.4331 - val_accuracy: 0.5867\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.5058 - accuracy: 0.7259 - val_loss: 46.0988 - val_accuracy: 0.5733\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.3769 - accuracy: 0.7467 - val_loss: 34.5784 - val_accuracy: 0.5956\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.0850 - accuracy: 0.7970 - val_loss: 8.4537 - val_accuracy: 0.8489\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.0390 - accuracy: 0.8430 - val_loss: 10.0545 - val_accuracy: 0.8444\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.3556 - accuracy: 0.8341 - val_loss: 13.6261 - val_accuracy: 0.8489\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9.8290 - accuracy: 0.8326 - val_loss: 8.9031 - val_accuracy: 0.8489\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.6886 - accuracy: 0.8311 - val_loss: 31.8447 - val_accuracy: 0.5956\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.9346 - accuracy: 0.8237 - val_loss: 17.0482 - val_accuracy: 0.8089\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.9987 - accuracy: 0.7896 - val_loss: 11.2978 - val_accuracy: 0.8267\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8409 - accuracy: 0.8074 - val_loss: 25.7910 - val_accuracy: 0.6578\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.8062 - accuracy: 0.6993 - val_loss: 28.1568 - val_accuracy: 0.6400\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.5355 - accuracy: 0.7615 - val_loss: 7.8548 - val_accuracy: 0.8622\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.8171 - accuracy: 0.8578 - val_loss: 10.3484 - val_accuracy: 0.8311\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.2516 - accuracy: 0.8207 - val_loss: 8.4843 - val_accuracy: 0.8400\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.6310 - accuracy: 0.7970 - val_loss: 15.2967 - val_accuracy: 0.8489\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.3296 - accuracy: 0.8548 - val_loss: 6.6575 - val_accuracy: 0.8844\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.5745 - accuracy: 0.7941 - val_loss: 32.7002 - val_accuracy: 0.6267\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.1134 - accuracy: 0.7807 - val_loss: 32.8058 - val_accuracy: 0.6311\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.3352 - accuracy: 0.8119 - val_loss: 7.0707 - val_accuracy: 0.8844\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9.9592 - accuracy: 0.8104 - val_loss: 8.2767 - val_accuracy: 0.8533\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 23.6523 - accuracy: 0.6785 - val_loss: 16.0051 - val_accuracy: 0.7422\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4568 - accuracy: 0.8119 - val_loss: 16.2696 - val_accuracy: 0.7422\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.9425 - accuracy: 0.7807 - val_loss: 12.2398 - val_accuracy: 0.7778\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.8316 - accuracy: 0.7763 - val_loss: 33.8384 - val_accuracy: 0.5822\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.1171 - accuracy: 0.7481 - val_loss: 62.1562 - val_accuracy: 0.5111\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 37.6503 - accuracy: 0.6578 - val_loss: 18.2920 - val_accuracy: 0.8044\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.4785 - accuracy: 0.7615 - val_loss: 24.9557 - val_accuracy: 0.6444\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.4537 - accuracy: 0.8044 - val_loss: 11.8343 - val_accuracy: 0.8267\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.3564 - accuracy: 0.8415 - val_loss: 15.3565 - val_accuracy: 0.7822\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.7567 - accuracy: 0.8222 - val_loss: 15.1104 - val_accuracy: 0.7467\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.0393 - accuracy: 0.7630 - val_loss: 22.3133 - val_accuracy: 0.6800\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.1420 - accuracy: 0.7807 - val_loss: 6.2719 - val_accuracy: 0.8844\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.8187 - accuracy: 0.8563 - val_loss: 34.0516 - val_accuracy: 0.6844\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 27.1113 - accuracy: 0.6993 - val_loss: 26.0660 - val_accuracy: 0.6311\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.2741 - accuracy: 0.6874 - val_loss: 12.8795 - val_accuracy: 0.8533\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.8127 - accuracy: 0.6978 - val_loss: 12.7473 - val_accuracy: 0.8489\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.9216 - accuracy: 0.8000 - val_loss: 28.6490 - val_accuracy: 0.6578\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.0193 - accuracy: 0.7467 - val_loss: 29.4661 - val_accuracy: 0.5956\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.6623 - accuracy: 0.7896 - val_loss: 8.8560 - val_accuracy: 0.8756\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.4115 - accuracy: 0.8459 - val_loss: 10.1384 - val_accuracy: 0.8267\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.7423 - accuracy: 0.8089 - val_loss: 60.7156 - val_accuracy: 0.5378\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 45.2427 - accuracy: 0.5970 - val_loss: 37.5842 - val_accuracy: 0.8667\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.4405 - accuracy: 0.7081 - val_loss: 8.7767 - val_accuracy: 0.8578\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9.5231 - accuracy: 0.8193 - val_loss: 10.6538 - val_accuracy: 0.8089\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.5761 - accuracy: 0.8237 - val_loss: 5.8430 - val_accuracy: 0.8711\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.1911 - accuracy: 0.8030 - val_loss: 8.7260 - val_accuracy: 0.8311\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.2467 - accuracy: 0.8341 - val_loss: 12.6221 - val_accuracy: 0.7600\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.4187 - accuracy: 0.7733 - val_loss: 6.7697 - val_accuracy: 0.8578\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.9108 - accuracy: 0.8237 - val_loss: 9.6563 - val_accuracy: 0.8089\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.6460 - accuracy: 0.7378 - val_loss: 19.3568 - val_accuracy: 0.6800\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4192 - accuracy: 0.7822 - val_loss: 5.7256 - val_accuracy: 0.8756\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.6496 - accuracy: 0.8385 - val_loss: 14.8410 - val_accuracy: 0.7156\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.3790 - accuracy: 0.7704 - val_loss: 18.6874 - val_accuracy: 0.6889\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.9656 - accuracy: 0.7793 - val_loss: 12.6432 - val_accuracy: 0.7378\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 8.7971 - accuracy: 0.7985 - val_loss: 5.7328 - val_accuracy: 0.8578\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.9064 - accuracy: 0.7763 - val_loss: 29.8812 - val_accuracy: 0.5733\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.9940 - accuracy: 0.7230 - val_loss: 17.3756 - val_accuracy: 0.6667\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.7407 - accuracy: 0.7867 - val_loss: 29.8729 - val_accuracy: 0.5689\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.3150 - accuracy: 0.7778 - val_loss: 13.9972 - val_accuracy: 0.7156\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 20.3902 - accuracy: 0.6830 - val_loss: 10.8961 - val_accuracy: 0.8533\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 21.5572 - accuracy: 0.7141 - val_loss: 15.5235 - val_accuracy: 0.7333\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.1394 - accuracy: 0.8178 - val_loss: 6.3530 - val_accuracy: 0.8622\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.5742 - accuracy: 0.7793 - val_loss: 6.0183 - val_accuracy: 0.8622\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.1864 - accuracy: 0.8237 - val_loss: 9.0087 - val_accuracy: 0.7911\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.5595 - accuracy: 0.8193 - val_loss: 5.7131 - val_accuracy: 0.8444\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.3621 - accuracy: 0.7141 - val_loss: 16.8688 - val_accuracy: 0.6889\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.1377 - accuracy: 0.7985 - val_loss: 17.7525 - val_accuracy: 0.6889\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.5149 - accuracy: 0.7867 - val_loss: 9.1225 - val_accuracy: 0.8489\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9.4149 - accuracy: 0.7970 - val_loss: 7.3968 - val_accuracy: 0.8444\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.1188 - accuracy: 0.8326 - val_loss: 6.7746 - val_accuracy: 0.8622\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.2109 - accuracy: 0.7644 - val_loss: 34.4554 - val_accuracy: 0.5511\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8309 - accuracy: 0.7481 - val_loss: 24.6012 - val_accuracy: 0.6133\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.6316 - accuracy: 0.7185 - val_loss: 9.6323 - val_accuracy: 0.7778\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.6304 - accuracy: 0.6800 - val_loss: 6.6223 - val_accuracy: 0.8578\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.3111 - accuracy: 0.7719 - val_loss: 20.8585 - val_accuracy: 0.6267\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.4239 - accuracy: 0.7807 - val_loss: 7.8276 - val_accuracy: 0.8356\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.2413 - accuracy: 0.7037 - val_loss: 27.9636 - val_accuracy: 0.5733\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.1832 - accuracy: 0.7644 - val_loss: 11.1268 - val_accuracy: 0.7644\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.6749 - accuracy: 0.8252 - val_loss: 11.7865 - val_accuracy: 0.7467\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.8127 - accuracy: 0.7141 - val_loss: 7.4932 - val_accuracy: 0.8489\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.7991 - accuracy: 0.8015 - val_loss: 5.7610 - val_accuracy: 0.8622\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.4695 - accuracy: 0.8311 - val_loss: 6.0649 - val_accuracy: 0.8533\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 16.2632 - accuracy: 0.7067 - val_loss: 11.5402 - val_accuracy: 0.7778\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.0619 - accuracy: 0.8222 - val_loss: 6.0958 - val_accuracy: 0.8533\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.2452 - accuracy: 0.8430 - val_loss: 8.5241 - val_accuracy: 0.7822\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.2072 - accuracy: 0.7763 - val_loss: 11.9230 - val_accuracy: 0.7600\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.3520 - accuracy: 0.7985 - val_loss: 6.7320 - val_accuracy: 0.8667\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.7681 - accuracy: 0.8267 - val_loss: 18.4662 - val_accuracy: 0.6222\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.3216 - accuracy: 0.7985 - val_loss: 15.5065 - val_accuracy: 0.6667\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4809 - accuracy: 0.7556 - val_loss: 32.5955 - val_accuracy: 0.5689\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 22.6995 - accuracy: 0.7511 - val_loss: 41.5807 - val_accuracy: 0.5511\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.4533 - accuracy: 0.7393 - val_loss: 8.4420 - val_accuracy: 0.8711\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.1980 - accuracy: 0.8281 - val_loss: 11.3685 - val_accuracy: 0.8089\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 7.8190 - accuracy: 0.8104 - val_loss: 22.6108 - val_accuracy: 0.6667\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.8628 - accuracy: 0.7511 - val_loss: 10.2027 - val_accuracy: 0.7956\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.3511 - accuracy: 0.7867 - val_loss: 9.5358 - val_accuracy: 0.8356\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.0929 - accuracy: 0.7704 - val_loss: 8.4734 - val_accuracy: 0.8089\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.5174 - accuracy: 0.8296 - val_loss: 11.7796 - val_accuracy: 0.7600\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.6630 - accuracy: 0.7793 - val_loss: 16.9014 - val_accuracy: 0.7333\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.1807 - accuracy: 0.7630 - val_loss: 6.3054 - val_accuracy: 0.8489\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.4463 - accuracy: 0.8178 - val_loss: 12.1802 - val_accuracy: 0.7467\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.6360 - accuracy: 0.7689 - val_loss: 13.1110 - val_accuracy: 0.8533\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 13.5518 - accuracy: 0.7422 - val_loss: 27.2056 - val_accuracy: 0.5956\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.8847 - accuracy: 0.7437 - val_loss: 26.5015 - val_accuracy: 0.5778\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.3720 - accuracy: 0.7689 - val_loss: 5.0866 - val_accuracy: 0.8533\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.5992 - accuracy: 0.8607 - val_loss: 7.6674 - val_accuracy: 0.8089\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.3927 - accuracy: 0.8059 - val_loss: 5.4149 - val_accuracy: 0.8489\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.9734 - accuracy: 0.8178 - val_loss: 9.3432 - val_accuracy: 0.7689\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.1233 - accuracy: 0.7393 - val_loss: 10.0708 - val_accuracy: 0.7822\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.1193 - accuracy: 0.8252 - val_loss: 10.7838 - val_accuracy: 0.8489\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.4081 - accuracy: 0.7733 - val_loss: 5.1356 - val_accuracy: 0.8622\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.0301 - accuracy: 0.8593 - val_loss: 3.9732 - val_accuracy: 0.8711\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.4656 - accuracy: 0.8341 - val_loss: 6.5828 - val_accuracy: 0.8044\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.1272 - accuracy: 0.7496 - val_loss: 14.6417 - val_accuracy: 0.6533\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 17.5043 - accuracy: 0.6770 - val_loss: 22.7290 - val_accuracy: 0.5822\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.8890 - accuracy: 0.7644 - val_loss: 22.8088 - val_accuracy: 0.5733\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.8053 - accuracy: 0.7393 - val_loss: 11.2863 - val_accuracy: 0.7289\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.2663 - accuracy: 0.8089 - val_loss: 15.7546 - val_accuracy: 0.6800\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 6.6419 - accuracy: 0.7837 - val_loss: 14.1290 - val_accuracy: 0.6578\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.1162 - accuracy: 0.8044 - val_loss: 15.9919 - val_accuracy: 0.6178\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.3631 - accuracy: 0.7437 - val_loss: 4.6475 - val_accuracy: 0.8622\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.3108 - accuracy: 0.8148 - val_loss: 7.2732 - val_accuracy: 0.7867\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2535 - accuracy: 0.8400 - val_loss: 10.9162 - val_accuracy: 0.7067\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.4719 - accuracy: 0.8148 - val_loss: 3.9645 - val_accuracy: 0.8756\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.9056 - accuracy: 0.8430 - val_loss: 3.4894 - val_accuracy: 0.8756\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.9941 - accuracy: 0.8356 - val_loss: 4.8730 - val_accuracy: 0.8400\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.6773 - accuracy: 0.8326 - val_loss: 4.6625 - val_accuracy: 0.8622\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.3502 - accuracy: 0.6830 - val_loss: 20.0551 - val_accuracy: 0.5733\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 7.7525 - accuracy: 0.7763 - val_loss: 7.0917 - val_accuracy: 0.7911\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14.0537 - accuracy: 0.6815 - val_loss: 4.0905 - val_accuracy: 0.8489\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.1241 - accuracy: 0.8207 - val_loss: 4.3017 - val_accuracy: 0.8444\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.3250 - accuracy: 0.8311 - val_loss: 6.1840 - val_accuracy: 0.8089\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8585 - accuracy: 0.8222 - val_loss: 3.6712 - val_accuracy: 0.8756\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7141 - accuracy: 0.8563 - val_loss: 4.7848 - val_accuracy: 0.8533\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.8192 - accuracy: 0.8311 - val_loss: 11.0428 - val_accuracy: 0.8711\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.9526 - accuracy: 0.7941 - val_loss: 7.6912 - val_accuracy: 0.7733\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.4737 - accuracy: 0.7911 - val_loss: 3.6383 - val_accuracy: 0.8622\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0634 - accuracy: 0.8281 - val_loss: 18.7963 - val_accuracy: 0.5733\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.3246 - accuracy: 0.7363 - val_loss: 14.5956 - val_accuracy: 0.7378\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9.8708 - accuracy: 0.7615 - val_loss: 3.9466 - val_accuracy: 0.8444\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.7108 - accuracy: 0.8207 - val_loss: 3.3825 - val_accuracy: 0.8711\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3170 - accuracy: 0.8474 - val_loss: 9.4582 - val_accuracy: 0.7378\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.2260 - accuracy: 0.8207 - val_loss: 10.6168 - val_accuracy: 0.6711\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.5863 - accuracy: 0.7570 - val_loss: 13.5473 - val_accuracy: 0.6133\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.3766 - accuracy: 0.7081 - val_loss: 3.6976 - val_accuracy: 0.8533\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2101 - accuracy: 0.8163 - val_loss: 7.1286 - val_accuracy: 0.7867\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.4090 - accuracy: 0.7481 - val_loss: 7.0624 - val_accuracy: 0.7733\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.1904 - accuracy: 0.7763 - val_loss: 10.2266 - val_accuracy: 0.7022\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.4130 - accuracy: 0.7896 - val_loss: 7.0321 - val_accuracy: 0.7644\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.7508 - accuracy: 0.8370 - val_loss: 3.2196 - val_accuracy: 0.8667\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.0334 - accuracy: 0.8593 - val_loss: 5.4947 - val_accuracy: 0.7822\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7236 - accuracy: 0.8281 - val_loss: 3.9638 - val_accuracy: 0.8622\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0920 - accuracy: 0.8074 - val_loss: 7.5193 - val_accuracy: 0.7378\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.0842 - accuracy: 0.7452 - val_loss: 3.6072 - val_accuracy: 0.8444\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2777 - accuracy: 0.8400 - val_loss: 37.0654 - val_accuracy: 0.5333\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.4770 - accuracy: 0.7363 - val_loss: 8.8963 - val_accuracy: 0.7244\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.6881 - accuracy: 0.7556 - val_loss: 12.6706 - val_accuracy: 0.7289\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.2718 - accuracy: 0.7956 - val_loss: 4.8303 - val_accuracy: 0.8578\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.9714 - accuracy: 0.8267 - val_loss: 13.5283 - val_accuracy: 0.7067\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.1581 - accuracy: 0.7793 - val_loss: 19.1915 - val_accuracy: 0.5556\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.4906 - accuracy: 0.8089 - val_loss: 15.1779 - val_accuracy: 0.5822\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 15.6560 - accuracy: 0.6963 - val_loss: 33.6784 - val_accuracy: 0.5067\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.6678 - accuracy: 0.7437 - val_loss: 17.1151 - val_accuracy: 0.5867\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.0025 - accuracy: 0.6830 - val_loss: 6.7105 - val_accuracy: 0.8489\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.7496 - accuracy: 0.7719 - val_loss: 8.0974 - val_accuracy: 0.8756\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.0116 - accuracy: 0.7733 - val_loss: 22.4658 - val_accuracy: 0.5467\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.7703 - accuracy: 0.7378 - val_loss: 4.1012 - val_accuracy: 0.8578\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3186 - accuracy: 0.8548 - val_loss: 4.9852 - val_accuracy: 0.8356\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4384 - accuracy: 0.8356 - val_loss: 13.4948 - val_accuracy: 0.6000\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 11.9933 - accuracy: 0.6889 - val_loss: 8.0516 - val_accuracy: 0.7333\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 18.9449 - accuracy: 0.6296 - val_loss: 32.6906 - val_accuracy: 0.5378\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 17.3637 - accuracy: 0.7244 - val_loss: 4.3094 - val_accuracy: 0.8533\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.5491 - accuracy: 0.8252 - val_loss: 24.7157 - val_accuracy: 0.5467\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.3941 - accuracy: 0.6859 - val_loss: 12.6977 - val_accuracy: 0.6667\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 16.9815 - accuracy: 0.6593 - val_loss: 12.3076 - val_accuracy: 0.6978\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.5754 - accuracy: 0.7244 - val_loss: 3.8310 - val_accuracy: 0.8711\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8222 - accuracy: 0.8341 - val_loss: 4.2626 - val_accuracy: 0.8489\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7500 - accuracy: 0.8474 - val_loss: 10.2845 - val_accuracy: 0.7067\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.3271 - accuracy: 0.8178 - val_loss: 6.2795 - val_accuracy: 0.7956\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7478 - accuracy: 0.8281 - val_loss: 3.8762 - val_accuracy: 0.8578\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8331 - accuracy: 0.8326 - val_loss: 9.9546 - val_accuracy: 0.6933\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2800 - accuracy: 0.8044 - val_loss: 4.5933 - val_accuracy: 0.8400\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.6362 - accuracy: 0.7970 - val_loss: 7.1876 - val_accuracy: 0.7600\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.9487 - accuracy: 0.8385 - val_loss: 3.5554 - val_accuracy: 0.8756\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0191 - accuracy: 0.7970 - val_loss: 8.3678 - val_accuracy: 0.7200\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.4850 - accuracy: 0.7778 - val_loss: 9.9925 - val_accuracy: 0.7378\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.4318 - accuracy: 0.7378 - val_loss: 7.5916 - val_accuracy: 0.7244\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5653 - accuracy: 0.8207 - val_loss: 8.6288 - val_accuracy: 0.6889\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.5421 - accuracy: 0.7600 - val_loss: 3.3833 - val_accuracy: 0.8444\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.1682 - accuracy: 0.7822 - val_loss: 3.5228 - val_accuracy: 0.8533\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.7998 - accuracy: 0.7556 - val_loss: 3.0111 - val_accuracy: 0.8711\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.0651 - accuracy: 0.8370 - val_loss: 4.7673 - val_accuracy: 0.8089\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.8607 - accuracy: 0.8296 - val_loss: 4.5675 - val_accuracy: 0.8089\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1520 - accuracy: 0.8074 - val_loss: 6.3745 - val_accuracy: 0.7467\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.6180 - accuracy: 0.7748 - val_loss: 14.6994 - val_accuracy: 0.5733\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.9426 - accuracy: 0.7200 - val_loss: 5.0417 - val_accuracy: 0.8489\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.0768 - accuracy: 0.8252 - val_loss: 4.8072 - val_accuracy: 0.8000\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3446 - accuracy: 0.8222 - val_loss: 3.0853 - val_accuracy: 0.8711\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6851 - accuracy: 0.8533 - val_loss: 2.9866 - val_accuracy: 0.8489\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5233 - accuracy: 0.8119 - val_loss: 7.5171 - val_accuracy: 0.7378\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.5324 - accuracy: 0.7541 - val_loss: 2.7002 - val_accuracy: 0.8756\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4067 - accuracy: 0.8578 - val_loss: 9.9443 - val_accuracy: 0.7956\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 6.2636 - accuracy: 0.7659 - val_loss: 7.7243 - val_accuracy: 0.7733\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.3730 - accuracy: 0.8104 - val_loss: 2.8432 - val_accuracy: 0.8711\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.9025 - accuracy: 0.7230 - val_loss: 9.6293 - val_accuracy: 0.6578\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.0568 - accuracy: 0.7911 - val_loss: 3.4540 - val_accuracy: 0.8533\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.6695 - accuracy: 0.8267 - val_loss: 3.4576 - val_accuracy: 0.8489\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.4818 - accuracy: 0.7763 - val_loss: 14.1936 - val_accuracy: 0.5689\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 9.6149 - accuracy: 0.6889 - val_loss: 6.8747 - val_accuracy: 0.8578\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.1433 - accuracy: 0.8252 - val_loss: 3.7033 - val_accuracy: 0.8622\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.0027 - accuracy: 0.8400 - val_loss: 5.8631 - val_accuracy: 0.8044\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8947 - accuracy: 0.7926 - val_loss: 11.0421 - val_accuracy: 0.6489\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.1961 - accuracy: 0.7407 - val_loss: 3.3069 - val_accuracy: 0.8489\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.2756 - accuracy: 0.7896 - val_loss: 3.3126 - val_accuracy: 0.8444\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.9940 - accuracy: 0.8207 - val_loss: 4.4657 - val_accuracy: 0.7822\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.7094 - accuracy: 0.7867 - val_loss: 4.9980 - val_accuracy: 0.8356\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0687 - accuracy: 0.7719 - val_loss: 2.3894 - val_accuracy: 0.8711\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2782 - accuracy: 0.8148 - val_loss: 11.1490 - val_accuracy: 0.6000\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4558 - accuracy: 0.8222 - val_loss: 4.2993 - val_accuracy: 0.8311\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2926 - accuracy: 0.8015 - val_loss: 3.3624 - val_accuracy: 0.8444\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.8025 - accuracy: 0.6963 - val_loss: 14.2703 - val_accuracy: 0.5911\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 8.8267 - accuracy: 0.6993 - val_loss: 11.0515 - val_accuracy: 0.6978\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 7.0925 - accuracy: 0.7481 - val_loss: 5.5766 - val_accuracy: 0.8667\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.0064 - accuracy: 0.8370 - val_loss: 8.9594 - val_accuracy: 0.6889\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 6.0599 - accuracy: 0.7778 - val_loss: 5.2536 - val_accuracy: 0.7733\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.4051 - accuracy: 0.7911 - val_loss: 11.6014 - val_accuracy: 0.5911\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3775 - accuracy: 0.8148 - val_loss: 5.7752 - val_accuracy: 0.7600\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.0910 - accuracy: 0.7689 - val_loss: 4.7030 - val_accuracy: 0.7733\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5642 - accuracy: 0.8193 - val_loss: 4.3601 - val_accuracy: 0.7778\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1917 - accuracy: 0.7837 - val_loss: 4.1933 - val_accuracy: 0.7778\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.6217 - accuracy: 0.7748 - val_loss: 2.0711 - val_accuracy: 0.8756\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2312 - accuracy: 0.7704 - val_loss: 2.2123 - val_accuracy: 0.8711\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2788 - accuracy: 0.8044 - val_loss: 5.6229 - val_accuracy: 0.7378\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8063 - accuracy: 0.7956 - val_loss: 2.9885 - val_accuracy: 0.8622\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.3363 - accuracy: 0.7911 - val_loss: 2.3166 - val_accuracy: 0.8444\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4738 - accuracy: 0.8222 - val_loss: 2.4141 - val_accuracy: 0.8489\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.9050 - accuracy: 0.8104 - val_loss: 2.0344 - val_accuracy: 0.8711\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2085 - accuracy: 0.8341 - val_loss: 2.2823 - val_accuracy: 0.8622\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2221 - accuracy: 0.7689 - val_loss: 7.1142 - val_accuracy: 0.7422\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7294 - accuracy: 0.7911 - val_loss: 3.3234 - val_accuracy: 0.8622\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5416 - accuracy: 0.8119 - val_loss: 4.8396 - val_accuracy: 0.8667\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2475 - accuracy: 0.8074 - val_loss: 11.8822 - val_accuracy: 0.5644\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 12.3630 - accuracy: 0.6281 - val_loss: 19.8758 - val_accuracy: 0.5111\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 10.3874 - accuracy: 0.7096 - val_loss: 5.9754 - val_accuracy: 0.7867\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3516 - accuracy: 0.8044 - val_loss: 7.7904 - val_accuracy: 0.6533\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.5054 - accuracy: 0.7452 - val_loss: 7.1318 - val_accuracy: 0.8711\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.6400 - accuracy: 0.7644 - val_loss: 2.5036 - val_accuracy: 0.8533\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8206 - accuracy: 0.8015 - val_loss: 5.6483 - val_accuracy: 0.7200\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5943 - accuracy: 0.8311 - val_loss: 3.4006 - val_accuracy: 0.8356\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1894 - accuracy: 0.8459 - val_loss: 4.1527 - val_accuracy: 0.8578\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5.2325 - accuracy: 0.7733 - val_loss: 7.6820 - val_accuracy: 0.6400\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.0160 - accuracy: 0.7852 - val_loss: 3.0269 - val_accuracy: 0.8178\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.6449 - accuracy: 0.7911 - val_loss: 8.1003 - val_accuracy: 0.7067\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.8381 - accuracy: 0.8030 - val_loss: 5.1189 - val_accuracy: 0.7778\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0454 - accuracy: 0.7481 - val_loss: 11.5302 - val_accuracy: 0.5644\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.8896 - accuracy: 0.7126 - val_loss: 13.7033 - val_accuracy: 0.5733\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.9369 - accuracy: 0.7644 - val_loss: 3.8308 - val_accuracy: 0.7867\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4028 - accuracy: 0.8296 - val_loss: 2.0718 - val_accuracy: 0.8489\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8531 - accuracy: 0.8563 - val_loss: 12.8468 - val_accuracy: 0.5511\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.9417 - accuracy: 0.7200 - val_loss: 15.7292 - val_accuracy: 0.5289\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.7416 - accuracy: 0.7822 - val_loss: 1.9335 - val_accuracy: 0.8578\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1547 - accuracy: 0.7733 - val_loss: 2.1783 - val_accuracy: 0.8533\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.3310 - accuracy: 0.7911 - val_loss: 3.6756 - val_accuracy: 0.8044\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2467 - accuracy: 0.7896 - val_loss: 2.4678 - val_accuracy: 0.8400\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.0356 - accuracy: 0.7615 - val_loss: 7.4137 - val_accuracy: 0.6578\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.5644 - accuracy: 0.7881 - val_loss: 2.5241 - val_accuracy: 0.8578\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.9339 - accuracy: 0.8089 - val_loss: 3.5795 - val_accuracy: 0.7956\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6515 - accuracy: 0.8089 - val_loss: 5.1648 - val_accuracy: 0.7911\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8939 - accuracy: 0.8163 - val_loss: 2.1618 - val_accuracy: 0.8533\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2463 - accuracy: 0.8267 - val_loss: 10.2289 - val_accuracy: 0.5733\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.6874 - accuracy: 0.7067 - val_loss: 13.4652 - val_accuracy: 0.5644\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.3852 - accuracy: 0.7630 - val_loss: 3.9825 - val_accuracy: 0.7867\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1634 - accuracy: 0.8533 - val_loss: 1.9007 - val_accuracy: 0.8533\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1544 - accuracy: 0.8356 - val_loss: 1.7540 - val_accuracy: 0.8711\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8865 - accuracy: 0.8030 - val_loss: 13.8554 - val_accuracy: 0.5644\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 10.8245 - accuracy: 0.6356 - val_loss: 4.3698 - val_accuracy: 0.7911\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5482 - accuracy: 0.8281 - val_loss: 1.9574 - val_accuracy: 0.8622\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0969 - accuracy: 0.8281 - val_loss: 2.5426 - val_accuracy: 0.8622\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9455 - accuracy: 0.8444 - val_loss: 3.7595 - val_accuracy: 0.7511\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4467 - accuracy: 0.8030 - val_loss: 3.3727 - val_accuracy: 0.8267\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8672 - accuracy: 0.7630 - val_loss: 2.7550 - val_accuracy: 0.8622\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.3311 - accuracy: 0.7719 - val_loss: 10.5403 - val_accuracy: 0.7467\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 4.1371 - accuracy: 0.8148 - val_loss: 3.2721 - val_accuracy: 0.8044\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4246 - accuracy: 0.8163 - val_loss: 3.0684 - val_accuracy: 0.8444\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.5167 - accuracy: 0.8370 - val_loss: 1.7044 - val_accuracy: 0.8667\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1467 - accuracy: 0.8074 - val_loss: 6.0483 - val_accuracy: 0.6533\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.2711 - accuracy: 0.7526 - val_loss: 2.0821 - val_accuracy: 0.8444\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5.3711 - accuracy: 0.7096 - val_loss: 1.8327 - val_accuracy: 0.8622\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.7375 - accuracy: 0.8015 - val_loss: 2.9620 - val_accuracy: 0.7911\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.3555 - accuracy: 0.7244 - val_loss: 3.2391 - val_accuracy: 0.8667\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1893 - accuracy: 0.8089 - val_loss: 5.0039 - val_accuracy: 0.7911\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4346 - accuracy: 0.7837 - val_loss: 7.0782 - val_accuracy: 0.6311\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.9290 - accuracy: 0.8044 - val_loss: 2.2739 - val_accuracy: 0.8533\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5.9292 - accuracy: 0.7333 - val_loss: 1.7204 - val_accuracy: 0.8711\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5934 - accuracy: 0.7719 - val_loss: 4.8173 - val_accuracy: 0.8000\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1223 - accuracy: 0.7956 - val_loss: 1.6998 - val_accuracy: 0.8622\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8453 - accuracy: 0.8311 - val_loss: 6.5498 - val_accuracy: 0.6444\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4.0460 - accuracy: 0.7659 - val_loss: 6.7808 - val_accuracy: 0.6978\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.3076 - accuracy: 0.7704 - val_loss: 13.3109 - val_accuracy: 0.5289\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.2410 - accuracy: 0.7541 - val_loss: 4.5359 - val_accuracy: 0.8622\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3484 - accuracy: 0.8133 - val_loss: 1.6380 - val_accuracy: 0.8711\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4750 - accuracy: 0.8044 - val_loss: 3.8027 - val_accuracy: 0.7644\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.2482 - accuracy: 0.7763 - val_loss: 4.4602 - val_accuracy: 0.7289\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7555 - accuracy: 0.7452 - val_loss: 8.3644 - val_accuracy: 0.5822\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3612 - accuracy: 0.7911 - val_loss: 3.8756 - val_accuracy: 0.7644\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6338 - accuracy: 0.8341 - val_loss: 7.7086 - val_accuracy: 0.6622\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.0468 - accuracy: 0.7526 - val_loss: 2.8275 - val_accuracy: 0.7911\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.6511 - accuracy: 0.8030 - val_loss: 13.3863 - val_accuracy: 0.6356\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.5941 - accuracy: 0.8178 - val_loss: 1.7309 - val_accuracy: 0.8756\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.3385 - accuracy: 0.8326 - val_loss: 3.0293 - val_accuracy: 0.8044\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4339 - accuracy: 0.8119 - val_loss: 1.5334 - val_accuracy: 0.8667\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6613 - accuracy: 0.7689 - val_loss: 4.0782 - val_accuracy: 0.7556\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2269 - accuracy: 0.8207 - val_loss: 5.7637 - val_accuracy: 0.6400\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5469 - accuracy: 0.7585 - val_loss: 3.3054 - val_accuracy: 0.7644\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.7256 - accuracy: 0.8385 - val_loss: 1.8014 - val_accuracy: 0.8400\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5523 - accuracy: 0.8430 - val_loss: 1.5210 - val_accuracy: 0.8578\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3987 - accuracy: 0.7822 - val_loss: 2.5267 - val_accuracy: 0.8444\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3055 - accuracy: 0.8059 - val_loss: 1.4191 - val_accuracy: 0.8711\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0023 - accuracy: 0.8059 - val_loss: 1.8668 - val_accuracy: 0.8489\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3805 - accuracy: 0.8400 - val_loss: 1.8469 - val_accuracy: 0.8400\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7939 - accuracy: 0.7985 - val_loss: 2.5116 - val_accuracy: 0.7822\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6076 - accuracy: 0.7585 - val_loss: 4.9488 - val_accuracy: 0.6756\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.7327 - accuracy: 0.7230 - val_loss: 1.8008 - val_accuracy: 0.8444\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8661 - accuracy: 0.8252 - val_loss: 1.4200 - val_accuracy: 0.8711\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3227 - accuracy: 0.8548 - val_loss: 1.3755 - val_accuracy: 0.8533\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3330 - accuracy: 0.7733 - val_loss: 6.8315 - val_accuracy: 0.6178\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7914 - accuracy: 0.7585 - val_loss: 2.8669 - val_accuracy: 0.7956\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8024 - accuracy: 0.8178 - val_loss: 7.2800 - val_accuracy: 0.6400\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8058 - accuracy: 0.7363 - val_loss: 3.7441 - val_accuracy: 0.7378\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.7304 - accuracy: 0.7867 - val_loss: 2.1641 - val_accuracy: 0.8444\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5412 - accuracy: 0.7659 - val_loss: 3.9226 - val_accuracy: 0.6933\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1638 - accuracy: 0.7852 - val_loss: 1.8366 - val_accuracy: 0.8489\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8500 - accuracy: 0.8222 - val_loss: 1.5313 - val_accuracy: 0.8444\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6212 - accuracy: 0.7570 - val_loss: 7.0424 - val_accuracy: 0.5733\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.4229 - accuracy: 0.6859 - val_loss: 2.0058 - val_accuracy: 0.8533\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.9577 - accuracy: 0.7541 - val_loss: 12.2612 - val_accuracy: 0.5422\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.8020 - accuracy: 0.7096 - val_loss: 6.8971 - val_accuracy: 0.6044\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1861 - accuracy: 0.7526 - val_loss: 20.3228 - val_accuracy: 0.4800\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 6.3812 - accuracy: 0.6844 - val_loss: 2.8568 - val_accuracy: 0.7733\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8035 - accuracy: 0.8252 - val_loss: 1.3747 - val_accuracy: 0.8711\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2109 - accuracy: 0.8504 - val_loss: 1.6726 - val_accuracy: 0.8533\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7968 - accuracy: 0.8089 - val_loss: 3.0900 - val_accuracy: 0.7600\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1587 - accuracy: 0.7926 - val_loss: 2.8743 - val_accuracy: 0.7467\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2917 - accuracy: 0.7896 - val_loss: 1.3309 - val_accuracy: 0.8711\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5366 - accuracy: 0.8222 - val_loss: 1.7821 - val_accuracy: 0.8400\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.6682 - accuracy: 0.6785 - val_loss: 5.4222 - val_accuracy: 0.8578\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.0275 - accuracy: 0.8326 - val_loss: 3.3300 - val_accuracy: 0.7778\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6941 - accuracy: 0.8207 - val_loss: 1.4264 - val_accuracy: 0.8533\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7000 - accuracy: 0.8148 - val_loss: 2.8258 - val_accuracy: 0.7600\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5068 - accuracy: 0.8356 - val_loss: 3.7893 - val_accuracy: 0.6844\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.9285 - accuracy: 0.8089 - val_loss: 6.7120 - val_accuracy: 0.5733\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8452 - accuracy: 0.7333 - val_loss: 6.5231 - val_accuracy: 0.5822\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5213 - accuracy: 0.7719 - val_loss: 3.6824 - val_accuracy: 0.7689\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3032 - accuracy: 0.7837 - val_loss: 3.4157 - val_accuracy: 0.7556\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1525 - accuracy: 0.8089 - val_loss: 3.4339 - val_accuracy: 0.8222\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2454 - accuracy: 0.7452 - val_loss: 2.1826 - val_accuracy: 0.8000\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3696 - accuracy: 0.8415 - val_loss: 3.2869 - val_accuracy: 0.7156\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.8910 - accuracy: 0.6504 - val_loss: 4.2963 - val_accuracy: 0.7289\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8188 - accuracy: 0.7585 - val_loss: 2.8111 - val_accuracy: 0.8711\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1211 - accuracy: 0.8207 - val_loss: 1.5449 - val_accuracy: 0.8578\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9262 - accuracy: 0.8178 - val_loss: 1.6479 - val_accuracy: 0.8489\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7467 - accuracy: 0.8296 - val_loss: 2.9150 - val_accuracy: 0.7378\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0074 - accuracy: 0.7807 - val_loss: 6.6068 - val_accuracy: 0.5778\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5.3662 - accuracy: 0.6756 - val_loss: 5.1381 - val_accuracy: 0.6178\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.2763 - accuracy: 0.7185 - val_loss: 2.2888 - val_accuracy: 0.8356\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3229 - accuracy: 0.8059 - val_loss: 2.5095 - val_accuracy: 0.7778\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6423 - accuracy: 0.8059 - val_loss: 1.8426 - val_accuracy: 0.8267\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4693 - accuracy: 0.8267 - val_loss: 3.6357 - val_accuracy: 0.7244\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3.6096 - accuracy: 0.7467 - val_loss: 4.0547 - val_accuracy: 0.7600\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8678 - accuracy: 0.8059 - val_loss: 3.0270 - val_accuracy: 0.8578\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8336 - accuracy: 0.8178 - val_loss: 3.3501 - val_accuracy: 0.7289\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0286 - accuracy: 0.8119 - val_loss: 2.9957 - val_accuracy: 0.7956\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8064 - accuracy: 0.8267 - val_loss: 3.1340 - val_accuracy: 0.7822\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0346 - accuracy: 0.8030 - val_loss: 3.3255 - val_accuracy: 0.7200\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3774 - accuracy: 0.7956 - val_loss: 4.2733 - val_accuracy: 0.6667\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6422 - accuracy: 0.7704 - val_loss: 3.9166 - val_accuracy: 0.6978\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.6236 - accuracy: 0.7407 - val_loss: 2.6776 - val_accuracy: 0.8489\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.9825 - accuracy: 0.7319 - val_loss: 4.0175 - val_accuracy: 0.7111\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1275 - accuracy: 0.7615 - val_loss: 1.6338 - val_accuracy: 0.8489\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.8207 - val_loss: 1.8707 - val_accuracy: 0.8800\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.7207 - accuracy: 0.7822 - val_loss: 9.0191 - val_accuracy: 0.5511\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4998 - accuracy: 0.7600 - val_loss: 1.2135 - val_accuracy: 0.8667\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3736 - accuracy: 0.8563 - val_loss: 1.9144 - val_accuracy: 0.8311\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6756 - accuracy: 0.8074 - val_loss: 1.5831 - val_accuracy: 0.8489\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2755 - accuracy: 0.8370 - val_loss: 4.0145 - val_accuracy: 0.6444\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1319 - accuracy: 0.7778 - val_loss: 3.8496 - val_accuracy: 0.6889\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0651 - accuracy: 0.7956 - val_loss: 3.1177 - val_accuracy: 0.7200\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7878 - accuracy: 0.8119 - val_loss: 2.8590 - val_accuracy: 0.7289\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5901 - accuracy: 0.7289 - val_loss: 6.0807 - val_accuracy: 0.5644\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8607 - accuracy: 0.7481 - val_loss: 2.2942 - val_accuracy: 0.8489\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8976 - accuracy: 0.7881 - val_loss: 1.3706 - val_accuracy: 0.8667\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.4109 - accuracy: 0.7615 - val_loss: 5.1904 - val_accuracy: 0.6133\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0237 - accuracy: 0.8015 - val_loss: 1.7744 - val_accuracy: 0.8622\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6918 - accuracy: 0.8133 - val_loss: 3.1872 - val_accuracy: 0.7333\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2277 - accuracy: 0.7274 - val_loss: 6.0946 - val_accuracy: 0.6000\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2538 - accuracy: 0.8030 - val_loss: 2.4127 - val_accuracy: 0.7600\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9766 - accuracy: 0.7822 - val_loss: 1.6650 - val_accuracy: 0.8222\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4579 - accuracy: 0.8030 - val_loss: 3.6168 - val_accuracy: 0.6756\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3721 - accuracy: 0.8222 - val_loss: 2.6823 - val_accuracy: 0.7378\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2976 - accuracy: 0.8267 - val_loss: 4.0449 - val_accuracy: 0.6489\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6852 - accuracy: 0.8119 - val_loss: 1.5757 - val_accuracy: 0.8622\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3521 - accuracy: 0.8415 - val_loss: 1.3267 - val_accuracy: 0.8800\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.5621 - accuracy: 0.8030 - val_loss: 2.2674 - val_accuracy: 0.7733\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9612 - accuracy: 0.7911 - val_loss: 5.3205 - val_accuracy: 0.5644\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.2621 - accuracy: 0.7422 - val_loss: 3.4913 - val_accuracy: 0.6489\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3821 - accuracy: 0.8059 - val_loss: 2.7065 - val_accuracy: 0.7422\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6086 - accuracy: 0.8000 - val_loss: 1.1800 - val_accuracy: 0.8400\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1107 - accuracy: 0.8370 - val_loss: 1.4070 - val_accuracy: 0.8267\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0635 - accuracy: 0.8370 - val_loss: 1.5254 - val_accuracy: 0.8356\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3388 - accuracy: 0.8163 - val_loss: 3.6791 - val_accuracy: 0.6222\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6548 - accuracy: 0.7511 - val_loss: 1.1628 - val_accuracy: 0.8489\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1877 - accuracy: 0.8178 - val_loss: 6.7578 - val_accuracy: 0.5244\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2927 - accuracy: 0.7185 - val_loss: 5.3651 - val_accuracy: 0.5556\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5773 - accuracy: 0.7822 - val_loss: 1.4370 - val_accuracy: 0.8844\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2432 - accuracy: 0.7644 - val_loss: 1.9487 - val_accuracy: 0.8356\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4629 - accuracy: 0.8030 - val_loss: 2.7035 - val_accuracy: 0.6933\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4779 - accuracy: 0.8133 - val_loss: 5.6944 - val_accuracy: 0.8444\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.7177 - accuracy: 0.8074 - val_loss: 1.8411 - val_accuracy: 0.8533\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4806 - accuracy: 0.8415 - val_loss: 1.3234 - val_accuracy: 0.8400\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7376 - accuracy: 0.7704 - val_loss: 1.5770 - val_accuracy: 0.8133\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0421 - accuracy: 0.7319 - val_loss: 1.4613 - val_accuracy: 0.8578\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.7252 - accuracy: 0.6711 - val_loss: 4.1971 - val_accuracy: 0.6089\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.5929 - accuracy: 0.6919 - val_loss: 6.7680 - val_accuracy: 0.5778\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.8258 - accuracy: 0.7259 - val_loss: 1.7618 - val_accuracy: 0.8178\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1384 - accuracy: 0.8222 - val_loss: 1.3307 - val_accuracy: 0.8311\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7941 - accuracy: 0.7689 - val_loss: 2.7506 - val_accuracy: 0.7067\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5227 - accuracy: 0.7304 - val_loss: 6.2836 - val_accuracy: 0.5511\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0569 - accuracy: 0.7644 - val_loss: 1.8636 - val_accuracy: 0.7867\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2623 - accuracy: 0.8059 - val_loss: 0.8762 - val_accuracy: 0.8756\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1332 - accuracy: 0.8133 - val_loss: 4.1109 - val_accuracy: 0.6000\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.4623 - accuracy: 0.6637 - val_loss: 2.9912 - val_accuracy: 0.6978\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7420 - accuracy: 0.7822 - val_loss: 2.4994 - val_accuracy: 0.7778\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.9134 - accuracy: 0.7274 - val_loss: 6.4070 - val_accuracy: 0.5556\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.3730 - accuracy: 0.7348 - val_loss: 4.0707 - val_accuracy: 0.8044\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6979 - accuracy: 0.7807 - val_loss: 1.4512 - val_accuracy: 0.8356\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7043 - accuracy: 0.7689 - val_loss: 4.6386 - val_accuracy: 0.5911\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5352 - accuracy: 0.8059 - val_loss: 2.0143 - val_accuracy: 0.7733\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4774 - accuracy: 0.8044 - val_loss: 0.8813 - val_accuracy: 0.8756\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3692 - accuracy: 0.8163 - val_loss: 1.3473 - val_accuracy: 0.8533\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.8607 - val_loss: 1.1259 - val_accuracy: 0.8400\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4117 - accuracy: 0.8148 - val_loss: 1.6873 - val_accuracy: 0.7644\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.2450 - accuracy: 0.8193 - val_loss: 4.3549 - val_accuracy: 0.6311\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.2421 - accuracy: 0.7200 - val_loss: 1.0975 - val_accuracy: 0.8444\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4613 - accuracy: 0.8089 - val_loss: 5.6662 - val_accuracy: 0.5867\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6325 - accuracy: 0.8089 - val_loss: 1.2552 - val_accuracy: 0.8800\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5745 - accuracy: 0.8222 - val_loss: 1.5331 - val_accuracy: 0.8622\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1440 - accuracy: 0.7615 - val_loss: 5.2290 - val_accuracy: 0.5911\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1925 - accuracy: 0.7704 - val_loss: 1.9183 - val_accuracy: 0.8044\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2862 - accuracy: 0.8133 - val_loss: 1.5822 - val_accuracy: 0.8044\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0260 - accuracy: 0.8193 - val_loss: 6.3820 - val_accuracy: 0.5600\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0132 - accuracy: 0.7541 - val_loss: 1.2839 - val_accuracy: 0.8756\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2854 - accuracy: 0.7970 - val_loss: 1.2367 - val_accuracy: 0.8356\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9162 - accuracy: 0.7511 - val_loss: 1.4166 - val_accuracy: 0.8178\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9885 - accuracy: 0.8341 - val_loss: 1.6702 - val_accuracy: 0.7733\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9710 - accuracy: 0.8385 - val_loss: 3.2422 - val_accuracy: 0.8444\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9513 - accuracy: 0.7570 - val_loss: 1.4585 - val_accuracy: 0.7867\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6150 - accuracy: 0.7022 - val_loss: 1.5765 - val_accuracy: 0.8356\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0635 - accuracy: 0.8370 - val_loss: 1.5532 - val_accuracy: 0.7600\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0743 - accuracy: 0.8133 - val_loss: 0.7800 - val_accuracy: 0.8578\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.8370 - val_loss: 2.9470 - val_accuracy: 0.6889\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5481 - accuracy: 0.7778 - val_loss: 6.3059 - val_accuracy: 0.5600\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.5797 - accuracy: 0.7437 - val_loss: 3.7022 - val_accuracy: 0.6267\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4450 - accuracy: 0.8044 - val_loss: 1.9313 - val_accuracy: 0.8267\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1759 - accuracy: 0.8474 - val_loss: 2.6944 - val_accuracy: 0.6933\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3967 - accuracy: 0.8074 - val_loss: 0.9687 - val_accuracy: 0.8489\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0089 - accuracy: 0.8296 - val_loss: 3.9777 - val_accuracy: 0.5956\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1674 - accuracy: 0.7778 - val_loss: 0.8889 - val_accuracy: 0.8578\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8843 - accuracy: 0.7659 - val_loss: 1.4172 - val_accuracy: 0.8489\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5391 - accuracy: 0.7941 - val_loss: 0.8993 - val_accuracy: 0.8711\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4996 - accuracy: 0.8059 - val_loss: 1.7724 - val_accuracy: 0.7467\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5824 - accuracy: 0.8015 - val_loss: 2.3841 - val_accuracy: 0.7956\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3367 - accuracy: 0.8163 - val_loss: 1.6015 - val_accuracy: 0.7822\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.8237 - val_loss: 5.3263 - val_accuracy: 0.5600\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6116 - accuracy: 0.7259 - val_loss: 3.5975 - val_accuracy: 0.6000\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.8780 - accuracy: 0.7363 - val_loss: 3.4095 - val_accuracy: 0.6444\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0985 - accuracy: 0.7867 - val_loss: 2.4484 - val_accuracy: 0.7244\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.0237 - accuracy: 0.7333 - val_loss: 2.3955 - val_accuracy: 0.7067\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9160 - accuracy: 0.7822 - val_loss: 1.4628 - val_accuracy: 0.8756\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4393 - accuracy: 0.7896 - val_loss: 3.0910 - val_accuracy: 0.7067\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9760 - accuracy: 0.7926 - val_loss: 6.0268 - val_accuracy: 0.5422\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4.4076 - accuracy: 0.6756 - val_loss: 1.6028 - val_accuracy: 0.7911\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1096 - accuracy: 0.7970 - val_loss: 4.7956 - val_accuracy: 0.6044\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.8669 - accuracy: 0.7852 - val_loss: 1.3049 - val_accuracy: 0.8622\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 1.4235 - accuracy: 0.8030 - val_loss: 1.2439 - val_accuracy: 0.8489\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 1.4659 - accuracy: 0.8133 - val_loss: 2.5450 - val_accuracy: 0.8000\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1327 - accuracy: 0.8207 - val_loss: 1.4971 - val_accuracy: 0.8089\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.8326 - val_loss: 1.7730 - val_accuracy: 0.7422\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7905 - accuracy: 0.8341 - val_loss: 1.2551 - val_accuracy: 0.8133\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.8356 - val_loss: 3.8634 - val_accuracy: 0.6133\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 2.0083 - accuracy: 0.7467 - val_loss: 5.2022 - val_accuracy: 0.5600\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 2.7875 - accuracy: 0.7526 - val_loss: 1.1400 - val_accuracy: 0.8356\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.8252 - val_loss: 4.0617 - val_accuracy: 0.5733\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.0838 - accuracy: 0.7111 - val_loss: 2.2409 - val_accuracy: 0.7244\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.8059 - val_loss: 1.6238 - val_accuracy: 0.7778\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3373 - accuracy: 0.7674 - val_loss: 0.8531 - val_accuracy: 0.8533\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.8444 - val_loss: 0.9560 - val_accuracy: 0.8178\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.8059 - val_loss: 2.2718 - val_accuracy: 0.6933\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0688 - accuracy: 0.8030 - val_loss: 0.6200 - val_accuracy: 0.8711\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1042 - accuracy: 0.8148 - val_loss: 1.2750 - val_accuracy: 0.7778\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5066 - accuracy: 0.7911 - val_loss: 1.9321 - val_accuracy: 0.6933\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2266 - accuracy: 0.7704 - val_loss: 2.1427 - val_accuracy: 0.8444\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.4963 - accuracy: 0.7867 - val_loss: 0.8469 - val_accuracy: 0.8533\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2006 - accuracy: 0.7926 - val_loss: 2.8212 - val_accuracy: 0.7822\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9190 - accuracy: 0.7748 - val_loss: 2.9034 - val_accuracy: 0.6133\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.1725 - accuracy: 0.7185 - val_loss: 1.3008 - val_accuracy: 0.8178\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1041 - accuracy: 0.8193 - val_loss: 0.6976 - val_accuracy: 0.8711\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.8281 - val_loss: 0.6564 - val_accuracy: 0.8756\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.8474 - val_loss: 0.6325 - val_accuracy: 0.8667\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7965 - accuracy: 0.8163 - val_loss: 2.0677 - val_accuracy: 0.6756\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5257 - accuracy: 0.7378 - val_loss: 1.2072 - val_accuracy: 0.8089\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2258 - accuracy: 0.7659 - val_loss: 3.3804 - val_accuracy: 0.5778\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8663 - accuracy: 0.8148 - val_loss: 1.0334 - val_accuracy: 0.8133\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.8430 - val_loss: 0.6899 - val_accuracy: 0.8489\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.7970 - val_loss: 0.9844 - val_accuracy: 0.8489\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7301 - accuracy: 0.7319 - val_loss: 1.6202 - val_accuracy: 0.8756\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9996 - accuracy: 0.7496 - val_loss: 1.0882 - val_accuracy: 0.8444\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.7600 - val_loss: 6.0131 - val_accuracy: 0.6489\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6701 - accuracy: 0.7778 - val_loss: 9.5039 - val_accuracy: 0.5333\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.1631 - accuracy: 0.6844 - val_loss: 0.9987 - val_accuracy: 0.8356\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.8059 - val_loss: 0.7022 - val_accuracy: 0.8756\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.8044 - val_loss: 1.1653 - val_accuracy: 0.8000\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8730 - accuracy: 0.7289 - val_loss: 0.7501 - val_accuracy: 0.8533\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.7852 - val_loss: 2.7496 - val_accuracy: 0.6089\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.6105 - accuracy: 0.7526 - val_loss: 0.7513 - val_accuracy: 0.8444\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0036 - accuracy: 0.8104 - val_loss: 0.8167 - val_accuracy: 0.8489\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6486 - accuracy: 0.7867 - val_loss: 1.2260 - val_accuracy: 0.8533\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9162 - accuracy: 0.8119 - val_loss: 0.7652 - val_accuracy: 0.8400\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.8104 - val_loss: 1.5562 - val_accuracy: 0.7467\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8481 - accuracy: 0.7081 - val_loss: 0.9439 - val_accuracy: 0.8533\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.8533 - val_loss: 0.8107 - val_accuracy: 0.8622\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7348 - accuracy: 0.8356 - val_loss: 1.3251 - val_accuracy: 0.7689\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8882 - accuracy: 0.8015 - val_loss: 2.9195 - val_accuracy: 0.5956\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3011 - accuracy: 0.7481 - val_loss: 0.6703 - val_accuracy: 0.8711\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.8119 - val_loss: 2.1323 - val_accuracy: 0.6489\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3501 - accuracy: 0.7496 - val_loss: 0.9601 - val_accuracy: 0.8756\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.7250 - accuracy: 0.7393 - val_loss: 1.9606 - val_accuracy: 0.7556\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2130 - accuracy: 0.8044 - val_loss: 0.6892 - val_accuracy: 0.8667\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7809 - accuracy: 0.8267 - val_loss: 0.9959 - val_accuracy: 0.8356\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.8267 - val_loss: 1.3760 - val_accuracy: 0.7422\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7785 - accuracy: 0.8074 - val_loss: 0.5925 - val_accuracy: 0.8667\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.8237 - val_loss: 0.8028 - val_accuracy: 0.8400\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.8385 - val_loss: 0.6396 - val_accuracy: 0.8489\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.8281 - val_loss: 0.9209 - val_accuracy: 0.8222\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.8015 - val_loss: 2.9530 - val_accuracy: 0.6222\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9483 - accuracy: 0.7378 - val_loss: 1.9438 - val_accuracy: 0.8400\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1420 - accuracy: 0.8207 - val_loss: 1.5268 - val_accuracy: 0.7600\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.2401 - accuracy: 0.7659 - val_loss: 0.7780 - val_accuracy: 0.8667\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.5315 - accuracy: 0.7304 - val_loss: 2.6400 - val_accuracy: 0.6000\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3247 - accuracy: 0.7600 - val_loss: 0.7066 - val_accuracy: 0.8667\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.8207 - val_loss: 1.0948 - val_accuracy: 0.7644\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8688 - accuracy: 0.8015 - val_loss: 2.8383 - val_accuracy: 0.5911\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.7896 - val_loss: 0.7569 - val_accuracy: 0.8267\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.8163 - val_loss: 2.5350 - val_accuracy: 0.5867\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.1071 - accuracy: 0.7659 - val_loss: 1.0950 - val_accuracy: 0.8133\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8360 - accuracy: 0.8207 - val_loss: 0.6634 - val_accuracy: 0.8533\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7500 - accuracy: 0.8178 - val_loss: 2.5701 - val_accuracy: 0.5822\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1.3622 - accuracy: 0.7674 - val_loss: 1.4659 - val_accuracy: 0.7289\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0800 - accuracy: 0.7719 - val_loss: 0.6688 - val_accuracy: 0.8489\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.8163 - val_loss: 0.5871 - val_accuracy: 0.8444\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.8356 - val_loss: 0.7527 - val_accuracy: 0.8489\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.8178 - val_loss: 0.7119 - val_accuracy: 0.8489\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.7556 - val_loss: 8.0854 - val_accuracy: 0.5378\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 3.5697 - accuracy: 0.6711 - val_loss: 0.8437 - val_accuracy: 0.8622\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8192 - accuracy: 0.8385 - val_loss: 3.8603 - val_accuracy: 0.5600\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.8166 - accuracy: 0.7763 - val_loss: 1.0783 - val_accuracy: 0.8356\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7964 - accuracy: 0.8222 - val_loss: 0.9692 - val_accuracy: 0.8267\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.8519 - val_loss: 1.3345 - val_accuracy: 0.7600\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.8207 - val_loss: 1.1995 - val_accuracy: 0.7778\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7879 - accuracy: 0.7867 - val_loss: 5.8907 - val_accuracy: 0.5333\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.1282 - accuracy: 0.7022 - val_loss: 0.6804 - val_accuracy: 0.8578\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.9532 - accuracy: 0.7852 - val_loss: 3.2699 - val_accuracy: 0.5778\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2.6703 - accuracy: 0.7037 - val_loss: 3.0643 - val_accuracy: 0.6978\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.9496 - accuracy: 0.7600 - val_loss: 1.5441 - val_accuracy: 0.7644\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.3908 - accuracy: 0.7407 - val_loss: 1.3209 - val_accuracy: 0.8222\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.8774 - accuracy: 0.8267 - val_loss: 3.6317 - val_accuracy: 0.5422\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2.2054 - accuracy: 0.6741 - val_loss: 3.3288 - val_accuracy: 0.5600\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1.6757 - accuracy: 0.7274 - val_loss: 1.0415 - val_accuracy: 0.8089\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.8370 - val_loss: 0.8078 - val_accuracy: 0.8533\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.7848 - accuracy: 0.8119 - val_loss: 1.6962 - val_accuracy: 0.7067\n",
      "8/8 [==============================] - 0s 613us/step\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=6, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_pred_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa696b51b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hist = history.history\n",
    "\n",
    "x = np.arange(0, 1000)\n",
    "y = hist['loss']\n",
    "y_val = hist['val_loss']\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, y_val)\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
