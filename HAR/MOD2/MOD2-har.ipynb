{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"../../../dataset/UCI_HAR/UCI HAR Dataset/features.txt\", sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
    "\n",
    "# 피쳐이름에 그룹바이와 cumcount를 적용한 데이터프레임을 만든다\n",
    "features_cc = features_df.groupby('column_name').cumcount() # (561, )의 시리즈 생성됨\n",
    "features_cc = pd.DataFrame(features_cc) # (561, 1)의 데이터프레임으로 변환\n",
    "features_cc.columns = ['cumcount'] # 칼럼명 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cc = features_cc.reset_index() # (561,2)가 된다.\n",
    "features_df = features_df.reset_index() # (561,3)이 된다.\n",
    "\n",
    "# 양쪽 데이터프레임 reset_index()의 결과로 생긴 'index'열을 기준으로 outer join(병합)한다.\n",
    "# 그럼 결과적으로 index, column_index, column_name, cumcount 4개의 열을 가진 데이터프레임이 생성된다.\n",
    "new_df = pd.merge(features_cc, features_df, on='index', how='outer')\n",
    "\n",
    "# 병합에 사용되었던 index 칼럼을 드랍한다.\n",
    "new_df = new_df.drop(['index'], axis=1) # column_index, column_name, cumcount의 (561,3)이 된다.\n",
    "\n",
    "# column_name과 cumcount를 합쳐서 하나의 column_name으로 만드는 과정이다\n",
    "# cumcount가 1이상일경우 column_name 뒤에 _1 또는 _2를 붙인다.\n",
    "new_df['column_name'] = new_df[['column_name', 'cumcount']].apply(lambda x: x[0]+'_'+str(x[1])\n",
    "                                                                if x[1]>0 else x[0], axis=1)\n",
    "\n",
    "# cumcount를 column_name을 새로짓는 데 사용하였으므로 이제 드랍한다.\n",
    "# 이 작업을 마치면 cumcount 칼럼이 없어져서 (561,2) 데이터프레임이 된다.\n",
    "new_df = new_df.drop(['cumcount'], axis=1) # column_index, column_name 두개의 (561,2) 가 된다.\n",
    "\n",
    "h = new_df['column_name'].value_counts()\n",
    "\n",
    "for i in h:\n",
    "    if (i == 3):\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z',\n",
       "       'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z',\n",
       "       'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z',\n",
       "       'tBodyAcc-max()-X', 'tBodyAcc-max()-Y', 'tBodyAcc-max()-Z',\n",
       "       'tBodyAcc-min()-X', 'tBodyAcc-min()-Y', 'tBodyAcc-min()-Z',\n",
       "       'tBodyAcc-sma()', 'tBodyAcc-energy()-X', 'tBodyAcc-energy()-Y',\n",
       "       'tBodyAcc-energy()-Z', 'tBodyAcc-iqr()-X', 'tBodyAcc-iqr()-Y',\n",
       "       'tBodyAcc-iqr()-Z', 'tBodyAcc-entropy()-X', 'tBodyAcc-entropy()-Y',\n",
       "       'tBodyAcc-entropy()-Z', 'tBodyAcc-arCoeff()-X,1',\n",
       "       'tBodyAcc-arCoeff()-X,2', 'tBodyAcc-arCoeff()-X,3',\n",
       "       'tBodyAcc-arCoeff()-X,4', 'tBodyAcc-arCoeff()-Y,1',\n",
       "       'tBodyAcc-arCoeff()-Y,2', 'tBodyAcc-arCoeff()-Y,3',\n",
       "       'tBodyAcc-arCoeff()-Y,4', 'tBodyAcc-arCoeff()-Z,1',\n",
       "       'tBodyAcc-arCoeff()-Z,2', 'tBodyAcc-arCoeff()-Z,3',\n",
       "       'tBodyAcc-arCoeff()-Z,4', 'tBodyAcc-correlation()-X,Y',\n",
       "       'tBodyAcc-correlation()-X,Z', 'tBodyAcc-correlation()-Y,Z',\n",
       "       'tGravityAcc-mean()-X', 'tGravityAcc-mean()-Y',\n",
       "       'tGravityAcc-mean()-Z', 'tGravityAcc-std()-X',\n",
       "       'tGravityAcc-std()-Y', 'tGravityAcc-std()-Z',\n",
       "       'tGravityAcc-mad()-X', 'tGravityAcc-mad()-Y',\n",
       "       'tGravityAcc-mad()-Z', 'tGravityAcc-max()-X',\n",
       "       'tGravityAcc-max()-Y', 'tGravityAcc-max()-Z',\n",
       "       'tGravityAcc-min()-X', 'tGravityAcc-min()-Y',\n",
       "       'tGravityAcc-min()-Z', 'tGravityAcc-sma()',\n",
       "       'tGravityAcc-energy()-X', 'tGravityAcc-energy()-Y',\n",
       "       'tGravityAcc-energy()-Z', 'tGravityAcc-iqr()-X',\n",
       "       'tGravityAcc-iqr()-Y', 'tGravityAcc-iqr()-Z',\n",
       "       'tGravityAcc-entropy()-X', 'tGravityAcc-entropy()-Y',\n",
       "       'tGravityAcc-entropy()-Z', 'tGravityAcc-arCoeff()-X,1',\n",
       "       'tGravityAcc-arCoeff()-X,2', 'tGravityAcc-arCoeff()-X,3',\n",
       "       'tGravityAcc-arCoeff()-X,4', 'tGravityAcc-arCoeff()-Y,1',\n",
       "       'tGravityAcc-arCoeff()-Y,2', 'tGravityAcc-arCoeff()-Y,3',\n",
       "       'tGravityAcc-arCoeff()-Y,4', 'tGravityAcc-arCoeff()-Z,1',\n",
       "       'tGravityAcc-arCoeff()-Z,2', 'tGravityAcc-arCoeff()-Z,3',\n",
       "       'tGravityAcc-arCoeff()-Z,4', 'tGravityAcc-correlation()-X,Y',\n",
       "       'tGravityAcc-correlation()-X,Z', 'tGravityAcc-correlation()-Y,Z',\n",
       "       'tBodyAccJerk-mean()-X', 'tBodyAccJerk-mean()-Y',\n",
       "       'tBodyAccJerk-mean()-Z', 'tBodyAccJerk-std()-X',\n",
       "       'tBodyAccJerk-std()-Y', 'tBodyAccJerk-std()-Z',\n",
       "       'tBodyAccJerk-mad()-X', 'tBodyAccJerk-mad()-Y',\n",
       "       'tBodyAccJerk-mad()-Z', 'tBodyAccJerk-max()-X',\n",
       "       'tBodyAccJerk-max()-Y', 'tBodyAccJerk-max()-Z',\n",
       "       'tBodyAccJerk-min()-X', 'tBodyAccJerk-min()-Y',\n",
       "       'tBodyAccJerk-min()-Z', 'tBodyAccJerk-sma()',\n",
       "       'tBodyAccJerk-energy()-X', 'tBodyAccJerk-energy()-Y',\n",
       "       'tBodyAccJerk-energy()-Z', 'tBodyAccJerk-iqr()-X',\n",
       "       'tBodyAccJerk-iqr()-Y', 'tBodyAccJerk-iqr()-Z',\n",
       "       'tBodyAccJerk-entropy()-X', 'tBodyAccJerk-entropy()-Y',\n",
       "       'tBodyAccJerk-entropy()-Z', 'tBodyAccJerk-arCoeff()-X,1',\n",
       "       'tBodyAccJerk-arCoeff()-X,2', 'tBodyAccJerk-arCoeff()-X,3',\n",
       "       'tBodyAccJerk-arCoeff()-X,4', 'tBodyAccJerk-arCoeff()-Y,1',\n",
       "       'tBodyAccJerk-arCoeff()-Y,2', 'tBodyAccJerk-arCoeff()-Y,3',\n",
       "       'tBodyAccJerk-arCoeff()-Y,4', 'tBodyAccJerk-arCoeff()-Z,1',\n",
       "       'tBodyAccJerk-arCoeff()-Z,2', 'tBodyAccJerk-arCoeff()-Z,3',\n",
       "       'tBodyAccJerk-arCoeff()-Z,4', 'tBodyAccJerk-correlation()-X,Y',\n",
       "       'tBodyAccJerk-correlation()-X,Z', 'tBodyAccJerk-correlation()-Y,Z',\n",
       "       'tBodyGyro-mean()-X', 'tBodyGyro-mean()-Y', 'tBodyGyro-mean()-Z',\n",
       "       'tBodyGyro-std()-X', 'tBodyGyro-std()-Y', 'tBodyGyro-std()-Z',\n",
       "       'tBodyGyro-mad()-X', 'tBodyGyro-mad()-Y', 'tBodyGyro-mad()-Z',\n",
       "       'tBodyGyro-max()-X', 'tBodyGyro-max()-Y', 'tBodyGyro-max()-Z',\n",
       "       'tBodyGyro-min()-X', 'tBodyGyro-min()-Y', 'tBodyGyro-min()-Z',\n",
       "       'tBodyGyro-sma()', 'tBodyGyro-energy()-X', 'tBodyGyro-energy()-Y',\n",
       "       'tBodyGyro-energy()-Z', 'tBodyGyro-iqr()-X', 'tBodyGyro-iqr()-Y',\n",
       "       'tBodyGyro-iqr()-Z', 'tBodyGyro-entropy()-X',\n",
       "       'tBodyGyro-entropy()-Y', 'tBodyGyro-entropy()-Z',\n",
       "       'tBodyGyro-arCoeff()-X,1', 'tBodyGyro-arCoeff()-X,2',\n",
       "       'tBodyGyro-arCoeff()-X,3', 'tBodyGyro-arCoeff()-X,4',\n",
       "       'tBodyGyro-arCoeff()-Y,1', 'tBodyGyro-arCoeff()-Y,2',\n",
       "       'tBodyGyro-arCoeff()-Y,3', 'tBodyGyro-arCoeff()-Y,4',\n",
       "       'tBodyGyro-arCoeff()-Z,1', 'tBodyGyro-arCoeff()-Z,2',\n",
       "       'tBodyGyro-arCoeff()-Z,3', 'tBodyGyro-arCoeff()-Z,4',\n",
       "       'tBodyGyro-correlation()-X,Y', 'tBodyGyro-correlation()-X,Z',\n",
       "       'tBodyGyro-correlation()-Y,Z', 'tBodyGyroJerk-mean()-X',\n",
       "       'tBodyGyroJerk-mean()-Y', 'tBodyGyroJerk-mean()-Z',\n",
       "       'tBodyGyroJerk-std()-X', 'tBodyGyroJerk-std()-Y',\n",
       "       'tBodyGyroJerk-std()-Z', 'tBodyGyroJerk-mad()-X',\n",
       "       'tBodyGyroJerk-mad()-Y', 'tBodyGyroJerk-mad()-Z',\n",
       "       'tBodyGyroJerk-max()-X', 'tBodyGyroJerk-max()-Y',\n",
       "       'tBodyGyroJerk-max()-Z', 'tBodyGyroJerk-min()-X',\n",
       "       'tBodyGyroJerk-min()-Y', 'tBodyGyroJerk-min()-Z',\n",
       "       'tBodyGyroJerk-sma()', 'tBodyGyroJerk-energy()-X',\n",
       "       'tBodyGyroJerk-energy()-Y', 'tBodyGyroJerk-energy()-Z',\n",
       "       'tBodyGyroJerk-iqr()-X', 'tBodyGyroJerk-iqr()-Y',\n",
       "       'tBodyGyroJerk-iqr()-Z', 'tBodyGyroJerk-entropy()-X',\n",
       "       'tBodyGyroJerk-entropy()-Y', 'tBodyGyroJerk-entropy()-Z',\n",
       "       'tBodyGyroJerk-arCoeff()-X,1', 'tBodyGyroJerk-arCoeff()-X,2',\n",
       "       'tBodyGyroJerk-arCoeff()-X,3', 'tBodyGyroJerk-arCoeff()-X,4',\n",
       "       'tBodyGyroJerk-arCoeff()-Y,1', 'tBodyGyroJerk-arCoeff()-Y,2',\n",
       "       'tBodyGyroJerk-arCoeff()-Y,3', 'tBodyGyroJerk-arCoeff()-Y,4',\n",
       "       'tBodyGyroJerk-arCoeff()-Z,1', 'tBodyGyroJerk-arCoeff()-Z,2',\n",
       "       'tBodyGyroJerk-arCoeff()-Z,3', 'tBodyGyroJerk-arCoeff()-Z,4',\n",
       "       'tBodyGyroJerk-correlation()-X,Y',\n",
       "       'tBodyGyroJerk-correlation()-X,Z',\n",
       "       'tBodyGyroJerk-correlation()-Y,Z', 'tBodyAccMag-mean()',\n",
       "       'tBodyAccMag-std()', 'tBodyAccMag-mad()', 'tBodyAccMag-max()',\n",
       "       'tBodyAccMag-min()', 'tBodyAccMag-sma()', 'tBodyAccMag-energy()',\n",
       "       'tBodyAccMag-iqr()', 'tBodyAccMag-entropy()',\n",
       "       'tBodyAccMag-arCoeff()1', 'tBodyAccMag-arCoeff()2',\n",
       "       'tBodyAccMag-arCoeff()3', 'tBodyAccMag-arCoeff()4',\n",
       "       'tGravityAccMag-mean()', 'tGravityAccMag-std()',\n",
       "       'tGravityAccMag-mad()', 'tGravityAccMag-max()',\n",
       "       'tGravityAccMag-min()', 'tGravityAccMag-sma()',\n",
       "       'tGravityAccMag-energy()', 'tGravityAccMag-iqr()',\n",
       "       'tGravityAccMag-entropy()', 'tGravityAccMag-arCoeff()1',\n",
       "       'tGravityAccMag-arCoeff()2', 'tGravityAccMag-arCoeff()3',\n",
       "       'tGravityAccMag-arCoeff()4', 'tBodyAccJerkMag-mean()',\n",
       "       'tBodyAccJerkMag-std()', 'tBodyAccJerkMag-mad()',\n",
       "       'tBodyAccJerkMag-max()', 'tBodyAccJerkMag-min()',\n",
       "       'tBodyAccJerkMag-sma()', 'tBodyAccJerkMag-energy()',\n",
       "       'tBodyAccJerkMag-iqr()', 'tBodyAccJerkMag-entropy()',\n",
       "       'tBodyAccJerkMag-arCoeff()1', 'tBodyAccJerkMag-arCoeff()2',\n",
       "       'tBodyAccJerkMag-arCoeff()3', 'tBodyAccJerkMag-arCoeff()4',\n",
       "       'tBodyGyroMag-mean()', 'tBodyGyroMag-std()', 'tBodyGyroMag-mad()',\n",
       "       'tBodyGyroMag-max()', 'tBodyGyroMag-min()', 'tBodyGyroMag-sma()',\n",
       "       'tBodyGyroMag-energy()', 'tBodyGyroMag-iqr()',\n",
       "       'tBodyGyroMag-entropy()', 'tBodyGyroMag-arCoeff()1',\n",
       "       'tBodyGyroMag-arCoeff()2', 'tBodyGyroMag-arCoeff()3',\n",
       "       'tBodyGyroMag-arCoeff()4', 'tBodyGyroJerkMag-mean()',\n",
       "       'tBodyGyroJerkMag-std()', 'tBodyGyroJerkMag-mad()',\n",
       "       'tBodyGyroJerkMag-max()', 'tBodyGyroJerkMag-min()',\n",
       "       'tBodyGyroJerkMag-sma()', 'tBodyGyroJerkMag-energy()',\n",
       "       'tBodyGyroJerkMag-iqr()', 'tBodyGyroJerkMag-entropy()',\n",
       "       'tBodyGyroJerkMag-arCoeff()1', 'tBodyGyroJerkMag-arCoeff()2',\n",
       "       'tBodyGyroJerkMag-arCoeff()3', 'tBodyGyroJerkMag-arCoeff()4',\n",
       "       'fBodyAcc-mean()-X', 'fBodyAcc-mean()-Y', 'fBodyAcc-mean()-Z',\n",
       "       'fBodyAcc-std()-X', 'fBodyAcc-std()-Y', 'fBodyAcc-std()-Z',\n",
       "       'fBodyAcc-mad()-X', 'fBodyAcc-mad()-Y', 'fBodyAcc-mad()-Z',\n",
       "       'fBodyAcc-max()-X', 'fBodyAcc-max()-Y', 'fBodyAcc-max()-Z',\n",
       "       'fBodyAcc-min()-X', 'fBodyAcc-min()-Y', 'fBodyAcc-min()-Z',\n",
       "       'fBodyAcc-sma()', 'fBodyAcc-energy()-X', 'fBodyAcc-energy()-Y',\n",
       "       'fBodyAcc-energy()-Z', 'fBodyAcc-iqr()-X', 'fBodyAcc-iqr()-Y',\n",
       "       'fBodyAcc-iqr()-Z', 'fBodyAcc-entropy()-X', 'fBodyAcc-entropy()-Y',\n",
       "       'fBodyAcc-entropy()-Z', 'fBodyAcc-maxInds-X', 'fBodyAcc-maxInds-Y',\n",
       "       'fBodyAcc-maxInds-Z', 'fBodyAcc-meanFreq()-X',\n",
       "       'fBodyAcc-meanFreq()-Y', 'fBodyAcc-meanFreq()-Z',\n",
       "       'fBodyAcc-skewness()-X', 'fBodyAcc-kurtosis()-X',\n",
       "       'fBodyAcc-skewness()-Y', 'fBodyAcc-kurtosis()-Y',\n",
       "       'fBodyAcc-skewness()-Z', 'fBodyAcc-kurtosis()-Z',\n",
       "       'fBodyAcc-bandsEnergy()-1,8', 'fBodyAcc-bandsEnergy()-9,16',\n",
       "       'fBodyAcc-bandsEnergy()-17,24', 'fBodyAcc-bandsEnergy()-25,32',\n",
       "       'fBodyAcc-bandsEnergy()-33,40', 'fBodyAcc-bandsEnergy()-41,48',\n",
       "       'fBodyAcc-bandsEnergy()-49,56', 'fBodyAcc-bandsEnergy()-57,64',\n",
       "       'fBodyAcc-bandsEnergy()-1,16', 'fBodyAcc-bandsEnergy()-17,32',\n",
       "       'fBodyAcc-bandsEnergy()-33,48', 'fBodyAcc-bandsEnergy()-49,64',\n",
       "       'fBodyAcc-bandsEnergy()-1,24', 'fBodyAcc-bandsEnergy()-25,48',\n",
       "       'fBodyAcc-bandsEnergy()-1,8_1', 'fBodyAcc-bandsEnergy()-9,16_1',\n",
       "       'fBodyAcc-bandsEnergy()-17,24_1', 'fBodyAcc-bandsEnergy()-25,32_1',\n",
       "       'fBodyAcc-bandsEnergy()-33,40_1', 'fBodyAcc-bandsEnergy()-41,48_1',\n",
       "       'fBodyAcc-bandsEnergy()-49,56_1', 'fBodyAcc-bandsEnergy()-57,64_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,16_1', 'fBodyAcc-bandsEnergy()-17,32_1',\n",
       "       'fBodyAcc-bandsEnergy()-33,48_1', 'fBodyAcc-bandsEnergy()-49,64_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,24_1', 'fBodyAcc-bandsEnergy()-25,48_1',\n",
       "       'fBodyAcc-bandsEnergy()-1,8_2', 'fBodyAcc-bandsEnergy()-9,16_2',\n",
       "       'fBodyAcc-bandsEnergy()-17,24_2', 'fBodyAcc-bandsEnergy()-25,32_2',\n",
       "       'fBodyAcc-bandsEnergy()-33,40_2', 'fBodyAcc-bandsEnergy()-41,48_2',\n",
       "       'fBodyAcc-bandsEnergy()-49,56_2', 'fBodyAcc-bandsEnergy()-57,64_2',\n",
       "       'fBodyAcc-bandsEnergy()-1,16_2', 'fBodyAcc-bandsEnergy()-17,32_2',\n",
       "       'fBodyAcc-bandsEnergy()-33,48_2', 'fBodyAcc-bandsEnergy()-49,64_2',\n",
       "       'fBodyAcc-bandsEnergy()-1,24_2', 'fBodyAcc-bandsEnergy()-25,48_2',\n",
       "       'fBodyAccJerk-mean()-X', 'fBodyAccJerk-mean()-Y',\n",
       "       'fBodyAccJerk-mean()-Z', 'fBodyAccJerk-std()-X',\n",
       "       'fBodyAccJerk-std()-Y', 'fBodyAccJerk-std()-Z',\n",
       "       'fBodyAccJerk-mad()-X', 'fBodyAccJerk-mad()-Y',\n",
       "       'fBodyAccJerk-mad()-Z', 'fBodyAccJerk-max()-X',\n",
       "       'fBodyAccJerk-max()-Y', 'fBodyAccJerk-max()-Z',\n",
       "       'fBodyAccJerk-min()-X', 'fBodyAccJerk-min()-Y',\n",
       "       'fBodyAccJerk-min()-Z', 'fBodyAccJerk-sma()',\n",
       "       'fBodyAccJerk-energy()-X', 'fBodyAccJerk-energy()-Y',\n",
       "       'fBodyAccJerk-energy()-Z', 'fBodyAccJerk-iqr()-X',\n",
       "       'fBodyAccJerk-iqr()-Y', 'fBodyAccJerk-iqr()-Z',\n",
       "       'fBodyAccJerk-entropy()-X', 'fBodyAccJerk-entropy()-Y',\n",
       "       'fBodyAccJerk-entropy()-Z', 'fBodyAccJerk-maxInds-X',\n",
       "       'fBodyAccJerk-maxInds-Y', 'fBodyAccJerk-maxInds-Z',\n",
       "       'fBodyAccJerk-meanFreq()-X', 'fBodyAccJerk-meanFreq()-Y',\n",
       "       'fBodyAccJerk-meanFreq()-Z', 'fBodyAccJerk-skewness()-X',\n",
       "       'fBodyAccJerk-kurtosis()-X', 'fBodyAccJerk-skewness()-Y',\n",
       "       'fBodyAccJerk-kurtosis()-Y', 'fBodyAccJerk-skewness()-Z',\n",
       "       'fBodyAccJerk-kurtosis()-Z', 'fBodyAccJerk-bandsEnergy()-1,8',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,8_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48_1',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,8_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-9,16_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,24_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,32_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,40_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-41,48_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,56_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-57,64_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,16_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-17,32_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-33,48_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-49,64_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-1,24_2',\n",
       "       'fBodyAccJerk-bandsEnergy()-25,48_2', 'fBodyGyro-mean()-X',\n",
       "       'fBodyGyro-mean()-Y', 'fBodyGyro-mean()-Z', 'fBodyGyro-std()-X',\n",
       "       'fBodyGyro-std()-Y', 'fBodyGyro-std()-Z', 'fBodyGyro-mad()-X',\n",
       "       'fBodyGyro-mad()-Y', 'fBodyGyro-mad()-Z', 'fBodyGyro-max()-X',\n",
       "       'fBodyGyro-max()-Y', 'fBodyGyro-max()-Z', 'fBodyGyro-min()-X',\n",
       "       'fBodyGyro-min()-Y', 'fBodyGyro-min()-Z', 'fBodyGyro-sma()',\n",
       "       'fBodyGyro-energy()-X', 'fBodyGyro-energy()-Y',\n",
       "       'fBodyGyro-energy()-Z', 'fBodyGyro-iqr()-X', 'fBodyGyro-iqr()-Y',\n",
       "       'fBodyGyro-iqr()-Z', 'fBodyGyro-entropy()-X',\n",
       "       'fBodyGyro-entropy()-Y', 'fBodyGyro-entropy()-Z',\n",
       "       'fBodyGyro-maxInds-X', 'fBodyGyro-maxInds-Y',\n",
       "       'fBodyGyro-maxInds-Z', 'fBodyGyro-meanFreq()-X',\n",
       "       'fBodyGyro-meanFreq()-Y', 'fBodyGyro-meanFreq()-Z',\n",
       "       'fBodyGyro-skewness()-X', 'fBodyGyro-kurtosis()-X',\n",
       "       'fBodyGyro-skewness()-Y', 'fBodyGyro-kurtosis()-Y',\n",
       "       'fBodyGyro-skewness()-Z', 'fBodyGyro-kurtosis()-Z',\n",
       "       'fBodyGyro-bandsEnergy()-1,8', 'fBodyGyro-bandsEnergy()-9,16',\n",
       "       'fBodyGyro-bandsEnergy()-17,24', 'fBodyGyro-bandsEnergy()-25,32',\n",
       "       'fBodyGyro-bandsEnergy()-33,40', 'fBodyGyro-bandsEnergy()-41,48',\n",
       "       'fBodyGyro-bandsEnergy()-49,56', 'fBodyGyro-bandsEnergy()-57,64',\n",
       "       'fBodyGyro-bandsEnergy()-1,16', 'fBodyGyro-bandsEnergy()-17,32',\n",
       "       'fBodyGyro-bandsEnergy()-33,48', 'fBodyGyro-bandsEnergy()-49,64',\n",
       "       'fBodyGyro-bandsEnergy()-1,24', 'fBodyGyro-bandsEnergy()-25,48',\n",
       "       'fBodyGyro-bandsEnergy()-1,8_1', 'fBodyGyro-bandsEnergy()-9,16_1',\n",
       "       'fBodyGyro-bandsEnergy()-17,24_1',\n",
       "       'fBodyGyro-bandsEnergy()-25,32_1',\n",
       "       'fBodyGyro-bandsEnergy()-33,40_1',\n",
       "       'fBodyGyro-bandsEnergy()-41,48_1',\n",
       "       'fBodyGyro-bandsEnergy()-49,56_1',\n",
       "       'fBodyGyro-bandsEnergy()-57,64_1',\n",
       "       'fBodyGyro-bandsEnergy()-1,16_1',\n",
       "       'fBodyGyro-bandsEnergy()-17,32_1',\n",
       "       'fBodyGyro-bandsEnergy()-33,48_1',\n",
       "       'fBodyGyro-bandsEnergy()-49,64_1',\n",
       "       'fBodyGyro-bandsEnergy()-1,24_1',\n",
       "       'fBodyGyro-bandsEnergy()-25,48_1', 'fBodyGyro-bandsEnergy()-1,8_2',\n",
       "       'fBodyGyro-bandsEnergy()-9,16_2',\n",
       "       'fBodyGyro-bandsEnergy()-17,24_2',\n",
       "       'fBodyGyro-bandsEnergy()-25,32_2',\n",
       "       'fBodyGyro-bandsEnergy()-33,40_2',\n",
       "       'fBodyGyro-bandsEnergy()-41,48_2',\n",
       "       'fBodyGyro-bandsEnergy()-49,56_2',\n",
       "       'fBodyGyro-bandsEnergy()-57,64_2',\n",
       "       'fBodyGyro-bandsEnergy()-1,16_2',\n",
       "       'fBodyGyro-bandsEnergy()-17,32_2',\n",
       "       'fBodyGyro-bandsEnergy()-33,48_2',\n",
       "       'fBodyGyro-bandsEnergy()-49,64_2',\n",
       "       'fBodyGyro-bandsEnergy()-1,24_2',\n",
       "       'fBodyGyro-bandsEnergy()-25,48_2', 'fBodyAccMag-mean()',\n",
       "       'fBodyAccMag-std()', 'fBodyAccMag-mad()', 'fBodyAccMag-max()',\n",
       "       'fBodyAccMag-min()', 'fBodyAccMag-sma()', 'fBodyAccMag-energy()',\n",
       "       'fBodyAccMag-iqr()', 'fBodyAccMag-entropy()',\n",
       "       'fBodyAccMag-maxInds', 'fBodyAccMag-meanFreq()',\n",
       "       'fBodyAccMag-skewness()', 'fBodyAccMag-kurtosis()',\n",
       "       'fBodyBodyAccJerkMag-mean()', 'fBodyBodyAccJerkMag-std()',\n",
       "       'fBodyBodyAccJerkMag-mad()', 'fBodyBodyAccJerkMag-max()',\n",
       "       'fBodyBodyAccJerkMag-min()', 'fBodyBodyAccJerkMag-sma()',\n",
       "       'fBodyBodyAccJerkMag-energy()', 'fBodyBodyAccJerkMag-iqr()',\n",
       "       'fBodyBodyAccJerkMag-entropy()', 'fBodyBodyAccJerkMag-maxInds',\n",
       "       'fBodyBodyAccJerkMag-meanFreq()', 'fBodyBodyAccJerkMag-skewness()',\n",
       "       'fBodyBodyAccJerkMag-kurtosis()', 'fBodyBodyGyroMag-mean()',\n",
       "       'fBodyBodyGyroMag-std()', 'fBodyBodyGyroMag-mad()',\n",
       "       'fBodyBodyGyroMag-max()', 'fBodyBodyGyroMag-min()',\n",
       "       'fBodyBodyGyroMag-sma()', 'fBodyBodyGyroMag-energy()',\n",
       "       'fBodyBodyGyroMag-iqr()', 'fBodyBodyGyroMag-entropy()',\n",
       "       'fBodyBodyGyroMag-maxInds', 'fBodyBodyGyroMag-meanFreq()',\n",
       "       'fBodyBodyGyroMag-skewness()', 'fBodyBodyGyroMag-kurtosis()',\n",
       "       'fBodyBodyGyroJerkMag-mean()', 'fBodyBodyGyroJerkMag-std()',\n",
       "       'fBodyBodyGyroJerkMag-mad()', 'fBodyBodyGyroJerkMag-max()',\n",
       "       'fBodyBodyGyroJerkMag-min()', 'fBodyBodyGyroJerkMag-sma()',\n",
       "       'fBodyBodyGyroJerkMag-energy()', 'fBodyBodyGyroJerkMag-iqr()',\n",
       "       'fBodyBodyGyroJerkMag-entropy()', 'fBodyBodyGyroJerkMag-maxInds',\n",
       "       'fBodyBodyGyroJerkMag-meanFreq()',\n",
       "       'fBodyBodyGyroJerkMag-skewness()',\n",
       "       'fBodyBodyGyroJerkMag-kurtosis()', 'angle(tBodyAccMean,gravity)',\n",
       "       'angle(tBodyAccJerkMean),gravityMean)',\n",
       "       'angle(tBodyGyroMean,gravityMean)',\n",
       "       'angle(tBodyGyroJerkMean,gravityMean)', 'angle(X,gravityMean)',\n",
       "       'angle(Y,gravityMean)', 'angle(Z,gravityMean)'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['column_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity\n",
       "0            5\n",
       "1            5\n",
       "2            5\n",
       "3            5\n",
       "4            5\n",
       "...        ...\n",
       "7347         2\n",
       "7348         2\n",
       "7349         2\n",
       "7350         2\n",
       "7351         2\n",
       "\n",
       "[7352 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"../../../dataset/UCI_HAR/UCI HAR Dataset/train/X_train.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_train = pd.read_csv(\"../../../dataset/UCI_HAR/UCI HAR Dataset/train/y_train.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "X_test = pd.read_csv(\"../../../dataset/UCI_HAR/UCI HAR Dataset/test/X_test.txt\", header=None, sep=\"\\s+\", names=new_df['column_name'].values)\n",
    "y_test = pd.read_csv(\"../../../dataset/UCI_HAR/UCI HAR Dataset/test/y_test.txt\", header=None, sep=\"\\s+\", names=['activity'])\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200642</td>\n",
       "      <td>-0.063683</td>\n",
       "      <td>-0.419628</td>\n",
       "      <td>-0.868814</td>\n",
       "      <td>-0.939441</td>\n",
       "      <td>-0.737529</td>\n",
       "      <td>-0.859817</td>\n",
       "      <td>-0.939019</td>\n",
       "      <td>-0.766437</td>\n",
       "      <td>-0.856036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>-0.276399</td>\n",
       "      <td>-0.360603</td>\n",
       "      <td>0.062940</td>\n",
       "      <td>-0.778427</td>\n",
       "      <td>-0.026080</td>\n",
       "      <td>-0.687219</td>\n",
       "      <td>0.407946</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055948</td>\n",
       "      <td>0.031486</td>\n",
       "      <td>-0.253908</td>\n",
       "      <td>-0.875426</td>\n",
       "      <td>-0.923902</td>\n",
       "      <td>-0.849304</td>\n",
       "      <td>-0.868531</td>\n",
       "      <td>-0.921998</td>\n",
       "      <td>-0.848928</td>\n",
       "      <td>-0.871359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897357</td>\n",
       "      <td>-0.767990</td>\n",
       "      <td>0.133011</td>\n",
       "      <td>-0.021461</td>\n",
       "      <td>-1.218805</td>\n",
       "      <td>1.484470</td>\n",
       "      <td>-0.694138</td>\n",
       "      <td>0.409117</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073515</td>\n",
       "      <td>-0.043416</td>\n",
       "      <td>-0.076295</td>\n",
       "      <td>-0.869039</td>\n",
       "      <td>-0.907760</td>\n",
       "      <td>-0.893785</td>\n",
       "      <td>-0.863137</td>\n",
       "      <td>-0.898854</td>\n",
       "      <td>-0.896701</td>\n",
       "      <td>-0.863323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260878</td>\n",
       "      <td>-0.438316</td>\n",
       "      <td>-0.377840</td>\n",
       "      <td>0.391976</td>\n",
       "      <td>0.151207</td>\n",
       "      <td>1.704201</td>\n",
       "      <td>-0.702239</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.026502</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066696</td>\n",
       "      <td>-0.208422</td>\n",
       "      <td>-0.249712</td>\n",
       "      <td>-0.870626</td>\n",
       "      <td>-0.940022</td>\n",
       "      <td>-0.921805</td>\n",
       "      <td>-0.864503</td>\n",
       "      <td>-0.938124</td>\n",
       "      <td>-0.925279</td>\n",
       "      <td>-0.863323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.463155</td>\n",
       "      <td>-0.135025</td>\n",
       "      <td>-0.033637</td>\n",
       "      <td>1.037851</td>\n",
       "      <td>-1.003019</td>\n",
       "      <td>-0.701684</td>\n",
       "      <td>0.414650</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030469</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>-0.109848</td>\n",
       "      <td>-0.875188</td>\n",
       "      <td>-0.934878</td>\n",
       "      <td>-0.921343</td>\n",
       "      <td>-0.867384</td>\n",
       "      <td>-0.931789</td>\n",
       "      <td>-0.928028</td>\n",
       "      <td>-0.870260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138515</td>\n",
       "      <td>-0.240313</td>\n",
       "      <td>0.340406</td>\n",
       "      <td>0.268486</td>\n",
       "      <td>1.125918</td>\n",
       "      <td>-1.276282</td>\n",
       "      <td>-0.700152</td>\n",
       "      <td>0.425463</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.186180</td>\n",
       "      <td>0.070699</td>\n",
       "      <td>-0.873397</td>\n",
       "      <td>-0.954117</td>\n",
       "      <td>-0.933139</td>\n",
       "      <td>-0.865748</td>\n",
       "      <td>-0.953493</td>\n",
       "      <td>-0.940363</td>\n",
       "      <td>-0.870260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742707</td>\n",
       "      <td>-0.713107</td>\n",
       "      <td>0.219586</td>\n",
       "      <td>-0.324856</td>\n",
       "      <td>0.437830</td>\n",
       "      <td>-0.757922</td>\n",
       "      <td>-0.703603</td>\n",
       "      <td>0.424358</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.070680</td>\n",
       "      <td>-0.047671</td>\n",
       "      <td>-0.015559</td>\n",
       "      <td>-0.872474</td>\n",
       "      <td>-0.907757</td>\n",
       "      <td>-0.903754</td>\n",
       "      <td>-0.864275</td>\n",
       "      <td>-0.903852</td>\n",
       "      <td>-0.910339</td>\n",
       "      <td>-0.867538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279795</td>\n",
       "      <td>0.197889</td>\n",
       "      <td>-0.657546</td>\n",
       "      <td>-0.519341</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>-0.384001</td>\n",
       "      <td>-0.708525</td>\n",
       "      <td>0.415441</td>\n",
       "      <td>0.048386</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041908</td>\n",
       "      <td>-0.313491</td>\n",
       "      <td>-0.286403</td>\n",
       "      <td>-0.871668</td>\n",
       "      <td>-0.906847</td>\n",
       "      <td>-0.900094</td>\n",
       "      <td>-0.863055</td>\n",
       "      <td>-0.904297</td>\n",
       "      <td>-0.910015</td>\n",
       "      <td>-0.867538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700031</td>\n",
       "      <td>0.661908</td>\n",
       "      <td>-0.087811</td>\n",
       "      <td>1.320191</td>\n",
       "      <td>-0.938078</td>\n",
       "      <td>0.990421</td>\n",
       "      <td>-0.706310</td>\n",
       "      <td>0.420848</td>\n",
       "      <td>0.052091</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039929</td>\n",
       "      <td>-0.099375</td>\n",
       "      <td>-0.205007</td>\n",
       "      <td>-0.873382</td>\n",
       "      <td>-0.895938</td>\n",
       "      <td>-0.905077</td>\n",
       "      <td>-0.865674</td>\n",
       "      <td>-0.885617</td>\n",
       "      <td>-0.913390</td>\n",
       "      <td>-0.866823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117163</td>\n",
       "      <td>0.170041</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>0.175674</td>\n",
       "      <td>-0.399562</td>\n",
       "      <td>0.258981</td>\n",
       "      <td>-0.700359</td>\n",
       "      <td>0.438343</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.189550</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>-0.867755</td>\n",
       "      <td>-0.918844</td>\n",
       "      <td>-0.911221</td>\n",
       "      <td>-0.860507</td>\n",
       "      <td>-0.919424</td>\n",
       "      <td>-0.916439</td>\n",
       "      <td>-0.865776</td>\n",
       "      <td>...</td>\n",
       "      <td>2.014197</td>\n",
       "      <td>2.489717</td>\n",
       "      <td>-0.086925</td>\n",
       "      <td>-0.289813</td>\n",
       "      <td>-0.808199</td>\n",
       "      <td>-0.135349</td>\n",
       "      <td>-0.700990</td>\n",
       "      <td>0.442807</td>\n",
       "      <td>0.079173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.200642          -0.063683          -0.419628         -0.868814   \n",
       "1           0.055948           0.031486          -0.253908         -0.875426   \n",
       "2           0.073515          -0.043416          -0.076295         -0.869039   \n",
       "3           0.066696          -0.208422          -0.249712         -0.870626   \n",
       "4           0.030469           0.027587          -0.109848         -0.875188   \n",
       "5           0.038582           0.186180           0.070699         -0.873397   \n",
       "6           0.070680          -0.047671          -0.015559         -0.872474   \n",
       "7           0.041908          -0.313491          -0.286403         -0.871668   \n",
       "8           0.039929          -0.099375          -0.205007         -0.873382   \n",
       "9           0.086790           0.189550           0.054314         -0.867755   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.939441         -0.737529         -0.859817         -0.939019   \n",
       "1         -0.923902         -0.849304         -0.868531         -0.921998   \n",
       "2         -0.907760         -0.893785         -0.863137         -0.898854   \n",
       "3         -0.940022         -0.921805         -0.864503         -0.938124   \n",
       "4         -0.934878         -0.921343         -0.867384         -0.931789   \n",
       "5         -0.954117         -0.933139         -0.865748         -0.953493   \n",
       "6         -0.907757         -0.903754         -0.864275         -0.903852   \n",
       "7         -0.906847         -0.900094         -0.863055         -0.904297   \n",
       "8         -0.895938         -0.905077         -0.865674         -0.885617   \n",
       "9         -0.918844         -0.911221         -0.860507         -0.919424   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.766437         -0.856036  ...                         0.025960   \n",
       "1         -0.848928         -0.871359  ...                        -0.897357   \n",
       "2         -0.896701         -0.863323  ...                        -0.260878   \n",
       "3         -0.925279         -0.863323  ...                         0.591045   \n",
       "4         -0.928028         -0.870260  ...                        -0.138515   \n",
       "5         -0.940363         -0.870260  ...                        -0.742707   \n",
       "6         -0.910339         -0.867538  ...                         0.279795   \n",
       "7         -0.910015         -0.867538  ...                         0.700031   \n",
       "8         -0.913390         -0.866823  ...                         0.117163   \n",
       "9         -0.916439         -0.865776  ...                         2.014197   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.276399                    -0.360603   \n",
       "1                        -0.767990                     0.133011   \n",
       "2                        -0.438316                    -0.377840   \n",
       "3                         0.463155                    -0.135025   \n",
       "4                        -0.240313                     0.340406   \n",
       "5                        -0.713107                     0.219586   \n",
       "6                         0.197889                    -0.657546   \n",
       "7                         0.661908                    -0.087811   \n",
       "8                         0.170041                     0.012681   \n",
       "9                         2.489717                    -0.086925   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.062940                         -0.778427   \n",
       "1                             -0.021461                         -1.218805   \n",
       "2                              0.391976                          0.151207   \n",
       "3                             -0.033637                          1.037851   \n",
       "4                              0.268486                          1.125918   \n",
       "5                             -0.324856                          0.437830   \n",
       "6                             -0.519341                          0.009718   \n",
       "7                              1.320191                         -0.938078   \n",
       "8                              0.175674                         -0.399562   \n",
       "9                             -0.289813                         -0.808199   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.026080             -0.687219   \n",
       "1                              1.484470             -0.694138   \n",
       "2                              1.704201             -0.702239   \n",
       "3                             -1.003019             -0.701684   \n",
       "4                             -1.276282             -0.700152   \n",
       "5                             -0.757922             -0.703603   \n",
       "6                             -0.384001             -0.708525   \n",
       "7                              0.990421             -0.706310   \n",
       "8                              0.258981             -0.700359   \n",
       "9                             -0.135349             -0.700990   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  label  \n",
       "0              0.407946             -0.007568      5  \n",
       "1              0.409117              0.007875      5  \n",
       "2              0.410288              0.026502      5  \n",
       "3              0.414650              0.031714      5  \n",
       "4              0.425463              0.045225      5  \n",
       "5              0.424358              0.051552      5  \n",
       "6              0.415441              0.048386      5  \n",
       "7              0.420848              0.052091      5  \n",
       "8              0.438343              0.068615      5  \n",
       "9              0.442807              0.079173      5  \n",
       "\n",
       "[10 rows x 562 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(data = X_train, columns = new_df['column_name'].values)\n",
    "scaled_X_test = pd.DataFrame(data = X_test, columns = new_df['column_name'].values)\n",
    "scaled_X_train['label'] = y_train.values\n",
    "scaled_X_test['label'] = y_test.values\n",
    "\n",
    "X_train = scaled_X_train\n",
    "X_test = scaled_X_test\n",
    "\n",
    "scaled_X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "\n",
    "# The steps to take from one segment to the next; if this value is equal to TIME_PERIODS, then there is\n",
    "# no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label statistics::\n",
      "[[   1 1226]\n",
      " [   2 1073]\n",
      " [   3  986]\n",
      " [   4 1286]\n",
      " [   5 1374]\n",
      " [   6 1407]]\n",
      "Test data label statistics::\n",
      "[[  1 496]\n",
      " [  2 471]\n",
      " [  3 420]\n",
      " [  4 491]\n",
      " [  5 532]\n",
      " [  6 537]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print (\"Train data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  \n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print (\"Test data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7337, 15, 561) (7337, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 15 # 한 데이터마다 몇 블록으로 묶을지\n",
    "STEP = 1 # 블록을 만들 때 얼마나 건너뛰면서 만들지\n",
    "\n",
    "X_train, y_train = create_dataset(X_train[new_df['column_name'].values], X_train.label, TIME_STEPS,\n",
    "                                  STEP)\n",
    "X_test, y_test = create_dataset(X_test[new_df['column_name'].values], X_test.label, TIME_STEPS, STEP)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimtaeyoon/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# cnn model vary kernel size\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose,epochs,batch_size=1,10,32 \n",
    "\n",
    "n_timesteps,n_features,n_outputs=X_train.shape[1],X_train.shape[2],y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(Bidirectional(LSTM(units = 128, input_shape = [X_train.shape[1], X_train.shape[2]])))\n",
    "# model.add(Dropout(rate = 0.5))\n",
    "# model.add(Dense(units = 128, activation = \"relu\"))\n",
    "# model.add(Dense(y_train.shape[1], activation = \"softmax\"))\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                160256    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,222\n",
      "Trainable params: 177,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "207/207 [==============================] - 3s 9ms/step - loss: 0.5568 - acc: 0.7757 - val_loss: 0.1972 - val_acc: 0.9251\n",
      "Epoch 2/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.2597 - acc: 0.8999 - val_loss: 0.1236 - val_acc: 0.9523\n",
      "Epoch 3/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.2077 - acc: 0.9267 - val_loss: 0.0848 - val_acc: 0.9714\n",
      "Epoch 4/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.1413 - acc: 0.9527 - val_loss: 0.0961 - val_acc: 0.9632\n",
      "Epoch 5/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.1223 - acc: 0.9553 - val_loss: 0.0773 - val_acc: 0.9700\n",
      "Epoch 6/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.1222 - acc: 0.9547 - val_loss: 0.0558 - val_acc: 0.9796\n",
      "Epoch 7/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0877 - acc: 0.9664 - val_loss: 0.0809 - val_acc: 0.9714\n",
      "Epoch 8/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0845 - acc: 0.9714 - val_loss: 0.1337 - val_acc: 0.9496\n",
      "Epoch 9/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0619 - acc: 0.9788 - val_loss: 0.0642 - val_acc: 0.9728\n",
      "Epoch 10/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0652 - acc: 0.9774 - val_loss: 0.0296 - val_acc: 0.9946\n",
      "Epoch 11/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0711 - acc: 0.9756 - val_loss: 0.0280 - val_acc: 0.9918\n",
      "Epoch 12/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0642 - acc: 0.9796 - val_loss: 0.0485 - val_acc: 0.9809\n",
      "Epoch 13/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0613 - acc: 0.9777 - val_loss: 0.0319 - val_acc: 0.9891\n",
      "Epoch 14/500\n",
      "207/207 [==============================] - 2s 7ms/step - loss: 0.0416 - acc: 0.9855 - val_loss: 0.1475 - val_acc: 0.9605\n",
      "Epoch 15/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0345 - acc: 0.9883 - val_loss: 0.0128 - val_acc: 0.9946\n",
      "Epoch 16/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0430 - acc: 0.9844 - val_loss: 0.0274 - val_acc: 0.9905\n",
      "Epoch 17/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0498 - acc: 0.9820 - val_loss: 0.0598 - val_acc: 0.9768\n",
      "Epoch 18/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0489 - acc: 0.9827 - val_loss: 0.0262 - val_acc: 0.9891\n",
      "Epoch 19/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0160 - val_acc: 0.9932\n",
      "Epoch 20/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0344 - acc: 0.9871 - val_loss: 0.0274 - val_acc: 0.9946\n",
      "Epoch 21/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0389 - acc: 0.9900 - val_loss: 0.0282 - val_acc: 0.9891\n",
      "Epoch 22/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0401 - acc: 0.9868 - val_loss: 0.0668 - val_acc: 0.9700\n",
      "Epoch 23/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0350 - acc: 0.9879 - val_loss: 0.0228 - val_acc: 0.9932\n",
      "Epoch 24/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0513 - acc: 0.9814 - val_loss: 0.0239 - val_acc: 0.9877\n",
      "Epoch 25/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0351 - acc: 0.9885 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "Epoch 26/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0292 - acc: 0.9902 - val_loss: 0.0245 - val_acc: 0.9932\n",
      "Epoch 27/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0272 - acc: 0.9905 - val_loss: 0.0086 - val_acc: 0.9959\n",
      "Epoch 28/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0220 - acc: 0.9909 - val_loss: 0.0340 - val_acc: 0.9905\n",
      "Epoch 29/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0431 - acc: 0.9850 - val_loss: 0.0218 - val_acc: 0.9959\n",
      "Epoch 30/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0475 - val_acc: 0.9850\n",
      "Epoch 31/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0307 - acc: 0.9908 - val_loss: 0.1260 - val_acc: 0.9673\n",
      "Epoch 32/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0407 - acc: 0.9868 - val_loss: 0.0435 - val_acc: 0.9877\n",
      "Epoch 33/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0383 - acc: 0.9864 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 34/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0228 - acc: 0.9923 - val_loss: 0.0450 - val_acc: 0.9809\n",
      "Epoch 35/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0171 - acc: 0.9933 - val_loss: 0.0967 - val_acc: 0.9768\n",
      "Epoch 36/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0250 - acc: 0.9917 - val_loss: 0.1347 - val_acc: 0.9728\n",
      "Epoch 37/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0153 - acc: 0.9953 - val_loss: 0.1187 - val_acc: 0.9755\n",
      "Epoch 38/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0169 - val_acc: 0.9946\n",
      "Epoch 39/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0181 - acc: 0.9935 - val_loss: 0.0310 - val_acc: 0.9905\n",
      "Epoch 40/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0356 - acc: 0.9880 - val_loss: 0.0282 - val_acc: 0.9864\n",
      "Epoch 41/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0227 - acc: 0.9923 - val_loss: 0.0633 - val_acc: 0.9768\n",
      "Epoch 42/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0501 - acc: 0.9835 - val_loss: 0.0129 - val_acc: 0.9946\n",
      "Epoch 43/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0337 - acc: 0.9876 - val_loss: 0.0133 - val_acc: 0.9946\n",
      "Epoch 44/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0191 - acc: 0.9930 - val_loss: 0.1157 - val_acc: 0.9768\n",
      "Epoch 45/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0215 - acc: 0.9923 - val_loss: 0.0494 - val_acc: 0.9864\n",
      "Epoch 46/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0265 - acc: 0.9911 - val_loss: 0.0317 - val_acc: 0.9864\n",
      "Epoch 47/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0215 - acc: 0.9921 - val_loss: 0.0139 - val_acc: 0.9959\n",
      "Epoch 48/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0217 - acc: 0.9923 - val_loss: 0.0491 - val_acc: 0.9782\n",
      "Epoch 49/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0225 - val_acc: 0.9932\n",
      "Epoch 50/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0144 - val_acc: 0.9946\n",
      "Epoch 51/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0115 - acc: 0.9952 - val_loss: 0.0510 - val_acc: 0.9768\n",
      "Epoch 52/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.2192 - val_acc: 0.9673\n",
      "Epoch 53/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0347 - acc: 0.9885 - val_loss: 0.0226 - val_acc: 0.9864\n",
      "Epoch 54/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0283 - acc: 0.9906 - val_loss: 0.1397 - val_acc: 0.9659\n",
      "Epoch 55/500\n",
      "207/207 [==============================] - 3s 12ms/step - loss: 0.0198 - acc: 0.9939 - val_loss: 0.0111 - val_acc: 0.9946\n",
      "Epoch 56/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0438 - val_acc: 0.9864\n",
      "Epoch 57/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0186 - acc: 0.9944 - val_loss: 0.0871 - val_acc: 0.9687\n",
      "Epoch 58/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.0229 - val_acc: 0.9891\n",
      "Epoch 59/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0156 - val_acc: 0.9946\n",
      "Epoch 60/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.0174 - val_acc: 0.9946\n",
      "Epoch 61/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0348 - acc: 0.9918 - val_loss: 0.0231 - val_acc: 0.9946\n",
      "Epoch 62/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0124 - val_acc: 0.9959\n",
      "Epoch 63/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0149 - acc: 0.9944 - val_loss: 0.0778 - val_acc: 0.9850\n",
      "Epoch 64/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0283 - acc: 0.9917 - val_loss: 0.0847 - val_acc: 0.9714\n",
      "Epoch 65/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0209 - acc: 0.9941 - val_loss: 0.0473 - val_acc: 0.9891\n",
      "Epoch 66/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "Epoch 67/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "Epoch 68/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0453 - val_acc: 0.9905\n",
      "Epoch 69/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.2657 - val_acc: 0.9632\n",
      "Epoch 70/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0170 - acc: 0.9952 - val_loss: 0.0925 - val_acc: 0.9659\n",
      "Epoch 71/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.1647 - val_acc: 0.9605\n",
      "Epoch 72/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0250 - acc: 0.9926 - val_loss: 0.0128 - val_acc: 0.9946\n",
      "Epoch 73/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0212 - acc: 0.9923 - val_loss: 0.0205 - val_acc: 0.9905\n",
      "Epoch 74/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0162 - acc: 0.9950 - val_loss: 0.0101 - val_acc: 0.9946\n",
      "Epoch 75/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0133 - val_acc: 0.9959\n",
      "Epoch 76/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0264 - val_acc: 0.9932\n",
      "Epoch 77/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0131 - acc: 0.9947 - val_loss: 0.0275 - val_acc: 0.9905\n",
      "Epoch 78/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0216 - acc: 0.9924 - val_loss: 0.0272 - val_acc: 0.9891\n",
      "Epoch 79/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0186 - val_acc: 0.9946\n",
      "Epoch 80/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0130 - acc: 0.9959 - val_loss: 0.1984 - val_acc: 0.9619\n",
      "Epoch 81/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0108 - val_acc: 0.9959\n",
      "Epoch 82/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0117 - val_acc: 0.9986\n",
      "Epoch 83/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.0070 - val_acc: 0.9946\n",
      "Epoch 84/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0173 - acc: 0.9939 - val_loss: 0.0246 - val_acc: 0.9932\n",
      "Epoch 85/500\n",
      "207/207 [==============================] - 4s 18ms/step - loss: 0.0110 - acc: 0.9956 - val_loss: 0.0390 - val_acc: 0.9877\n",
      "Epoch 86/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0678 - val_acc: 0.9850\n",
      "Epoch 87/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0167 - val_acc: 0.9973\n",
      "Epoch 88/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0179 - val_acc: 0.9959\n",
      "Epoch 89/500\n",
      "207/207 [==============================] - 3s 13ms/step - loss: 0.0178 - acc: 0.9936 - val_loss: 0.0192 - val_acc: 0.9905\n",
      "Epoch 90/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0152 - acc: 0.9938 - val_loss: 0.0435 - val_acc: 0.9850\n",
      "Epoch 91/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0110 - acc: 0.9955 - val_loss: 0.0212 - val_acc: 0.9932\n",
      "Epoch 92/500\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0256 - val_acc: 0.9905\n",
      "Epoch 93/500\n",
      "207/207 [==============================] - 3s 16ms/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0657 - val_acc: 0.9864\n",
      "Epoch 94/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0193 - acc: 0.9941 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "Epoch 95/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0136 - acc: 0.9952 - val_loss: 0.0286 - val_acc: 0.9877\n",
      "Epoch 96/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0098 - acc: 0.9965 - val_loss: 0.0211 - val_acc: 0.9946\n",
      "Epoch 97/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0219 - val_acc: 0.9918\n",
      "Epoch 98/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Epoch 99/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0141 - acc: 0.9958 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 100/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0096 - acc: 0.9959 - val_loss: 0.0108 - val_acc: 0.9959\n",
      "Epoch 101/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0070 - acc: 0.9973 - val_loss: 0.0695 - val_acc: 0.9850\n",
      "Epoch 102/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0239 - acc: 0.9921 - val_loss: 0.1158 - val_acc: 0.9673\n",
      "Epoch 103/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0197 - acc: 0.9945 - val_loss: 0.0143 - val_acc: 0.9946\n",
      "Epoch 104/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "Epoch 105/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0146 - acc: 0.9947 - val_loss: 0.0083 - val_acc: 0.9973\n",
      "Epoch 106/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0108 - acc: 0.9958 - val_loss: 0.0212 - val_acc: 0.9973\n",
      "Epoch 107/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0750 - val_acc: 0.9864\n",
      "Epoch 108/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0188 - acc: 0.9932 - val_loss: 0.0135 - val_acc: 0.9959\n",
      "Epoch 109/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0187 - val_acc: 0.9959\n",
      "Epoch 110/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0966 - val_acc: 0.9687\n",
      "Epoch 111/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0071 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9946\n",
      "Epoch 112/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.0337 - val_acc: 0.9932\n",
      "Epoch 113/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0254 - val_acc: 0.9946\n",
      "Epoch 114/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.0334 - val_acc: 0.9932\n",
      "Epoch 115/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0833 - val_acc: 0.9796\n",
      "Epoch 116/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0459 - val_acc: 0.9891\n",
      "Epoch 117/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0121 - acc: 0.9961 - val_loss: 0.1512 - val_acc: 0.9578\n",
      "Epoch 118/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0244 - val_acc: 0.9946\n",
      "Epoch 119/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0202 - acc: 0.9952 - val_loss: 0.0454 - val_acc: 0.9905\n",
      "Epoch 120/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.0400 - val_acc: 0.9932\n",
      "Epoch 121/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0443 - val_acc: 0.9918\n",
      "Epoch 122/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0103 - acc: 0.9968 - val_loss: 0.0702 - val_acc: 0.9905\n",
      "Epoch 123/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9932\n",
      "Epoch 124/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0722 - val_acc: 0.9864\n",
      "Epoch 125/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0044 - acc: 0.9983 - val_loss: 0.0514 - val_acc: 0.9932\n",
      "Epoch 126/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0252 - acc: 0.9930 - val_loss: 0.0270 - val_acc: 0.9946\n",
      "Epoch 127/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0079 - acc: 0.9979 - val_loss: 0.0397 - val_acc: 0.9918\n",
      "Epoch 128/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0303 - val_acc: 0.9946\n",
      "Epoch 129/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.1922 - val_acc: 0.9728\n",
      "Epoch 130/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0202 - val_acc: 0.9973\n",
      "Epoch 131/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0783 - val_acc: 0.9877\n",
      "Epoch 132/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0223 - val_acc: 0.9959\n",
      "Epoch 133/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0191 - val_acc: 0.9959\n",
      "Epoch 134/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0225 - val_acc: 0.9959\n",
      "Epoch 135/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0200 - acc: 0.9938 - val_loss: 0.0316 - val_acc: 0.9905\n",
      "Epoch 136/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0100 - acc: 0.9962 - val_loss: 0.0381 - val_acc: 0.9891\n",
      "Epoch 137/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0185 - val_acc: 0.9946\n",
      "Epoch 138/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0168 - val_acc: 0.9959\n",
      "Epoch 139/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0131 - val_acc: 0.9946\n",
      "Epoch 140/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0516 - val_acc: 0.9823\n",
      "Epoch 141/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.0259 - val_acc: 0.9946\n",
      "Epoch 142/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0193 - val_acc: 0.9959\n",
      "Epoch 143/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0151 - val_acc: 0.9973\n",
      "Epoch 144/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0155 - val_acc: 0.9932\n",
      "Epoch 145/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0126 - acc: 0.9959 - val_loss: 0.0315 - val_acc: 0.9918\n",
      "Epoch 146/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0406 - val_acc: 0.9932\n",
      "Epoch 147/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0105 - acc: 0.9965 - val_loss: 0.0298 - val_acc: 0.9946\n",
      "Epoch 148/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0834 - val_acc: 0.9728\n",
      "Epoch 149/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0098 - acc: 0.9977 - val_loss: 0.0149 - val_acc: 0.9973\n",
      "Epoch 150/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0216 - val_acc: 0.9946\n",
      "Epoch 151/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0165 - val_acc: 0.9959\n",
      "Epoch 152/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0138 - val_acc: 0.9946\n",
      "Epoch 153/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0110 - val_acc: 0.9973\n",
      "Epoch 154/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0463 - val_acc: 0.9891\n",
      "Epoch 155/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.0158 - val_acc: 0.9959\n",
      "Epoch 156/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0117 - acc: 0.9970 - val_loss: 0.0207 - val_acc: 0.9959\n",
      "Epoch 157/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0142 - acc: 0.9950 - val_loss: 0.0212 - val_acc: 0.9959\n",
      "Epoch 158/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0048 - acc: 0.9980 - val_loss: 0.0190 - val_acc: 0.9946\n",
      "Epoch 159/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0788 - val_acc: 0.9823\n",
      "Epoch 160/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0049 - val_acc: 0.9986\n",
      "Epoch 161/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0177 - val_acc: 0.9946\n",
      "Epoch 162/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0170 - val_acc: 0.9932\n",
      "Epoch 163/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0256 - val_acc: 0.9959\n",
      "Epoch 164/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0158 - val_acc: 0.9946\n",
      "Epoch 165/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0035 - acc: 0.9986 - val_loss: 0.0756 - val_acc: 0.9864\n",
      "Epoch 166/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0316 - val_acc: 0.9932\n",
      "Epoch 167/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0403 - val_acc: 0.9918\n",
      "Epoch 168/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0608 - val_acc: 0.9905\n",
      "Epoch 169/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0125 - acc: 0.9955 - val_loss: 0.0493 - val_acc: 0.9932\n",
      "Epoch 170/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0685 - val_acc: 0.9877\n",
      "Epoch 171/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "Epoch 172/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0191 - acc: 0.9959 - val_loss: 0.0451 - val_acc: 0.9905\n",
      "Epoch 173/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0211 - val_acc: 0.9946\n",
      "Epoch 174/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0143 - val_acc: 0.9959\n",
      "Epoch 175/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0249 - val_acc: 0.9946\n",
      "Epoch 176/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0453 - val_acc: 0.9932\n",
      "Epoch 177/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0137 - val_acc: 0.9959\n",
      "Epoch 178/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0171 - val_acc: 0.9959\n",
      "Epoch 179/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0193 - val_acc: 0.9946\n",
      "Epoch 180/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0142 - acc: 0.9959 - val_loss: 0.0626 - val_acc: 0.9782\n",
      "Epoch 181/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0327 - val_acc: 0.9891\n",
      "Epoch 182/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0330 - acc: 0.9909 - val_loss: 0.0291 - val_acc: 0.9905\n",
      "Epoch 183/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0250 - val_acc: 0.9918\n",
      "Epoch 184/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0081 - val_acc: 0.9986\n",
      "Epoch 185/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0157 - val_acc: 0.9973\n",
      "Epoch 186/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0060 - acc: 0.9974 - val_loss: 0.0172 - val_acc: 0.9959\n",
      "Epoch 187/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0218 - val_acc: 0.9973\n",
      "Epoch 188/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0123 - acc: 0.9970 - val_loss: 0.0384 - val_acc: 0.9891\n",
      "Epoch 189/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0084 - acc: 0.9965 - val_loss: 0.0155 - val_acc: 0.9986\n",
      "Epoch 190/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0052 - acc: 0.9988 - val_loss: 0.0184 - val_acc: 0.9973\n",
      "Epoch 191/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0227 - val_acc: 0.9959\n",
      "Epoch 192/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0293 - val_acc: 0.9932\n",
      "Epoch 193/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0043 - acc: 0.9983 - val_loss: 0.0206 - val_acc: 0.9959\n",
      "Epoch 194/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.1789 - val_acc: 0.9646\n",
      "Epoch 195/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9977 - val_loss: 0.0177 - val_acc: 0.9973\n",
      "Epoch 196/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0268 - val_acc: 0.9946\n",
      "Epoch 197/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0768 - val_acc: 0.9877\n",
      "Epoch 198/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0062 - val_acc: 0.9973\n",
      "Epoch 199/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0259 - val_acc: 0.9932\n",
      "Epoch 200/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0219 - val_acc: 0.9932\n",
      "Epoch 201/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0195 - val_acc: 0.9946\n",
      "Epoch 202/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0145 - val_acc: 0.9959\n",
      "Epoch 203/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0108 - acc: 0.9959 - val_loss: 0.0810 - val_acc: 0.9877\n",
      "Epoch 204/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0145 - acc: 0.9949 - val_loss: 0.0106 - val_acc: 0.9959\n",
      "Epoch 205/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0134 - val_acc: 0.9918\n",
      "Epoch 206/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.0619 - val_acc: 0.9891\n",
      "Epoch 207/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0350 - val_acc: 0.9946\n",
      "Epoch 208/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0245 - val_acc: 0.9946\n",
      "Epoch 209/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.0313 - val_acc: 0.9959\n",
      "Epoch 210/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0100 - val_acc: 0.9959\n",
      "Epoch 211/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.0135 - val_acc: 0.9986\n",
      "Epoch 212/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0203 - val_acc: 0.9959\n",
      "Epoch 213/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0487 - val_acc: 0.9932\n",
      "Epoch 214/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.0381 - val_acc: 0.9946\n",
      "Epoch 215/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0343 - val_acc: 0.9946\n",
      "Epoch 216/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0237 - val_acc: 0.9932\n",
      "Epoch 217/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0372 - val_acc: 0.9959\n",
      "Epoch 218/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0713 - val_acc: 0.9850\n",
      "Epoch 219/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0198 - val_acc: 0.9946\n",
      "Epoch 220/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0326 - val_acc: 0.9946\n",
      "Epoch 221/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "Epoch 222/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0409 - val_acc: 0.9877\n",
      "Epoch 223/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 0.0192 - val_acc: 0.9959\n",
      "Epoch 224/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0039 - acc: 0.9985 - val_loss: 0.0208 - val_acc: 0.9946\n",
      "Epoch 225/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0249 - val_acc: 0.9946\n",
      "Epoch 226/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0301 - val_acc: 0.9946\n",
      "Epoch 227/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0123 - acc: 0.9968 - val_loss: 0.0163 - val_acc: 0.9973\n",
      "Epoch 228/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0095 - acc: 0.9977 - val_loss: 0.0243 - val_acc: 0.9946\n",
      "Epoch 229/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0225 - val_acc: 0.9946\n",
      "Epoch 230/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0359 - val_acc: 0.9932\n",
      "Epoch 231/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0464 - val_acc: 0.9918\n",
      "Epoch 232/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0480 - val_acc: 0.9932\n",
      "Epoch 233/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0212 - acc: 0.9949 - val_loss: 0.0189 - val_acc: 0.9959\n",
      "Epoch 234/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0090 - acc: 0.9973 - val_loss: 0.0967 - val_acc: 0.9891\n",
      "Epoch 235/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0978 - val_acc: 0.9864\n",
      "Epoch 236/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0491 - val_acc: 0.9946\n",
      "Epoch 237/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0526 - val_acc: 0.9946\n",
      "Epoch 238/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0341 - val_acc: 0.9946\n",
      "Epoch 239/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0415 - val_acc: 0.9932\n",
      "Epoch 240/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9918\n",
      "Epoch 241/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0407 - val_acc: 0.9946\n",
      "Epoch 242/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0039 - acc: 0.9982 - val_loss: 0.0387 - val_acc: 0.9918\n",
      "Epoch 243/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0410 - val_acc: 0.9932\n",
      "Epoch 244/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0153 - acc: 0.9968 - val_loss: 0.0265 - val_acc: 0.9959\n",
      "Epoch 245/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0325 - val_acc: 0.9877\n",
      "Epoch 246/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0480 - val_acc: 0.9891\n",
      "Epoch 247/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0403 - val_acc: 0.9932\n",
      "Epoch 248/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0284 - val_acc: 0.9946\n",
      "Epoch 249/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0443 - val_acc: 0.9905\n",
      "Epoch 250/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0502 - val_acc: 0.9918\n",
      "Epoch 251/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0477 - val_acc: 0.9918\n",
      "Epoch 252/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0454 - val_acc: 0.9905\n",
      "Epoch 253/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.1556 - val_acc: 0.9809\n",
      "Epoch 254/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0373 - val_acc: 0.9918\n",
      "Epoch 255/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.1603 - val_acc: 0.9796\n",
      "Epoch 256/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0319 - val_acc: 0.9918\n",
      "Epoch 257/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0111 - val_acc: 0.9973\n",
      "Epoch 258/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0103 - val_acc: 0.9959\n",
      "Epoch 259/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0192 - val_acc: 0.9946\n",
      "Epoch 260/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0303 - val_acc: 0.9946\n",
      "Epoch 261/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0037 - acc: 0.9985 - val_loss: 0.0332 - val_acc: 0.9946\n",
      "Epoch 262/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "Epoch 263/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0209 - acc: 0.9947 - val_loss: 0.0224 - val_acc: 0.9946\n",
      "Epoch 264/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0284 - val_acc: 0.9932\n",
      "Epoch 265/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0314 - val_acc: 0.9932\n",
      "Epoch 266/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0395 - val_acc: 0.9932\n",
      "Epoch 267/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0025 - acc: 0.9986 - val_loss: 0.0370 - val_acc: 0.9932\n",
      "Epoch 268/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 0.2773 - val_acc: 0.9591\n",
      "Epoch 269/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 270/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0616 - val_acc: 0.9864\n",
      "Epoch 271/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0535 - val_acc: 0.9891\n",
      "Epoch 272/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0096 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9905\n",
      "Epoch 273/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0047 - acc: 0.9980 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 274/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0147 - acc: 0.9949 - val_loss: 0.0660 - val_acc: 0.9850\n",
      "Epoch 275/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 276/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 277/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0238 - val_acc: 0.9918\n",
      "Epoch 278/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0304 - val_acc: 0.9946\n",
      "Epoch 279/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0413 - val_acc: 0.9932\n",
      "Epoch 280/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0390 - val_acc: 0.9932\n",
      "Epoch 281/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0282 - val_acc: 0.9932\n",
      "Epoch 282/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9973\n",
      "Epoch 283/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0135 - val_acc: 0.9946\n",
      "Epoch 284/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0142 - val_acc: 0.9932\n",
      "Epoch 285/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0195 - val_acc: 0.9959\n",
      "Epoch 286/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0396 - val_acc: 0.9932\n",
      "Epoch 287/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 3.6838e-04 - acc: 0.9998 - val_loss: 0.0405 - val_acc: 0.9946\n",
      "Epoch 288/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0024 - acc: 0.9986 - val_loss: 0.0580 - val_acc: 0.9932\n",
      "Epoch 289/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9946\n",
      "Epoch 290/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0463 - val_acc: 0.9918\n",
      "Epoch 291/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0058 - acc: 0.9979 - val_loss: 0.0260 - val_acc: 0.9946\n",
      "Epoch 292/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0213 - acc: 0.9949 - val_loss: 0.0272 - val_acc: 0.9905\n",
      "Epoch 293/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0224 - val_acc: 0.9932\n",
      "Epoch 294/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0485 - val_acc: 0.9823\n",
      "Epoch 295/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0189 - val_acc: 0.9946\n",
      "Epoch 296/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.0068 - val_acc: 0.9973\n",
      "Epoch 297/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9986\n",
      "Epoch 298/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0111 - val_acc: 0.9959\n",
      "Epoch 299/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0077 - val_acc: 0.9973\n",
      "Epoch 300/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0141 - val_acc: 0.9946\n",
      "Epoch 301/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0230 - val_acc: 0.9959\n",
      "Epoch 302/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0203 - acc: 0.9945 - val_loss: 0.0571 - val_acc: 0.9823\n",
      "Epoch 303/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0588 - val_acc: 0.9877\n",
      "Epoch 304/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.0952 - val_acc: 0.9850\n",
      "Epoch 305/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0421 - val_acc: 0.9918\n",
      "Epoch 306/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0027 - acc: 0.9988 - val_loss: 0.4270 - val_acc: 0.9605\n",
      "Epoch 307/500\n",
      "207/207 [==============================] - 3s 15ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0168 - val_acc: 0.9959\n",
      "Epoch 308/500\n",
      "207/207 [==============================] - 3s 14ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0293 - val_acc: 0.9959\n",
      "Epoch 309/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0235 - val_acc: 0.9973\n",
      "Epoch 310/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.0306 - val_acc: 0.9946\n",
      "Epoch 311/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0145 - val_acc: 0.9973\n",
      "Epoch 312/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0029 - acc: 0.9985 - val_loss: 0.0203 - val_acc: 0.9959\n",
      "Epoch 313/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0361 - val_acc: 0.9932\n",
      "Epoch 314/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0022 - acc: 0.9989 - val_loss: 0.0390 - val_acc: 0.9959\n",
      "Epoch 315/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0405 - val_acc: 0.9946\n",
      "Epoch 316/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0089 - val_acc: 0.9973\n",
      "Epoch 317/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.0262 - val_acc: 0.9932\n",
      "Epoch 318/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0094 - val_acc: 0.9946\n",
      "Epoch 319/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0246 - val_acc: 0.9959\n",
      "Epoch 320/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 321/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0055 - val_acc: 0.9973\n",
      "Epoch 322/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0070 - val_acc: 0.9959\n",
      "Epoch 323/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0010 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9973\n",
      "Epoch 324/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0047 - acc: 0.9989 - val_loss: 0.0495 - val_acc: 0.9946\n",
      "Epoch 325/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0389 - val_acc: 0.9946\n",
      "Epoch 326/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 0.0234 - val_acc: 0.9973\n",
      "Epoch 327/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0769 - val_acc: 0.9905\n",
      "Epoch 328/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0098 - acc: 0.9973 - val_loss: 0.0072 - val_acc: 0.9973\n",
      "Epoch 329/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0132 - val_acc: 0.9946\n",
      "Epoch 330/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.0106 - val_acc: 0.9973\n",
      "Epoch 331/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0083 - acc: 0.9983 - val_loss: 0.2624 - val_acc: 0.9673\n",
      "Epoch 332/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0037 - acc: 0.9986 - val_loss: 0.0163 - val_acc: 0.9959\n",
      "Epoch 333/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0303 - val_acc: 0.9946\n",
      "Epoch 334/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0023 - acc: 0.9989 - val_loss: 0.0702 - val_acc: 0.9864\n",
      "Epoch 335/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0072 - acc: 0.9986 - val_loss: 0.1083 - val_acc: 0.9850\n",
      "Epoch 336/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0148 - val_acc: 0.9959\n",
      "Epoch 337/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0025 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9973\n",
      "Epoch 338/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0122 - val_acc: 0.9973\n",
      "Epoch 339/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.0058 - val_acc: 0.9973\n",
      "Epoch 340/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0199 - val_acc: 0.9959\n",
      "Epoch 341/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0303 - val_acc: 0.9918\n",
      "Epoch 342/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0127 - val_acc: 0.9959\n",
      "Epoch 343/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 6.7735e-04 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 0.9905\n",
      "Epoch 344/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0013 - acc: 0.9994 - val_loss: 0.0254 - val_acc: 0.9959\n",
      "Epoch 345/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0251 - val_acc: 0.9959\n",
      "Epoch 346/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 3.8233e-04 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 0.9959\n",
      "Epoch 347/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 8.6741e-04 - acc: 0.9997 - val_loss: 0.0184 - val_acc: 0.9973\n",
      "Epoch 348/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.1759 - val_acc: 0.9755\n",
      "Epoch 349/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0085 - val_acc: 0.9973\n",
      "Epoch 350/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0128 - val_acc: 0.9946\n",
      "Epoch 351/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0039 - acc: 0.9985 - val_loss: 0.0135 - val_acc: 0.9973\n",
      "Epoch 352/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0110 - val_acc: 0.9973\n",
      "Epoch 353/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0034 - acc: 0.9988 - val_loss: 0.0159 - val_acc: 0.9959\n",
      "Epoch 354/500\n",
      "207/207 [==============================] - 2s 12ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0149 - val_acc: 0.9973\n",
      "Epoch 355/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0130 - val_acc: 0.9973\n",
      "Epoch 356/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0395 - val_acc: 0.9946\n",
      "Epoch 357/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0631 - val_acc: 0.9864\n",
      "Epoch 358/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0222 - val_acc: 0.9946\n",
      "Epoch 359/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0020 - acc: 0.9991 - val_loss: 0.1675 - val_acc: 0.9768\n",
      "Epoch 360/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0142 - val_acc: 0.9973\n",
      "Epoch 361/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0750 - val_acc: 0.9905\n",
      "Epoch 362/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0361 - val_acc: 0.9946\n",
      "Epoch 363/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0519 - val_acc: 0.9932\n",
      "Epoch 364/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0194 - val_acc: 0.9946\n",
      "Epoch 365/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9959\n",
      "Epoch 366/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0185 - val_acc: 0.9946\n",
      "Epoch 367/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 368/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0142 - acc: 0.9977 - val_loss: 0.2418 - val_acc: 0.9741\n",
      "Epoch 369/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.2418 - val_acc: 0.9741\n",
      "Epoch 370/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0062 - acc: 0.9994 - val_loss: 0.3616 - val_acc: 0.9687\n",
      "Epoch 371/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.2384 - val_acc: 0.9755\n",
      "Epoch 372/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.2203 - val_acc: 0.9755\n",
      "Epoch 373/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.2552 - val_acc: 0.9741\n",
      "Epoch 374/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.1604 - val_acc: 0.9823\n",
      "Epoch 375/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0581 - val_acc: 0.9905\n",
      "Epoch 376/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0071 - val_acc: 0.9973\n",
      "Epoch 377/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0166 - val_acc: 0.9946\n",
      "Epoch 378/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0123 - val_acc: 0.9959\n",
      "Epoch 379/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0175 - val_acc: 0.9959\n",
      "Epoch 380/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0192 - val_acc: 0.9959\n",
      "Epoch 381/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9973\n",
      "Epoch 382/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0078 - val_acc: 0.9973\n",
      "Epoch 383/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0180 - val_acc: 0.9973\n",
      "Epoch 384/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0145 - acc: 0.9959 - val_loss: 0.0941 - val_acc: 0.9809\n",
      "Epoch 385/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0153 - val_acc: 0.9973\n",
      "Epoch 386/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0151 - val_acc: 0.9973\n",
      "Epoch 387/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0109 - acc: 0.9968 - val_loss: 0.0054 - val_acc: 0.9973\n",
      "Epoch 388/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0074 - acc: 0.9985 - val_loss: 0.0202 - val_acc: 0.9946\n",
      "Epoch 389/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0167 - val_acc: 0.9946\n",
      "Epoch 390/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0386 - val_acc: 0.9918\n",
      "Epoch 391/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0769 - val_acc: 0.9877\n",
      "Epoch 392/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0076 - acc: 0.9982 - val_loss: 0.1715 - val_acc: 0.9659\n",
      "Epoch 393/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0730 - val_acc: 0.9837\n",
      "Epoch 394/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0064 - acc: 0.9976 - val_loss: 0.0513 - val_acc: 0.9877\n",
      "Epoch 395/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.0281 - val_acc: 0.9905\n",
      "Epoch 396/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0059 - acc: 0.9976 - val_loss: 0.0066 - val_acc: 0.9973\n",
      "Epoch 397/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0052 - acc: 0.9979 - val_loss: 0.0245 - val_acc: 0.9905\n",
      "Epoch 398/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.1518 - val_acc: 0.9687\n",
      "Epoch 399/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0958 - val_acc: 0.9891\n",
      "Epoch 400/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0436 - val_acc: 0.9905\n",
      "Epoch 401/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0056 - acc: 0.9988 - val_loss: 0.3415 - val_acc: 0.9673\n",
      "Epoch 402/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0359 - val_acc: 0.9918\n",
      "Epoch 403/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.2677 - val_acc: 0.9687\n",
      "Epoch 404/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0209 - val_acc: 0.9959\n",
      "Epoch 405/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0104 - val_acc: 0.9959\n",
      "Epoch 406/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0044 - acc: 0.9992 - val_loss: 0.0165 - val_acc: 0.9959\n",
      "Epoch 407/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0222 - val_acc: 0.9946\n",
      "Epoch 408/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9932\n",
      "Epoch 409/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0016 - acc: 0.9992 - val_loss: 0.1217 - val_acc: 0.9864\n",
      "Epoch 410/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0606 - val_acc: 0.9918\n",
      "Epoch 411/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.1257 - val_acc: 0.9837\n",
      "Epoch 412/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.1455 - val_acc: 0.9850\n",
      "Epoch 413/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1881 - val_acc: 0.9823\n",
      "Epoch 414/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1797 - val_acc: 0.9823\n",
      "Epoch 415/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.1608 - val_acc: 0.9850\n",
      "Epoch 416/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.2525 - val_acc: 0.9755\n",
      "Epoch 417/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0308 - val_acc: 0.9946\n",
      "Epoch 418/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0441 - val_acc: 0.9932\n",
      "Epoch 419/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.2749 - val_acc: 0.9768\n",
      "Epoch 420/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.2054 - val_acc: 0.9782\n",
      "Epoch 421/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 6.6848e-04 - acc: 0.9997 - val_loss: 0.2653 - val_acc: 0.9755\n",
      "Epoch 422/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.1093 - val_acc: 0.9850\n",
      "Epoch 423/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0164 - acc: 0.9965 - val_loss: 0.1716 - val_acc: 0.9619\n",
      "Epoch 424/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0279 - val_acc: 0.9905\n",
      "Epoch 425/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0033 - acc: 0.9988 - val_loss: 0.2409 - val_acc: 0.9646\n",
      "Epoch 426/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.1739 - val_acc: 0.9755\n",
      "Epoch 427/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0011 - acc: 0.9995 - val_loss: 0.1488 - val_acc: 0.9782\n",
      "Epoch 428/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.1491 - val_acc: 0.9782\n",
      "Epoch 429/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.4554 - val_acc: 0.9605\n",
      "Epoch 430/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0625 - val_acc: 0.9877\n",
      "Epoch 431/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 7.5022e-04 - acc: 0.9995 - val_loss: 0.0510 - val_acc: 0.9932\n",
      "Epoch 432/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0456 - val_acc: 0.9946\n",
      "Epoch 433/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0421 - val_acc: 0.9946\n",
      "Epoch 434/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0147 - acc: 0.9971 - val_loss: 0.0331 - val_acc: 0.9946\n",
      "Epoch 435/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0228 - val_acc: 0.9959\n",
      "Epoch 436/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0032 - acc: 0.9988 - val_loss: 0.0727 - val_acc: 0.9877\n",
      "Epoch 437/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0015 - acc: 0.9994 - val_loss: 0.0225 - val_acc: 0.9959\n",
      "Epoch 438/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.1334 - val_acc: 0.9796\n",
      "Epoch 439/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.2332 - val_acc: 0.9755\n",
      "Epoch 440/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 7.6436e-04 - acc: 0.9997 - val_loss: 0.2996 - val_acc: 0.9741\n",
      "Epoch 441/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0232 - val_acc: 0.9959\n",
      "Epoch 442/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0013 - val_acc: 0.9986\n",
      "Epoch 443/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0066 - acc: 0.9986 - val_loss: 9.4410e-04 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0093 - acc: 0.9982 - val_loss: 8.0403e-04 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0115 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9932\n",
      "Epoch 446/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1180 - val_acc: 0.9837\n",
      "Epoch 447/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0030 - acc: 0.9988 - val_loss: 0.0026 - val_acc: 0.9973\n",
      "Epoch 448/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0023 - acc: 0.9991 - val_loss: 0.0213 - val_acc: 0.9959\n",
      "Epoch 449/500\n",
      "207/207 [==============================] - 3s 14ms/step - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0710 - val_acc: 0.9877\n",
      "Epoch 450/500\n",
      "207/207 [==============================] - 3s 13ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0230 - val_acc: 0.9959\n",
      "Epoch 451/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0026 - val_acc: 0.9986\n",
      "Epoch 452/500\n",
      "207/207 [==============================] - 3s 13ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.0168 - val_acc: 0.9973\n",
      "Epoch 453/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0103 - val_acc: 0.9973\n",
      "Epoch 454/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0117 - val_acc: 0.9959\n",
      "Epoch 455/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0104 - val_acc: 0.9973\n",
      "Epoch 456/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0018 - acc: 0.9992 - val_loss: 0.0181 - val_acc: 0.9959\n",
      "Epoch 457/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 6.5715e-04 - acc: 0.9997 - val_loss: 0.0323 - val_acc: 0.9959\n",
      "Epoch 458/500\n",
      "207/207 [==============================] - 3s 14ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0316 - val_acc: 0.9959\n",
      "Epoch 459/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0306 - val_acc: 0.9959\n",
      "Epoch 460/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0327 - val_acc: 0.9959\n",
      "Epoch 461/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0439 - val_acc: 0.9932\n",
      "Epoch 462/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 9.2811e-04 - acc: 0.9995 - val_loss: 0.0300 - val_acc: 0.9932\n",
      "Epoch 463/500\n",
      "207/207 [==============================] - 2s 12ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0880 - val_acc: 0.9864\n",
      "Epoch 464/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0037 - acc: 0.9986 - val_loss: 0.2100 - val_acc: 0.9768\n",
      "Epoch 465/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0408 - val_acc: 0.9932\n",
      "Epoch 466/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0443 - val_acc: 0.9918\n",
      "Epoch 467/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0220 - val_acc: 0.9959\n",
      "Epoch 468/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.1789 - val_acc: 0.9782\n",
      "Epoch 469/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.0183 - val_acc: 0.9946\n",
      "Epoch 470/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0020 - acc: 0.9989 - val_loss: 0.5752 - val_acc: 0.9605\n",
      "Epoch 471/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0196 - val_acc: 0.9973\n",
      "Epoch 472/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0245 - val_acc: 0.9959\n",
      "Epoch 473/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 6.4183e-04 - acc: 0.9997 - val_loss: 0.0564 - val_acc: 0.9905\n",
      "Epoch 474/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0650 - val_acc: 0.9918\n",
      "Epoch 475/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0318 - val_acc: 0.9932\n",
      "Epoch 476/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0041 - acc: 0.9991 - val_loss: 0.0384 - val_acc: 0.9946\n",
      "Epoch 477/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0355 - val_acc: 0.9959\n",
      "Epoch 478/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 3.8937e-04 - acc: 0.9998 - val_loss: 0.0354 - val_acc: 0.9959\n",
      "Epoch 479/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0094 - acc: 0.9988 - val_loss: 0.0344 - val_acc: 0.9959\n",
      "Epoch 480/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0205 - val_acc: 0.9946\n",
      "Epoch 481/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0150 - val_acc: 0.9946\n",
      "Epoch 482/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.1260 - val_acc: 0.9755\n",
      "Epoch 483/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0236 - val_acc: 0.9959\n",
      "Epoch 484/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0157 - val_acc: 0.9959\n",
      "Epoch 485/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0260 - val_acc: 0.9932\n",
      "Epoch 486/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0260 - val_acc: 0.9932\n",
      "Epoch 487/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0073 - acc: 0.9983 - val_loss: 0.0416 - val_acc: 0.9918\n",
      "Epoch 488/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0369 - val_acc: 0.9918\n",
      "Epoch 489/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0309 - val_acc: 0.9932\n",
      "Epoch 490/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.3773 - val_acc: 0.9605\n",
      "Epoch 491/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0280 - val_acc: 0.9959\n",
      "Epoch 492/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0426 - val_acc: 0.9932\n",
      "Epoch 493/500\n",
      "207/207 [==============================] - 2s 10ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0266 - val_acc: 0.9959\n",
      "Epoch 494/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.0279 - val_acc: 0.9959\n",
      "Epoch 495/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0322 - val_acc: 0.9959\n",
      "Epoch 496/500\n",
      "207/207 [==============================] - 2s 11ms/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0316 - val_acc: 0.9959\n",
      "Epoch 497/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0211 - val_acc: 0.9973\n",
      "Epoch 498/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 0.0021 - acc: 0.9992 - val_loss: 0.0159 - val_acc: 0.9973\n",
      "Epoch 499/500\n",
      "207/207 [==============================] - 2s 9ms/step - loss: 9.3653e-04 - acc: 0.9997 - val_loss: 0.0200 - val_acc: 0.9959\n",
      "Epoch 500/500\n",
      "207/207 [==============================] - 2s 8ms/step - loss: 7.0929e-04 - acc: 0.9998 - val_loss: 0.0203 - val_acc: 0.9959\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 500, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "x = np.arange(0, 500)\n",
    "plt.plot(x, acc, 'y', label='Training acc')\n",
    "plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step\n",
      "Confusion Matrix\n",
      "[[471   3  23   0   0   0]\n",
      " [  0 455  16   0   0   0]\n",
      " [  2  29 377   0   3   0]\n",
      " [  0   0   0 460  31   0]\n",
      " [  0   1   0  27 497   0]\n",
      " [  3   0   0   1   0 533]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "y_test_arg=np.argmax(y_test,axis=1)\n",
    "Y_pred = np.argmax(model.predict(X_test),axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test_arg, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6869 - acc: 0.9526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.686938\n",
       "1  0.952592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "pd.DataFrame(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
