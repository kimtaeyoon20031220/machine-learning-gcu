{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>handTemperature</th>\n",
       "      <th>handAcc16_1</th>\n",
       "      <th>handAcc16_2</th>\n",
       "      <th>handAcc16_3</th>\n",
       "      <th>handAcc6_1</th>\n",
       "      <th>handAcc6_2</th>\n",
       "      <th>handAcc6_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ankleGyro2</th>\n",
       "      <th>ankleGyro3</th>\n",
       "      <th>ankleMagne1</th>\n",
       "      <th>ankleMagne2</th>\n",
       "      <th>ankleMagne3</th>\n",
       "      <th>ankleOrientation1</th>\n",
       "      <th>ankleOrientation2</th>\n",
       "      <th>ankleOrientation3</th>\n",
       "      <th>ankleOrientation4</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.37223</td>\n",
       "      <td>8.60074</td>\n",
       "      <td>3.51048</td>\n",
       "      <td>2.43954</td>\n",
       "      <td>8.76165</td>\n",
       "      <td>3.35465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>-0.017580</td>\n",
       "      <td>-61.1888</td>\n",
       "      <td>-38.95990</td>\n",
       "      <td>-58.143800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.18837</td>\n",
       "      <td>8.56560</td>\n",
       "      <td>3.66179</td>\n",
       "      <td>2.39494</td>\n",
       "      <td>8.55081</td>\n",
       "      <td>3.64207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-59.8479</td>\n",
       "      <td>-38.89190</td>\n",
       "      <td>-58.525300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.37357</td>\n",
       "      <td>8.60107</td>\n",
       "      <td>3.54898</td>\n",
       "      <td>2.30514</td>\n",
       "      <td>8.53644</td>\n",
       "      <td>3.73280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>-60.7361</td>\n",
       "      <td>-39.41380</td>\n",
       "      <td>-58.399900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.07473</td>\n",
       "      <td>8.52853</td>\n",
       "      <td>3.66021</td>\n",
       "      <td>2.33528</td>\n",
       "      <td>8.53622</td>\n",
       "      <td>3.73277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020301</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>-60.4091</td>\n",
       "      <td>-38.76350</td>\n",
       "      <td>-58.395600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2.22936</td>\n",
       "      <td>8.83122</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>2.23055</td>\n",
       "      <td>8.59741</td>\n",
       "      <td>3.76295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>-61.5199</td>\n",
       "      <td>-39.38790</td>\n",
       "      <td>-58.269400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872528</th>\n",
       "      <td>100.19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-4.71493</td>\n",
       "      <td>10.22250</td>\n",
       "      <td>4.66893</td>\n",
       "      <td>-5.04654</td>\n",
       "      <td>9.94944</td>\n",
       "      <td>4.50736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062676</td>\n",
       "      <td>-0.127084</td>\n",
       "      <td>-46.5153</td>\n",
       "      <td>3.58240</td>\n",
       "      <td>-0.035995</td>\n",
       "      <td>0.598531</td>\n",
       "      <td>0.033615</td>\n",
       "      <td>0.799791</td>\n",
       "      <td>-0.031075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872529</th>\n",
       "      <td>100.20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-4.95932</td>\n",
       "      <td>10.37130</td>\n",
       "      <td>4.12594</td>\n",
       "      <td>-4.96890</td>\n",
       "      <td>10.29620</td>\n",
       "      <td>4.43102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027006</td>\n",
       "      <td>-0.089808</td>\n",
       "      <td>-45.7474</td>\n",
       "      <td>3.54453</td>\n",
       "      <td>0.108583</td>\n",
       "      <td>0.598428</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.799933</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872530</th>\n",
       "      <td>100.21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-4.93997</td>\n",
       "      <td>9.83615</td>\n",
       "      <td>3.70468</td>\n",
       "      <td>-5.04613</td>\n",
       "      <td>10.35690</td>\n",
       "      <td>4.14405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038024</td>\n",
       "      <td>-0.064709</td>\n",
       "      <td>-46.3997</td>\n",
       "      <td>4.22078</td>\n",
       "      <td>0.105504</td>\n",
       "      <td>0.598233</td>\n",
       "      <td>0.033172</td>\n",
       "      <td>0.800095</td>\n",
       "      <td>-0.029416</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872531</th>\n",
       "      <td>100.22</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-4.64941</td>\n",
       "      <td>9.11129</td>\n",
       "      <td>3.51904</td>\n",
       "      <td>-5.06854</td>\n",
       "      <td>9.75268</td>\n",
       "      <td>3.87359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025796</td>\n",
       "      <td>-0.064357</td>\n",
       "      <td>-46.5282</td>\n",
       "      <td>4.48593</td>\n",
       "      <td>0.530240</td>\n",
       "      <td>0.598116</td>\n",
       "      <td>0.033427</td>\n",
       "      <td>0.800180</td>\n",
       "      <td>-0.029208</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872532</th>\n",
       "      <td>100.23</td>\n",
       "      <td>0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>25.1875</td>\n",
       "      <td>-4.09726</td>\n",
       "      <td>8.15642</td>\n",
       "      <td>3.29961</td>\n",
       "      <td>-4.73244</td>\n",
       "      <td>8.82870</td>\n",
       "      <td>3.54305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>-0.042858</td>\n",
       "      <td>-46.2704</td>\n",
       "      <td>4.21475</td>\n",
       "      <td>0.247798</td>\n",
       "      <td>0.598119</td>\n",
       "      <td>0.033685</td>\n",
       "      <td>0.800188</td>\n",
       "      <td>-0.028602</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2872533 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  activityID  heartrate  handTemperature  handAcc16_1  \\\n",
       "0             8.38           0      100.0          30.0000      2.37223   \n",
       "1             8.39           0      100.0          30.0000      2.18837   \n",
       "2             8.40           0      100.0          30.0000      2.37357   \n",
       "3             8.41           0      100.0          30.0000      2.07473   \n",
       "4             8.42           0        NaN          30.0000      2.22936   \n",
       "...            ...         ...        ...              ...          ...   \n",
       "2872528     100.19           0        NaN          25.1875     -4.71493   \n",
       "2872529     100.20           0        NaN          25.1875     -4.95932   \n",
       "2872530     100.21           0        NaN          25.1875     -4.93997   \n",
       "2872531     100.22           0        NaN          25.1875     -4.64941   \n",
       "2872532     100.23           0      161.0          25.1875     -4.09726   \n",
       "\n",
       "         handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  handAcc6_3  ...  \\\n",
       "0            8.60074      3.51048     2.43954     8.76165     3.35465  ...   \n",
       "1            8.56560      3.66179     2.39494     8.55081     3.64207  ...   \n",
       "2            8.60107      3.54898     2.30514     8.53644     3.73280  ...   \n",
       "3            8.52853      3.66021     2.33528     8.53622     3.73277  ...   \n",
       "4            8.83122      3.70000     2.23055     8.59741     3.76295  ...   \n",
       "...              ...          ...         ...         ...         ...  ...   \n",
       "2872528     10.22250      4.66893    -5.04654     9.94944     4.50736  ...   \n",
       "2872529     10.37130      4.12594    -4.96890    10.29620     4.43102  ...   \n",
       "2872530      9.83615      3.70468    -5.04613    10.35690     4.14405  ...   \n",
       "2872531      9.11129      3.51904    -5.06854     9.75268     3.87359  ...   \n",
       "2872532      8.15642      3.29961    -4.73244     8.82870     3.54305  ...   \n",
       "\n",
       "         ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  ankleMagne3  \\\n",
       "0          0.009250   -0.017580     -61.1888    -38.95990   -58.143800   \n",
       "1         -0.004638    0.000368     -59.8479    -38.89190   -58.525300   \n",
       "2          0.000148    0.022495     -60.7361    -39.41380   -58.399900   \n",
       "3         -0.020301    0.011275     -60.4091    -38.76350   -58.395600   \n",
       "4         -0.014303   -0.002823     -61.5199    -39.38790   -58.269400   \n",
       "...             ...         ...          ...          ...          ...   \n",
       "2872528   -0.062676   -0.127084     -46.5153      3.58240    -0.035995   \n",
       "2872529   -0.027006   -0.089808     -45.7474      3.54453     0.108583   \n",
       "2872530   -0.038024   -0.064709     -46.3997      4.22078     0.105504   \n",
       "2872531   -0.025796   -0.064357     -46.5282      4.48593     0.530240   \n",
       "2872532    0.011866   -0.042858     -46.2704      4.21475     0.247798   \n",
       "\n",
       "         ankleOrientation1  ankleOrientation2  ankleOrientation3  \\\n",
       "0                 1.000000           0.000000           0.000000   \n",
       "1                 1.000000           0.000000           0.000000   \n",
       "2                 1.000000           0.000000           0.000000   \n",
       "3                 1.000000           0.000000           0.000000   \n",
       "4                 1.000000           0.000000           0.000000   \n",
       "...                    ...                ...                ...   \n",
       "2872528           0.598531           0.033615           0.799791   \n",
       "2872529           0.598428           0.033012           0.799933   \n",
       "2872530           0.598233           0.033172           0.800095   \n",
       "2872531           0.598116           0.033427           0.800180   \n",
       "2872532           0.598119           0.033685           0.800188   \n",
       "\n",
       "         ankleOrientation4  subject_id  \n",
       "0                 0.000000           1  \n",
       "1                 0.000000           1  \n",
       "2                 0.000000           1  \n",
       "3                 0.000000           1  \n",
       "4                 0.000000           1  \n",
       "...                    ...         ...  \n",
       "2872528          -0.031075           9  \n",
       "2872529          -0.030018           9  \n",
       "2872530          -0.029416           9  \n",
       "2872531          -0.029208           9  \n",
       "2872532          -0.028602           9  \n",
       "\n",
       "[2872533 rows x 55 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../../dataset/pamap_features.csv', index_col=0)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['heartrate'] = dataset['heartrate'].fillna(dataset['heartrate'].mean())\n",
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()\n",
    "\n",
    "dataset['activityID'].value_counts()\n",
    "\n",
    "dataset.columns\n",
    "col = dataset.columns.drop(['timestamp', 'activityID', 'heartrate', 'subject_id', \n",
    "                      'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4',\n",
    "                      'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4',\n",
    "                      'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4',\n",
    "                      'handTemperature', 'chestTemperature', 'ankleTemperature',\n",
    "                      'subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handAcc16_1</th>\n",
       "      <th>handAcc16_2</th>\n",
       "      <th>handAcc16_3</th>\n",
       "      <th>handAcc6_1</th>\n",
       "      <th>handAcc6_2</th>\n",
       "      <th>handAcc6_3</th>\n",
       "      <th>handGyro1</th>\n",
       "      <th>handGyro2</th>\n",
       "      <th>handGyro3</th>\n",
       "      <th>handMagne1</th>\n",
       "      <th>...</th>\n",
       "      <th>ankleAcc6_1</th>\n",
       "      <th>ankleAcc6_2</th>\n",
       "      <th>ankleAcc6_3</th>\n",
       "      <th>ankleGyro1</th>\n",
       "      <th>ankleGyro2</th>\n",
       "      <th>ankleGyro3</th>\n",
       "      <th>ankleMagne1</th>\n",
       "      <th>ankleMagne2</th>\n",
       "      <th>ankleMagne3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.224895</td>\n",
       "      <td>0.799466</td>\n",
       "      <td>0.087944</td>\n",
       "      <td>1.222699</td>\n",
       "      <td>0.856035</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.068503</td>\n",
       "      <td>0.028096</td>\n",
       "      <td>-0.006246</td>\n",
       "      <td>-0.269436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>-0.240078</td>\n",
       "      <td>0.739314</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.070493</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>-1.507237</td>\n",
       "      <td>-1.875621</td>\n",
       "      <td>-3.689774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.194172</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>0.127324</td>\n",
       "      <td>1.215255</td>\n",
       "      <td>0.821161</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>-0.260341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>-0.249625</td>\n",
       "      <td>0.729901</td>\n",
       "      <td>-0.012571</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>-0.001840</td>\n",
       "      <td>-1.436290</td>\n",
       "      <td>-1.872474</td>\n",
       "      <td>-3.708535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.225119</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.097964</td>\n",
       "      <td>1.200268</td>\n",
       "      <td>0.818784</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>-0.042074</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.287695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.244854</td>\n",
       "      <td>0.729845</td>\n",
       "      <td>-0.003602</td>\n",
       "      <td>0.055140</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>-1.483284</td>\n",
       "      <td>-1.896626</td>\n",
       "      <td>-3.702368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.175183</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.126912</td>\n",
       "      <td>1.205298</td>\n",
       "      <td>0.818747</td>\n",
       "      <td>0.098724</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.260686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022996</td>\n",
       "      <td>-0.251998</td>\n",
       "      <td>0.748941</td>\n",
       "      <td>-0.003452</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>-1.465983</td>\n",
       "      <td>-1.866532</td>\n",
       "      <td>-3.702157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.201022</td>\n",
       "      <td>0.836238</td>\n",
       "      <td>0.137268</td>\n",
       "      <td>1.187819</td>\n",
       "      <td>0.828869</td>\n",
       "      <td>0.106585</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>-0.015408</td>\n",
       "      <td>-0.032104</td>\n",
       "      <td>-0.232779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>-0.254382</td>\n",
       "      <td>0.748931</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.030764</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>-1.524755</td>\n",
       "      <td>-1.895427</td>\n",
       "      <td>-3.695951</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.212757</td>\n",
       "      <td>0.835930</td>\n",
       "      <td>0.097475</td>\n",
       "      <td>1.192954</td>\n",
       "      <td>0.838828</td>\n",
       "      <td>0.110474</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>-0.022237</td>\n",
       "      <td>-0.032897</td>\n",
       "      <td>-0.237137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025793</td>\n",
       "      <td>-0.249618</td>\n",
       "      <td>0.739375</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>0.027861</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>-1.459967</td>\n",
       "      <td>-1.871821</td>\n",
       "      <td>-3.702260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.219072</td>\n",
       "      <td>0.835883</td>\n",
       "      <td>0.097623</td>\n",
       "      <td>1.195576</td>\n",
       "      <td>0.858786</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>-0.015622</td>\n",
       "      <td>-0.071697</td>\n",
       "      <td>-0.028349</td>\n",
       "      <td>-0.251120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>-0.249610</td>\n",
       "      <td>0.748850</td>\n",
       "      <td>-0.036321</td>\n",
       "      <td>-0.036086</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-1.477708</td>\n",
       "      <td>-1.871349</td>\n",
       "      <td>-3.696034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.224760</td>\n",
       "      <td>0.871941</td>\n",
       "      <td>0.057491</td>\n",
       "      <td>1.215742</td>\n",
       "      <td>0.878612</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>-0.060948</td>\n",
       "      <td>-0.018528</td>\n",
       "      <td>-0.260640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>-0.249620</td>\n",
       "      <td>0.734588</td>\n",
       "      <td>-0.024791</td>\n",
       "      <td>-0.012476</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-1.471697</td>\n",
       "      <td>-1.876639</td>\n",
       "      <td>-3.696142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.219428</td>\n",
       "      <td>0.884307</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>1.223395</td>\n",
       "      <td>0.893543</td>\n",
       "      <td>0.070903</td>\n",
       "      <td>0.021847</td>\n",
       "      <td>-0.096028</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>-0.273753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031473</td>\n",
       "      <td>-0.235298</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>-1.512676</td>\n",
       "      <td>-1.906085</td>\n",
       "      <td>-3.690074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.206085</td>\n",
       "      <td>0.878187</td>\n",
       "      <td>0.067038</td>\n",
       "      <td>1.220901</td>\n",
       "      <td>0.898555</td>\n",
       "      <td>0.066957</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>-0.101344</td>\n",
       "      <td>-0.008475</td>\n",
       "      <td>-0.260149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025817</td>\n",
       "      <td>-0.247226</td>\n",
       "      <td>0.748885</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.031404</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>-1.489358</td>\n",
       "      <td>-1.881276</td>\n",
       "      <td>-3.689971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   handAcc16_1  handAcc16_2  handAcc16_3  handAcc6_1  handAcc6_2  handAcc6_3  \\\n",
       "0     1.224895     0.799466     0.087944    1.222699    0.856035    0.000235   \n",
       "1     1.194172     0.793859     0.127324    1.215255    0.821161    0.075099   \n",
       "2     1.225119     0.799518     0.097964    1.200268    0.818784    0.098732   \n",
       "3     1.175183     0.787945     0.126912    1.205298    0.818747    0.098724   \n",
       "4     1.201022     0.836238     0.137268    1.187819    0.828869    0.106585   \n",
       "5     1.212757     0.835930     0.097475    1.192954    0.838828    0.110474   \n",
       "6     1.219072     0.835883     0.097623    1.195576    0.858786    0.098602   \n",
       "7     1.224760     0.871941     0.057491    1.215742    0.878612    0.074901   \n",
       "8     1.219428     0.884307     0.097365    1.223395    0.893543    0.070903   \n",
       "9     1.206085     0.878187     0.067038    1.220901    0.898555    0.066957   \n",
       "\n",
       "   handGyro1  handGyro2  handGyro3  handMagne1  ...  ankleAcc6_1  ankleAcc6_2  \\\n",
       "0  -0.068503   0.028096  -0.006246   -0.269436  ...     0.025797    -0.240078   \n",
       "1  -0.016169   0.017868   0.009152   -0.260341  ...     0.020130    -0.249625   \n",
       "2  -0.042074   0.000714  -0.000136   -0.287695  ...     0.022951    -0.244854   \n",
       "3   0.000859   0.000980   0.002100   -0.260686  ...     0.022996    -0.251998   \n",
       "4   0.012144  -0.015408  -0.032104   -0.232779  ...     0.025816    -0.254382   \n",
       "5   0.005174  -0.022237  -0.032897   -0.237137  ...     0.025793    -0.249618   \n",
       "6  -0.015622  -0.071697  -0.028349   -0.251120  ...     0.031456    -0.249610   \n",
       "7   0.017393  -0.060948  -0.018528   -0.260640  ...     0.028601    -0.249620   \n",
       "8   0.021847  -0.096028  -0.003026   -0.273753  ...     0.031473    -0.235298   \n",
       "9   0.008561  -0.101344  -0.008475   -0.260149  ...     0.025817    -0.247226   \n",
       "\n",
       "   ankleAcc6_3  ankleGyro1  ankleGyro2  ankleGyro3  ankleMagne1  ankleMagne2  \\\n",
       "0     0.739314    0.001341    0.070493   -0.011664    -1.507237    -1.875621   \n",
       "1     0.729901   -0.012571    0.047067   -0.001840    -1.436290    -1.872474   \n",
       "2     0.729845   -0.003602    0.055140    0.010271    -1.483284    -1.896626   \n",
       "3     0.748941   -0.003452    0.020646    0.004130    -1.465983    -1.866532   \n",
       "4     0.748931    0.005454    0.030764   -0.003586    -1.524755    -1.895427   \n",
       "5     0.739375   -0.012115    0.027861   -0.001467    -1.459967    -1.871821   \n",
       "6     0.748850   -0.036321   -0.036086    0.006494    -1.477708    -1.871349   \n",
       "7     0.734588   -0.024791   -0.012476   -0.002471    -1.471697    -1.876639   \n",
       "8     0.753521    0.006435    0.037951    0.007647    -1.512676    -1.906085   \n",
       "9     0.748885    0.000733    0.031404    0.005894    -1.489358    -1.881276   \n",
       "\n",
       "   ankleMagne3  label  \n",
       "0    -3.689774      0  \n",
       "1    -3.708535      0  \n",
       "2    -3.702368      0  \n",
       "3    -3.702157      0  \n",
       "4    -3.695951      0  \n",
       "5    -3.702260      0  \n",
       "6    -3.696034      0  \n",
       "7    -3.696142      0  \n",
       "8    -3.690074      0  \n",
       "9    -3.689971      0  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = dataset[col]\n",
    "y= dataset['activityID']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = col)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "scaled_X = pd.DataFrame(data = X, columns = col)\n",
    "scaled_X['label'] = y.values\n",
    "\n",
    "scaled_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, \n",
    "                                                    scaled_X[\"label\"],\n",
    "                                                    test_size = 0.25, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 80\n",
    "\n",
    "# The steps to take from one segment to the next; if this value is equal to TIME_PERIODS, then there is\n",
    "# no overlap between the segments\n",
    "STEP_DISTANCE = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label statistics::\n",
      "[[     0 692581]\n",
      " [     1 143867]\n",
      " [     2 138404]\n",
      " [     3 141896]\n",
      " [     4 172563]\n",
      " [     5  71683]\n",
      " [     6 122319]\n",
      " [     7 138252]\n",
      " [    12  87783]\n",
      " [    13  78691]\n",
      " [    16 131389]\n",
      " [    17 178662]\n",
      " [    24  35561]]\n",
      "Test data label statistics::\n",
      "[[     0 230856]\n",
      " [     1  48423]\n",
      " [     2  46241]\n",
      " [     3  47088]\n",
      " [     4  57146]\n",
      " [     5  23958]\n",
      " [     6  40983]\n",
      " [     7  46192]\n",
      " [    12  29311]\n",
      " [    13  26174]\n",
      " [    16  43587]\n",
      " [    17  59240]\n",
      " [    24  12018]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print (\"Train data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T)  \n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print (\"Test data label statistics::\")\n",
    "print (np.asarray((unique, counts)).T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2133650, 1, 36) (2133650, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 1\n",
    "STEP = 1\n",
    "\n",
    "X_train, y_train = create_dataset(X_train[col], X_train.label, TIME_STEPS,\n",
    "                                  STEP)\n",
    "X_test, y_test = create_dataset(X_test[col], X_test.label, TIME_STEPS, STEP)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimtaeyoon/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# cnn model vary kernel size\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, LSTM, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose,epochs,batch_size=1,10,32 \n",
    "\n",
    "n_timesteps,n_features,n_outputs=X_train.shape[1],X_train.shape[2],y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential()\n",
    "# model.add(Bidirectional(LSTM(units = 128, input_shape = [X_train.shape[1], X_train.shape[2]])))\n",
    "# model.add(Dropout(rate = 0.5))\n",
    "# model.add(Dense(units = 128, activation = \"relu\"))\n",
    "# model.add(Dense(y_train.shape[1], activation = \"softmax\"))\n",
    "# model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                8832      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 13)                429       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,261\n",
      "Trainable params: 9,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60009/60009 [==============================] - 82s 1ms/step - loss: 1.0176 - acc: 0.6707 - val_loss: 0.7260 - val_acc: 0.7668\n",
      "Epoch 2/100\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.9321 - acc: 0.6993 - val_loss: 0.7056 - val_acc: 0.7723\n",
      "Epoch 3/100\n",
      "60009/60009 [==============================] - 90s 2ms/step - loss: 0.9189 - acc: 0.7040 - val_loss: 0.6923 - val_acc: 0.7770\n",
      "Epoch 4/100\n",
      "60009/60009 [==============================] - 92s 2ms/step - loss: 0.9108 - acc: 0.7063 - val_loss: 0.6867 - val_acc: 0.7778\n",
      "Epoch 5/100\n",
      "60009/60009 [==============================] - 90s 1ms/step - loss: 0.9045 - acc: 0.7088 - val_loss: 0.6792 - val_acc: 0.7830\n",
      "Epoch 6/100\n",
      "60009/60009 [==============================] - 99s 2ms/step - loss: 0.9016 - acc: 0.7100 - val_loss: 0.6795 - val_acc: 0.7811\n",
      "Epoch 7/100\n",
      "60009/60009 [==============================] - 94s 2ms/step - loss: 0.8998 - acc: 0.7109 - val_loss: 0.6763 - val_acc: 0.7836\n",
      "Epoch 8/100\n",
      "60009/60009 [==============================] - 92s 2ms/step - loss: 0.8997 - acc: 0.7110 - val_loss: 0.6755 - val_acc: 0.7826\n",
      "Epoch 9/100\n",
      "60009/60009 [==============================] - 89s 1ms/step - loss: 0.8979 - acc: 0.7121 - val_loss: 0.6749 - val_acc: 0.7843\n",
      "Epoch 10/100\n",
      "60009/60009 [==============================] - 92s 2ms/step - loss: 0.8972 - acc: 0.7121 - val_loss: 0.6733 - val_acc: 0.7840\n",
      "Epoch 11/100\n",
      "60009/60009 [==============================] - 91s 2ms/step - loss: 0.8953 - acc: 0.7128 - val_loss: 0.6713 - val_acc: 0.7845\n",
      "Epoch 12/100\n",
      "60009/60009 [==============================] - 93s 2ms/step - loss: 0.8950 - acc: 0.7135 - val_loss: 0.6737 - val_acc: 0.7845\n",
      "Epoch 13/100\n",
      "60009/60009 [==============================] - 97s 2ms/step - loss: 0.8955 - acc: 0.7133 - val_loss: 0.6706 - val_acc: 0.7847\n",
      "Epoch 14/100\n",
      "60009/60009 [==============================] - 113s 2ms/step - loss: 0.8948 - acc: 0.7136 - val_loss: 0.6716 - val_acc: 0.7841\n",
      "Epoch 15/100\n",
      "60009/60009 [==============================] - 100s 2ms/step - loss: 0.8951 - acc: 0.7137 - val_loss: 0.6706 - val_acc: 0.7856\n",
      "Epoch 16/100\n",
      "60009/60009 [==============================] - 96s 2ms/step - loss: 0.8943 - acc: 0.7143 - val_loss: 0.6705 - val_acc: 0.7843\n",
      "Epoch 17/100\n",
      "60009/60009 [==============================] - 100s 2ms/step - loss: 0.8948 - acc: 0.7142 - val_loss: 0.6707 - val_acc: 0.7851\n",
      "Epoch 18/100\n",
      "60009/60009 [==============================] - 102s 2ms/step - loss: 0.8958 - acc: 0.7141 - val_loss: 0.6724 - val_acc: 0.7843\n",
      "Epoch 19/100\n",
      "60009/60009 [==============================] - 78s 1ms/step - loss: 0.8965 - acc: 0.7138 - val_loss: 0.6711 - val_acc: 0.7851\n",
      "Epoch 20/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8962 - acc: 0.7137 - val_loss: 0.6741 - val_acc: 0.7848\n",
      "Epoch 21/100\n",
      "60009/60009 [==============================] - 77s 1ms/step - loss: 0.8967 - acc: 0.7141 - val_loss: 0.6725 - val_acc: 0.7847\n",
      "Epoch 22/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8960 - acc: 0.7140 - val_loss: 0.6723 - val_acc: 0.7863\n",
      "Epoch 23/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8959 - acc: 0.7146 - val_loss: 0.6728 - val_acc: 0.7853\n",
      "Epoch 24/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8973 - acc: 0.7143 - val_loss: 0.6730 - val_acc: 0.7848\n",
      "Epoch 25/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8978 - acc: 0.7136 - val_loss: 0.6748 - val_acc: 0.7835\n",
      "Epoch 26/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8979 - acc: 0.7136 - val_loss: 0.6751 - val_acc: 0.7847\n",
      "Epoch 27/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8964 - acc: 0.7143 - val_loss: 0.6735 - val_acc: 0.7849\n",
      "Epoch 28/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8970 - acc: 0.7140 - val_loss: 0.6762 - val_acc: 0.7840\n",
      "Epoch 29/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8969 - acc: 0.7145 - val_loss: 0.6745 - val_acc: 0.7849\n",
      "Epoch 30/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8965 - acc: 0.7140 - val_loss: 0.6747 - val_acc: 0.7848\n",
      "Epoch 31/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8969 - acc: 0.7144 - val_loss: 0.6764 - val_acc: 0.7836\n",
      "Epoch 32/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8972 - acc: 0.7139 - val_loss: 0.6744 - val_acc: 0.7850\n",
      "Epoch 33/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8968 - acc: 0.7145 - val_loss: 0.6789 - val_acc: 0.7827\n",
      "Epoch 34/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8969 - acc: 0.7143 - val_loss: 0.6786 - val_acc: 0.7830\n",
      "Epoch 35/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8984 - acc: 0.7138 - val_loss: 0.6768 - val_acc: 0.7833\n",
      "Epoch 36/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.8977 - acc: 0.7139 - val_loss: 0.6789 - val_acc: 0.7837\n",
      "Epoch 37/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8978 - acc: 0.7139 - val_loss: 0.6780 - val_acc: 0.7839\n",
      "Epoch 38/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8977 - acc: 0.7143 - val_loss: 0.6778 - val_acc: 0.7836\n",
      "Epoch 39/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8973 - acc: 0.7143 - val_loss: 0.6795 - val_acc: 0.7827\n",
      "Epoch 40/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8963 - acc: 0.7148 - val_loss: 0.6790 - val_acc: 0.7835\n",
      "Epoch 41/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8987 - acc: 0.7141 - val_loss: 0.6778 - val_acc: 0.7848\n",
      "Epoch 42/100\n",
      "60009/60009 [==============================] - 87s 1ms/step - loss: 0.8984 - acc: 0.7140 - val_loss: 0.6791 - val_acc: 0.7847\n",
      "Epoch 43/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8979 - acc: 0.7141 - val_loss: 0.6742 - val_acc: 0.7855\n",
      "Epoch 44/100\n",
      "60009/60009 [==============================] - 78s 1ms/step - loss: 0.8976 - acc: 0.7144 - val_loss: 0.6793 - val_acc: 0.7831\n",
      "Epoch 45/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8988 - acc: 0.7143 - val_loss: 0.6754 - val_acc: 0.7844\n",
      "Epoch 46/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8985 - acc: 0.7143 - val_loss: 0.6789 - val_acc: 0.7835\n",
      "Epoch 47/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8972 - acc: 0.7144 - val_loss: 0.6799 - val_acc: 0.7825\n",
      "Epoch 48/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8983 - acc: 0.7144 - val_loss: 0.6771 - val_acc: 0.7836\n",
      "Epoch 49/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8990 - acc: 0.7143 - val_loss: 0.6791 - val_acc: 0.7828\n",
      "Epoch 50/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8986 - acc: 0.7143 - val_loss: 0.6777 - val_acc: 0.7838\n",
      "Epoch 51/100\n",
      "60009/60009 [==============================] - 77s 1ms/step - loss: 0.8982 - acc: 0.7140 - val_loss: 0.6788 - val_acc: 0.7848\n",
      "Epoch 52/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8994 - acc: 0.7139 - val_loss: 0.6759 - val_acc: 0.7843\n",
      "Epoch 53/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8988 - acc: 0.7138 - val_loss: 0.6761 - val_acc: 0.7862\n",
      "Epoch 54/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8993 - acc: 0.7143 - val_loss: 0.6787 - val_acc: 0.7833\n",
      "Epoch 55/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8982 - acc: 0.7145 - val_loss: 0.6764 - val_acc: 0.7853\n",
      "Epoch 56/100\n",
      "60009/60009 [==============================] - 77s 1ms/step - loss: 0.8997 - acc: 0.7140 - val_loss: 0.6793 - val_acc: 0.7840\n",
      "Epoch 57/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8994 - acc: 0.7142 - val_loss: 0.6794 - val_acc: 0.7830\n",
      "Epoch 58/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.8985 - acc: 0.7142 - val_loss: 0.6793 - val_acc: 0.7843\n",
      "Epoch 59/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8991 - acc: 0.7138 - val_loss: 0.6773 - val_acc: 0.7843\n",
      "Epoch 60/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.9006 - acc: 0.7140 - val_loss: 0.6774 - val_acc: 0.7847\n",
      "Epoch 61/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.8996 - acc: 0.7142 - val_loss: 0.6768 - val_acc: 0.7845\n",
      "Epoch 62/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8992 - acc: 0.7140 - val_loss: 0.6765 - val_acc: 0.7849\n",
      "Epoch 63/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.9004 - acc: 0.7140 - val_loss: 0.6802 - val_acc: 0.7828\n",
      "Epoch 64/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9006 - acc: 0.7137 - val_loss: 0.6781 - val_acc: 0.7831\n",
      "Epoch 65/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8992 - acc: 0.7139 - val_loss: 0.6792 - val_acc: 0.7820\n",
      "Epoch 66/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.9000 - acc: 0.7141 - val_loss: 0.6799 - val_acc: 0.7829\n",
      "Epoch 67/100\n",
      "60009/60009 [==============================] - 71s 1ms/step - loss: 0.8996 - acc: 0.7138 - val_loss: 0.6784 - val_acc: 0.7837\n",
      "Epoch 68/100\n",
      "60009/60009 [==============================] - 75s 1ms/step - loss: 0.9006 - acc: 0.7138 - val_loss: 0.6786 - val_acc: 0.7851\n",
      "Epoch 69/100\n",
      "60009/60009 [==============================] - 71s 1ms/step - loss: 0.9005 - acc: 0.7137 - val_loss: 0.6783 - val_acc: 0.7840\n",
      "Epoch 70/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9012 - acc: 0.7135 - val_loss: 0.6805 - val_acc: 0.7832\n",
      "Epoch 71/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9009 - acc: 0.7137 - val_loss: 0.6800 - val_acc: 0.7831\n",
      "Epoch 72/100\n",
      "60009/60009 [==============================] - 71s 1ms/step - loss: 0.8995 - acc: 0.7142 - val_loss: 0.6803 - val_acc: 0.7828\n",
      "Epoch 73/100\n",
      "60009/60009 [==============================] - 70s 1ms/step - loss: 0.9008 - acc: 0.7138 - val_loss: 0.6812 - val_acc: 0.7833\n",
      "Epoch 74/100\n",
      "60009/60009 [==============================] - 71s 1ms/step - loss: 0.9003 - acc: 0.7138 - val_loss: 0.6774 - val_acc: 0.7840\n",
      "Epoch 75/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9001 - acc: 0.7139 - val_loss: 0.6766 - val_acc: 0.7855\n",
      "Epoch 76/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9003 - acc: 0.7140 - val_loss: 0.6800 - val_acc: 0.7833\n",
      "Epoch 77/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9002 - acc: 0.7137 - val_loss: 0.6770 - val_acc: 0.7854\n",
      "Epoch 78/100\n",
      "60009/60009 [==============================] - 76s 1ms/step - loss: 0.9001 - acc: 0.7136 - val_loss: 0.6786 - val_acc: 0.7835\n",
      "Epoch 79/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9002 - acc: 0.7133 - val_loss: 0.6783 - val_acc: 0.7836\n",
      "Epoch 80/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9000 - acc: 0.7135 - val_loss: 0.6795 - val_acc: 0.7832\n",
      "Epoch 81/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.8999 - acc: 0.7136 - val_loss: 0.6776 - val_acc: 0.7842\n",
      "Epoch 82/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.8995 - acc: 0.7143 - val_loss: 0.6784 - val_acc: 0.7845\n",
      "Epoch 83/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.8991 - acc: 0.7138 - val_loss: 0.6769 - val_acc: 0.7841\n",
      "Epoch 84/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.8997 - acc: 0.7140 - val_loss: 0.6779 - val_acc: 0.7847\n",
      "Epoch 85/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8999 - acc: 0.7139 - val_loss: 0.6803 - val_acc: 0.7835\n",
      "Epoch 86/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9001 - acc: 0.7137 - val_loss: 0.6772 - val_acc: 0.7842\n",
      "Epoch 87/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9005 - acc: 0.7136 - val_loss: 0.6781 - val_acc: 0.7843\n",
      "Epoch 88/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9009 - acc: 0.7131 - val_loss: 0.6795 - val_acc: 0.7837\n",
      "Epoch 89/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9005 - acc: 0.7134 - val_loss: 0.6773 - val_acc: 0.7847\n",
      "Epoch 90/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.8998 - acc: 0.7138 - val_loss: 0.6779 - val_acc: 0.7850\n",
      "Epoch 91/100\n",
      "60009/60009 [==============================] - 77s 1ms/step - loss: 0.9012 - acc: 0.7133 - val_loss: 0.6784 - val_acc: 0.7847\n",
      "Epoch 92/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9003 - acc: 0.7135 - val_loss: 0.6761 - val_acc: 0.7853\n",
      "Epoch 93/100\n",
      "60009/60009 [==============================] - 93s 2ms/step - loss: 0.8998 - acc: 0.7138 - val_loss: 0.6769 - val_acc: 0.7840\n",
      "Epoch 94/100\n",
      "60009/60009 [==============================] - 80s 1ms/step - loss: 0.9001 - acc: 0.7135 - val_loss: 0.6791 - val_acc: 0.7844\n",
      "Epoch 95/100\n",
      "60009/60009 [==============================] - 77s 1ms/step - loss: 0.9006 - acc: 0.7134 - val_loss: 0.6766 - val_acc: 0.7842\n",
      "Epoch 96/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.9005 - acc: 0.7136 - val_loss: 0.6758 - val_acc: 0.7850\n",
      "Epoch 97/100\n",
      "60009/60009 [==============================] - 74s 1ms/step - loss: 0.9006 - acc: 0.7136 - val_loss: 0.6762 - val_acc: 0.7850\n",
      "Epoch 98/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.9006 - acc: 0.7135 - val_loss: 0.6765 - val_acc: 0.7850\n",
      "Epoch 99/100\n",
      "60009/60009 [==============================] - 72s 1ms/step - loss: 0.9006 - acc: 0.7136 - val_loss: 0.6767 - val_acc: 0.7841\n",
      "Epoch 100/100\n",
      "60009/60009 [==============================] - 73s 1ms/step - loss: 0.8997 - acc: 0.7144 - val_loss: 0.6785 - val_acc: 0.7846\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 32, validation_split = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "x = np.arange(0, 100)\n",
    "plt.plot(x, acc, 'y', label='Training acc')\n",
    "plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22226/22226 [==============================] - 14s 610us/step - loss: 0.6784 - acc: 0.7842\n",
      "22226/22226 [==============================] - 13s 543us/step\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22226/22226 [==============================] - 12s 546us/step\n",
      "Confusion Matrix\n",
      "[[201596     22    600   2445  10598    254   2275   2802   1697   1508\n",
      "    3860   3107     91]\n",
      " [  3448  44841     40     10      0      1      0      7      6      8\n",
      "      50     11      1]\n",
      " [  3785      4  41813    286      2      1     27     18      6      0\n",
      "     293      5      1]\n",
      " [  6118      0    270  40141     14      1      0      9      2      0\n",
      "      30    503      0]\n",
      " [ 11956      0      7     18  42138     38     21   2649    264     26\n",
      "      13      7      9]\n",
      " [  2218      5      1      0    196  19785     14   1431     78     48\n",
      "      55      1    126]\n",
      " [  2698      0      0      4     23     19  37152    128     21     34\n",
      "     747    151      6]\n",
      " [  5849      9     12      0   2431    259     29  37319    101     18\n",
      "      48     75     42]\n",
      " [ 19544     18      1      4   1473    327    118    622   6130    297\n",
      "     450    205    122]\n",
      " [ 17871     34     21      8    962    335    492    467    408   4803\n",
      "     263    186    324]\n",
      " [ 16350      0    111     54     18     22   1781    148     60     37\n",
      "   24260    742      4]\n",
      " [  4340      0     41   1079      0     15    186     26      0      3\n",
      "     168  53381      1]\n",
      " [  3473     33      1      0    102   2196     95   1151    113    410\n",
      "      57     23   4364]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "y_test_arg=np.argmax(y_test,axis=1)\n",
    "Y_pred = np.argmax(model.predict(X_test),axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test_arg, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22226/22226 [==============================] - 14s 626us/step - loss: 0.6784 - acc: 0.7842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.678430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.784182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.678430\n",
       "1  0.784182"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "pd.DataFrame(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
